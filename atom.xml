<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zuolinlin.github.io/zuo.github.io/</id>
    <title>zuolinlin</title>
    <updated>2022-04-08T13:24:20.681Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zuolinlin.github.io/zuo.github.io/"/>
    <link rel="self" href="https://zuolinlin.github.io/zuo.github.io/atom.xml"/>
    <subtitle>你要问我如何去二仙桥，我会告诉你走成华大道，可你要问人生，我也说不清。</subtitle>
    <logo>https://zuolinlin.github.io/zuo.github.io/images/avatar.png</logo>
    <icon>https://zuolinlin.github.io/zuo.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, zuolinlin</rights>
    <entry>
        <title type="html"><![CDATA[Elasticsearch]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/elasticsearch/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/elasticsearch/">
        </link>
        <updated>2022-04-08T13:23:03.000Z</updated>
        <content type="html"><![CDATA[<h1 id="elasticsearch">Elasticsearch</h1>
<h2 id="目录">目录</h2>
<ul>
<li><a href="#Elasticsearch%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8%E7%AF%87">Elasticsearch核心知识入门篇</a>
<ul>
<li><a href="#Elasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8">Elasticsearch快速入门</a>
<ul>
<li><a href="#Elasticsearch%E5%8A%9F%E8%83%BD%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%E7%89%B9%E7%82%B9">Elasticsearch功能适用场景特点</a></li>
<li><a href="#Elasticsearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5">Elasticsearch核心概念</a></li>
<li><a href="#Elasticsearch%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2">Elasticsearch安装部署</a></li>
<li><a href="#Elasticsearch%E6%96%87%E6%A1%A3%E7%9A%84CRUD">Elasticsearch文档的CRUD</a></li>
<li><a href="#Elasticsearch%E5%A4%9A%E7%A7%8D%E6%90%9C%E7%B4%A2%E6%96%B9%E5%BC%8F">Elasticsearch多种搜索方式</a></li>
<li><a href="#Elasticsearch%E8%81%9A%E5%90%88%E6%90%9C%E7%B4%A2">Elasticsearch聚合搜索</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch分布式架构</a>
<ul>
<li><a href="#Elasticsearch%E5%9F%BA%E7%A1%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch基础分布式架构</a>
<ul>
<li><a href="#Elasticsearch%E5%AF%B9%E5%A4%8D%E6%9D%82%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%8F%E6%98%8E%E9%9A%90%E8%97%8F%E7%89%B9%E6%80%A7">Elasticsearch对复杂分布式机制的透明隐藏特性</a></li>
<li><a href="#Elasticsearch%E7%9A%84%E5%9E%82%E7%9B%B4%E6%89%A9%E5%AE%B9%E4%B8%8E%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9">Elasticsearch的垂直扩容与水平扩容</a></li>
<li><a href="#Elasticsearch%E5%A2%9E%E5%87%8F%E8%8A%82%E7%82%B9%E6%97%B6rebalance">Elasticsearch增减节点时rebalance</a></li>
<li><a href="#Elasticsearch%E7%9A%84master%E8%8A%82%E7%82%B9">Elasticsearch的master节点</a></li>
<li><a href="#Elasticsearch%E8%8A%82%E7%82%B9%E5%B9%B3%E7%AD%89%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch节点平等的分布式架构</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86">index分片原理</a>
<ul>
<li><a href="#Shard&amp;replica%E6%9C%BA%E5%88%B6%E6%A2%B3%E7%90%86">shard&amp;replica机制梳理</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E5%8E%9F%E7%90%86">Elasticsearch横向扩容原理</a>
<ul>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%9F%E7%90%86_%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%EF%BC%8C%E5%A6%82%E4%BD%95%E8%B6%85%E5%87%BA%E6%89%A9%E5%AE%B9%E6%9E%81%E9%99%90%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%AE%B9%E9%94%99%E6%80%A7">Elasticsearch分布式原理_横向扩容，如何超出扩容极限以及如何提升容错性</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%EF%BC%9Amaster%E9%80%89%E4%B8%BE%EF%BC%8Creplace%E5%AE%B9%E9%94%99%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D">Elasticsearch容错机制：master选举，replace容错，数据恢复</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8Fdocument">Elasticsearch分布式document</a>
<ul>
<li><a href="#Index%E5%85%83%E6%95%B0%E6%8D%AE">_index元数据</a></li>
<li><a href="#Type%E5%85%83%E6%95%B0%E6%8D%AE">_type元数据</a></li>
<li><a href="#Id%E5%85%83%E6%95%B0%E6%8D%AE">_id元数据</a></li>
<li><a href="#Source%E5%85%83%E6%95%B0%E6%8D%AE">_source元数据</a></li>
<li><a href="#Document%E7%9A%84%E5%85%A8%E9%87%8F%E6%9B%BF%E6%8D%A2">document的全量替换</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Eexterna1lVersion%E8%BF%9B%E8%A1%8C%E4%B9%90%E8%A7%82%E9%94%81%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6">_基于externa1lVersion进行乐观锁并发控制</a></li>
<li><a href="#PartialUpdate">partial update</a></li>
<li><a href="#%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C">批量操作</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">Elasticsearch分布式系统</a>
<ul>
<li><a href="#Document%E6%95%B0%E6%8D%AE%E8%B7%AF%E7%94%B1%E5%8E%9F%E7%90%86">document数据路由原理</a></li>
<li><a href="#Document%E5%A2%9E%E5%88%A0%E6%94%B9%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86">Document增删改内部原理</a></li>
<li><a href="#%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8Aquorum%E6%9C%BA%E5%88%B6%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">写一致性原理以及quorum机制的深入解析</a></li>
<li><a href="#Document%E5%86%85%E9%83%A8%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86">Document内部查询原理</a></li>
<li><a href="#BuilApi%E7%9A%84%E5%A5%87%E7%89%B9json%E6%A0%BC%E5%BC%8F%E4%B8%8E%E5%BA%95%E5%B1%82%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%85%B3%E7%B3%BB">BuilApi的奇特json格式与底层性能优化关系</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E">Elasticsearch搜索引擎</a>
<ul>
<li><a href="#Search%E7%BB%93%E6%9E%9C%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">search结果的深入解析</a></li>
<li><a href="#Multi-index&amp;multi-type%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86">Multi-index&amp;multi-type搜索模式解析以及搜索原理</a></li>
<li>[分页搜索以及deep paging性能问题深度图解](#分页搜索以及deep paging性能问题深度图解)</li>
<li>[快速掌握query stringserach语法以及_all metadata原理揭秘](#快速掌握query stringserach语法以及_all metadata原理揭秘)</li>
<li><a href="#mapping">mapping</a></li>
<li><a href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%BF%AB%E9%80%9F%E8%A7%A3%E5%AF%86">倒排索引的核心原理快速解密</a></li>
<li><a href="#%E5%88%86%E8%AF%8D%E5%99%A8">分词器</a></li>
<li><a href="#QueryDSL">queryDSL</a></li>
<li><a href="#%E5%AF%B9StringField%E6%8E%92%E5%BA%8F">对stringfield排序</a></li>
<li><a href="#%E7%9B%B8%E5%85%B3%E5%BA%A6%E8%AF%84%E5%88%86TF&amp;IDF%E7%AE%97%E6%B3%95">相关度评分TF&amp;IDF算法</a></li>
<li><a href="#DocValues%E6%AD%A3%E6%8E%92%E7%B4%A2%E5%BC%95">doc Values</a></li>
<li><a href="#QueryPhase">query phase</a></li>
<li><a href="#FetchPhase">fetch phase</a></li>
<li><a href="#%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0%E6%A2%B3%E7%90%86%E4%BB%A5%E5%8F%8Abouncingresults%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">搜索相关参数梳理以及bouncing results问题的解决方案</a></li>
<li><a href="#Scoll%E6%8A%80%E6%9C%AF%E6%BB%9A%E5%8A%A8%E6%90%9C%E7%B4%A2%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE">scoll技术滚动搜索大量数据</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86">Elasticsearch索引管理</a>
<ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5">索引的增删改查</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E5%88%86%E8%AF%8D%E8%B5%B7%E4%BB%A5%E5%8F%8A%E5%AE%9A%E5%88%B6%E5%88%86%E8%AF%8D%E5%99%A8">修改分词起以及定制分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2type%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">深入探索type底层数据结构</a></li>
<li><a href="#MappingRootObject%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">mapping root object深入解析</a></li>
<li><a href="#%E5%AE%9A%E5%88%B6%E5%8C%96%E8%87%AA%E5%B7%B1%E7%9A%84dynamicMapping%E7%AD%96%E7%95%A5">定制化自己的dynamic mapping策略</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Elasticsearch%E9%AB%98%E6%89%8B%E8%BF%9B%E9%98%B6%E7%AF%87">Elasticsearch高手进阶篇</a>
<ul>
<li><a href="#%E6%B7%B1%E5%BA%A6%E6%8F%AD%E7%A7%98%E6%90%9C%E7%B4%A2%E6%8A%80%E6%9C%AF">深度揭秘搜索技术</a></li>
<li><a href="#IK%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8">IK中文分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E8%81%9A%E5%90%88%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">深入聚合数据分析</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E5%AE%9E%E6%88%98">数据建模实战</a></li>
<li><a href="#%E5%AE%8C%E6%88%90%E5%BB%BA%E8%AE%AE">完成建议</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E9%9B%86%E7%BE%A4">生产实践-集群</a></li>
<li><a href="#Elasticsearch%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98">Elasticsearch性能调优</a></li>
</ul>
</li>
</ul>
<h1 id="elasticsearch-2">Elasticsearch</h1>
<h2 id="elasticsearch核心知识入门篇">Elasticsearch核心知识入门篇</h2>
<h3 id="elasticsearch快速入门">Elasticsearch快速入门</h3>
<h4 id="elasticsearch功能适用场景特点">Elasticsearch功能适用场景特点</h4>
<p>1.Elasticsearch的功能、适用场景、以及特点介绍</p>
<pre><code>1.分布式搜索引擎和数据分析引擎
2.全文检索、结构化检索、数据分析
3.对海量数据进行近实时处理
</code></pre>
<p>2.Elasticsearch适用场景</p>
<pre><code>1.维基百科、全文检索、高亮、搜索推荐
2.用户日志、社交网络数据、分析新闻文章公众反馈
3.日志数据分析、logstash采集日志、复杂的数据分析
4.分布式搜索引擎和数据分析引擎
5.全文检索、结构化检索、数据分析
6.对海量数据进行近实时处理
</code></pre>
<p>3.Elasticsearch特点介绍</p>
<pre><code>1.可以作为大型分布式集群技术，处理PB级数据服务大公司，也可以在单机上服务小公司
2.全文检索、数据分析、分布式技术结合在一起。
3.开箱即用、非常简单
4.Elasticsearch提供了全文检索、同义词处理、相关度排序、复杂数据分析、海量数据近实时的功能
</code></pre>
<h4 id="elasticsearch核心概念">Elasticsearch核心概念</h4>
<pre><code>1.Near Realtime(NRT)：近实时,意思是：从查询数据库到数据可以被es搜索到有一个延迟(大概1S);基于es执行搜索和分析可以达到秒级
2.cluster:集群,包含多个节点,每个节点属于哪个 集群是通过一个配置(集群名称,默认是elasticsearch)来决定的。
3.node：节点，几圈中的一个节点，节点也有名称（默认是随机分配的）,节点名称很重要(在运维管理进行操作的时候),默认节点会去加入一个名称为&quot;elasticsearch&quot;的集群中，如果直接启动一堆节点,那么他们会自动组成elasticsearch集群，当然一个节点可以组成elasticsearch集群
4.document:文档,es中最小的数据单元,一个document可以是一条订单数据或者是一个商品数据，通常用JSON数据结构表示,每个index下type中都可以存储多个document,一个document里面有多个field，每个field就是一个数据字段
5.index:索引，包含一堆相似的文档数据,比如订单索引，索引有一个名称。一个index包含多个document，一个index就代表一类类似的document.比如说建立一个product index，商品索引,里面可能就存放了所有的商品数据，所有的商品document.
6.type:类型,每个索引都可以有一个活多个type，type是index中的一个逻辑数据分类,一个type下的document都有相同的field
7.shard：单台机器无法存储大量数据,es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储.有了shard就可以横向扩展，存储更多数据,让搜索和分析等操作分布到多台机器上，执行速度快,提升吞吐量和性能.
8.replica:粉盒一个服务器随机可能出现故障或者宕机.因此可以为每个shard创建多个replica副本,replica可以在shard故障时候提供备用，保证数据不丢失。多个replica哈可以提升搜索作用的吞吐量和性能。
primary shard(建立索引时候一次设置,不能修改,默认5个),replica shard（随时修改数量,默认1个）,默认每个索引10个shard.5个primary shard。5个replica shard。最小高可用配置，是两台server.
</code></pre>
<h4 id="elasticsearch安装部署">Elasticsearch安装部署</h4>
<p>Elasticsearch安装</p>
<pre><code>docker pull elasticsearch:7.6.2

vim /etc/sysctl.conf #文件最后添加一行 vm.max_map_count=262144

mkdir -p /data/elasticsearch/config
mkdir -p /data/elasticsearch/data

进入config目录下 创建 elasticsearch.yml文件 粘贴下面配置

http.host: 0.0.0.0
http.port : 9200
transport.tcp.port : 9300
http.cors.enabled : true
http.cors.allow-origin : &quot;*&quot;
network.bind_host: 0.0.0.0
xpack.security.enabled: true
xpack.security.audit.enabled: true

#启动

docker run -d --restart=always -p 9200:9200 -p 9300:9300 --name elasticsearch -e &quot;discovery.type=single-node&quot; -e &quot;cluster.name=elasticsearch&quot; -v /data/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data/elasticsearch/data:/usr/share/elasticsearch/data -v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins elasticsearch:7.6.2

#启动完毕后设置密码 参考文档: https://www.cnblogs.com/woshimrf/p/docker-es7.html
#进入容器
docker exec -it elasticsearch /bin/bash
执行: ./bin/elasticsearch-setup-passwords auto
输出以下信息:
Changed password for user apm_system
PASSWORD apm_system = l5CWYr67Q6CJUzpKyvZb

Changed password for user kibana
PASSWORD kibana = HOauyvrBjHKxwQ1R2Idt

Changed password for user logstash_system
PASSWORD logstash_system = sHvJEh4kxu0inCAlk8Uc

Changed password for user beats_system
PASSWORD beats_system = 8YmZ4TAAlaSzuVMgBSDi

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = X48M4DRRnWBTgG8y9dWb

Changed password for user elastic
PASSWORD elastic = e4R0G5bbwWTT7IuTdR63

审核服务器:
Changed password for user apm_system
PASSWORD apm_system = E1OeyBsIoY1f4Hk8p3gM

Changed password for user kibana
PASSWORD kibana = 2qlVVaovTSguYNhw4YRf

Changed password for user logstash_system
PASSWORD logstash_system = m0Z9JdoGcPLLuLtjqrNv

Changed password for user beats_system
PASSWORD beats_system = LgNP0AhqfkEBKyg7E006

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = MpiGnxDhy36DtSviy7Bj

Changed password for user elastic
PASSWORD elastic = YWUVdA9MQPhUcFAt9JdH

生产密码:
Changed password for user apm_system
PASSWORD apm_system = rx7WKzaqc1jZMLISiodA

Changed password for user kibana
PASSWORD kibana = lXGbcUu5wFH27XLeOUfL

Changed password for user logstash_system
PASSWORD logstash_system = 9S2Mg1vkUjeqQUdDmCik

Changed password for user beats_system
PASSWORD beats_system = k0pxVqpDQtJnK6z6sjok

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = gN9dIqHHHRMyVmzifIVU

Changed password for user elastic
PASSWORD elastic = n4rI5IOzxqC0Db1HJKzc
</code></pre>
<p>查看Elasticsearch是否启动成功</p>
<p>http://ip:port/?pretty</p>
<pre><code>{
&quot;name&quot; : &quot;66405ae2daed&quot;,    //Node名称
&quot;cluster_name&quot; : &quot;docker-cluster&quot;,  //集群名称  在Elasticsearch.yml 文件里修改
&quot;cluster_uuid&quot; : &quot;5_7wD3BtSKSuIYrBas5w0A&quot;,
&quot;version&quot; : {
&quot;number&quot; : &quot;7.13.1&quot;,         //版本号
&quot;build_flavor&quot; : &quot;default&quot;,
&quot;build_type&quot; : &quot;docker&quot;,
&quot;build_hash&quot; : &quot;9a7758028e4ea59bcab41c12004603c5a7dd84a9&quot;,
&quot;build_date&quot; : &quot;2021-05-28T17:40:59.346932922Z&quot;,
&quot;build_snapshot&quot; : false,
&quot;lucene_version&quot; : &quot;8.8.2&quot;,
&quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,
&quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;
},
&quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre>
<p>查看Elasticsearch集群状态<br>
GET ip:port/_cat/health?v</p>
<p>green：每个索引的primary shard和replica shard 都是activity<br>
yellow：每个索引的primary shard 都是activity ，部分replica shard 不是activity状态，是不可用的状态<br>
red：不是所有的primary shard都是activity，部分索引有数据丢失</p>
<p>kibana安装</p>
<pre><code>mkdir -p /data/kibana/config
docker pull kibana:7.6.2

vim /data/kibana/config/kibana.yml # 填入下面配置

i18n.locale: 'zh-CN'
server.host: '0.0.0.0'
elasticsearch.hosts: ['http://172.18.14.12:9200','http://172.18.14.15:9200','http://172.18.14.10:9200']
elasticsearch.username: 'elastic'
elasticsearch.password: 'n4rI5IOzxqC0Db1HJKzc'
xpack:
  apm.ui.enabled: false
  graph.enabled: false
  ml.enabled: false
  monitoring.enabled: false
  reporting.enabled: false
  security.enabled: false
  grokdebugger.enabled: false
  searchprofiler.enabled: false


# 运行
docker run -d -it --restart=always --privileged=true --name=kibana -p 15601:5601 -v /data/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.6.2
</code></pre>
<h4 id="elasticsearch文档的crud">Elasticsearch文档的CRUD</h4>
<p>快速查看集群中有哪些索引</p>
<pre><code>    GET /_cat/indecs?v
</code></pre>
<p>创建索引</p>
<pre><code>   PUT /test?pretty
</code></pre>
<p>删除索引</p>
<pre><code>DELETE /test?pretty
</code></pre>
<p><strong>document CRUD</strong></p>
<pre><code>新增document文档
    put /index/type/id
    {
        &quot;key1&quot;:&quot;value1&quot;,
        &quot;key2&quot;:&quot;value2&quot;,
    }
更新document文档
POST /index/type/id/_update
   &quot;doc&quot; {
        &quot;key1&quot;:&quot;value1&quot;,
        &quot;key2&quot;:&quot;value2&quot;,
}

删除document文档
DELETE /index/type/id?pretty
</code></pre>
<h4 id="elasticsearch多种搜索方式">Elasticsearch多种搜索方式</h4>
<p>（1）、query string search（因为search都是http请求query string来附带的）</p>
<pre><code>语法：GET /index/type/_search

例：GET /index/type/_search?q=&quot;search&quot;&amp;sort=filed:desc

结果
    {
    &quot;took&quot; : 0, h耗费了几秒
    &quot;timed_out&quot; : false, 是否超时
    &quot;_shards&quot; : { // 请求了几个shard
    &quot;total&quot; : 3,
    &quot;successful&quot; : 3,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
    },
    &quot;hits&quot; : {
    &quot;total&quot; : {  查询的数量
    &quot;value&quot; : 174,
    &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 1.0, 相关度匹配分数，越相关就越匹配，分数越高
    &quot;hits&quot; : [  匹配的document的相关数据
    ]
</code></pre>
<p>在生产环境很少用</p>
<p>（2）、query DSL（Domain Specified Language 特定领域的语言） 基于Http request body请求体，可以用json格式构建语法，可以构建各种复杂的语法</p>
<pre><code>    例如：  
    {
        &quot;query&quot;:{ //查询
        “match_all”:{ //
        },
        &quot;filter&quot; :{ // 过滤
            &quot;range&quot;{
                &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
            }
        }
    }
        &quot;sort&quot;:[ 排序
        {
        &quot;price&quot;:&quot;desc&quot;
        }
        ]
        &quot;from&quot;:1, 查询游标
        &quot;size&quot;:2 查询数量
        }
        &quot;_source&quot;:[&quot;&quot;,&quot;&quot;] :指定要查询出来的field
     }
</code></pre>
<p>match_all:全部查询<br>
match:全文检索，将搜素词拆分为一个个词之后去倒排索引中进行匹配<br>
match_phrase(短语搜索) :要求输入的搜索串，必须在指定字段文本中，完全一模一样的，才能算匹配<br>
sort:排序<br>
highlight:高亮<br>
from:查询游标<br>
size：查询数量<br>
_source:指定要查询出来的field</p>
<h4 id="elasticsearch聚合搜索">Elasticsearch聚合搜索</h4>
<pre><code>GET /index/type/_search
{
    &quot;size&quot;:0,         // 去掉返回值里的hits 具体的document
    &quot;query&quot;：&quot;&quot;  // 查询条件之后在分组
    &quot;aggs&quot;:{
        &quot;group_by_tags&quot;:{       //聚合的别名
            //分组下的操作
            &quot;terms&quot;:{
                &quot;field&quot;:&quot;vaue&quot; //根据field的分组
                &quot;order&quot;:{&quot;group_by_tag1&quot;:desc/asc}  //按照内层聚合的结果降序排序
            },
            // 组内分组计算
            &quot;aggs&quot;:{
                &quot;group_by_tag1&quot;:{
                  }
                }
        }
    }
}
</code></pre>
<p>为需要聚合的filed添加正排索引</p>
<pre><code>PUT /index/_mapping/type
{
    &quot;properties&quot;:{
        &quot;field&quot;:{ //根据filed的设置
            &quot;type&quot;:&quot;string&quot;,
            &quot;fielddata&quot;:&quot;true&quot;,
        }
    }
    
}
</code></pre>
<h3 id="elasticsearch分布式架构">Elasticsearch分布式架构</h3>
<h4 id="elasticsearch基础分布式架构">Elasticsearch基础分布式架构</h4>
<h5 id="elasticsearch对复杂分布式机制的透明隐藏特性">Elasticsearch对复杂分布式机制的透明隐藏特性</h5>
<pre><code>分片机制:我们将document插入到es集群中去，不用关心数据是怎么进行分片的，数据到哪个shard中
cluster discovery：新加入的node自动发现集群，并且加入进去还接受了部分数据
Shared 负载均衡:es会自动进行负载均衡（让每个node上具备差不多的shard数量），以保持每个节点均衡读写负载请求
share副本:rep1ica shard是primary. shard的副本
集群扩容:水平扩容
请求路由:节点对等
share重分配:集群rebalance
</code></pre>
<h5 id="elasticsearch的垂直扩容与水平扩容">Elasticsearch的垂直扩容与水平扩容</h5>
<pre><code>(1).垂直扩容：采购更强大的服务器。成本高，有瓶颈
(2).水平扩容：增加服务器的数量
</code></pre>
<h5 id="elasticsearch增减节点时rebalance">Elasticsearch增减节点时rebalance</h5>
<pre><code>总有一些服务器负载重一些，承载的数据和请求会大一些，当增加或者减少节点时，数据分片会重新rebalance，实现shard的负载均衡（让每个节点的数据量差不多）
</code></pre>
<h5 id="elasticsearch的master节点">Elasticsearch的master节点</h5>
<p>（主要管理es的元数据）</p>
<pre><code>(1)、创建或者删除索引
(2)、增加或者删除节点
</code></pre>
<h5 id="elasticsearch节点平等的分布式架构">Elasticsearch节点平等的分布式架构</h5>
<pre><code>(1)、节点对等，每个节点都能接受所有请求
(2)、自动请求路由
(3)、响应收集
</code></pre>
<h4 id="分片原理">分片原理</h4>
<h5 id="shardreplica机制梳理">Shard&amp;replica机制梳理</h5>
<pre><code>(1) index包含 多个shard，将多个shard分配到各个节点上去，每个shard存储一部分数据
(2)每个shard都是一个最小工作单元， 承载部分数据，1ucene实例， 完整的建立索引和处理请求的能力
(3)增减节点时，shard会自动在nodes中负载均衡
(4) primary shard和replica shard; ，每个document肯定只存在于某一个primary      shard以及其对应的rep1ica shard中， 不可能存在于多个primary shard
(5) rep1ica shard是primary. shard的副本， 负责容错，以及承担读请求负载
(6).primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改
(7).primary shard的默认数量是5，rep1ica默认是1:默认直10个shard; 5 primary shard, 5个replica, shard
(8) primary shard不能和自己的replica shard放在同一个节点上(否则节点宕机，primary shard和副本都丢失，起不到容错的作用)，但是可以和其他primary shard的 ep1ica shard放在同一一个节点上
</code></pre>
<h4 id="elasticsearch横向扩容原理">Elasticsearch横向扩容原理</h4>
<h6 id="elasticsearch分布式原理_横向扩容如何超出扩容极限以及如何提升容错性">Elasticsearch分布式原理_横向扩容，如何超出扩容极限以及如何提升容错性</h6>
<pre><code>1、图解横向扩容过程，如何超出扩容极限，以及如何提升容错性
(1) primary&amp;rep1ica 自动负载均衡，6个shard， 3 primary，3 replica
(2)每个node有更少的shard, I0/CPU/Memory资 源给每个shard分配更多，每个shard性能更好
(3) 扩容的极限， 6个shard (3 primary, 3 replica) ，最多扩 容到6台机案，每个shard可以占用单 台服务器的所有资源，性能最好
(4)超出扩容极限，动态修改rep1ica数量，9个shard (3primary， 6 rep1ica)，扩容到9台机器，比3台机器时，拥有3倍的读吞吐量
(5) 3台机器下，9个shard (3 primary, 6 replica) ，资源更少，但是容错性更好，最多容纳2台机器宕机，6个shard只能容纳1台机器宕
</code></pre>
<h4 id="elasticsearch容错机制master选举replace容错数据恢复">Elasticsearch容错机制：master选举，replace容错，数据恢复</h4>
<pre><code>(1).容错第-步: master选举，自动选举另外一个node成为新的master ,承担起master的责任来
(2).容错第二步:新master ,将丢失掉的primary shard的某个replica shard提升为primary shard.此时cluster status会变为yellow ,因为primaryshard全都变成active了.但是,少了一个replica shard ,所以不是所有的replica shard都是active了.
(3).容错第三步:重启故障的node ,new master ,会将缺失的副本都是copy-份到该node上去。而且该node会使用之前已有的shard数据，只是同步- -下宕机之后发生过的修改。cluster status变为green,因为primary shard和replica shard都齐全了
</code></pre>
<h3 id="elasticsearch分布式document">Elasticsearch分布式document</h3>
<h4 id="index元数据">Index元数据</h4>
<pre><code>(1)代表一个document存放在哪个index中
(2)类似的数据放在一一个素引，非类似的数据放不同索引
(3) index中包含了很多类似的document
(4)索引名称必须是小写的，不能用下划线开头，不能包含逗号
</code></pre>
<h4 id="type元数据">Type元数据</h4>
<pre><code>(1)代表document属于index中的哪个类别(type)
(2)一个索引通常会划分为多个type,谭辑上对index中有些许不同的几类数据进行分类
(3) type名称可以是大写或者小写，但是同时不能用下划线开头，不能包含逗号
</code></pre>
<h4 id="id元数据">Id元数据</h4>
<pre><code>(1)代表document的唯-标识， 与index和type一起， 可以唯-标识和定位一-个document
(2)我们可以手动指定document的id,也可以不指定，由es自动为我们创建一-个id
</code></pre>
<p>根据应用情况来说，是否满足手动指定document id的前提:</p>
<pre><code>-般来说，是从某些其他的系统中，导入一些数据到es时，会采取这种方式，就是使用系统中已有数据的唯一标识，作为es中document的id。 举个例子，比如说，我们现在在开发
- 一个电商网站，做搜索功能:或者是0A系统，做员工检索功能。这个时候，数据首先会在网站系统或者IT系统内部的数据库中，会先有一 份，此时就肯定会有- 一个数据库的primary
  key (自增长，UID,或者是业务编号)。如果将数据导入到es中，此时就比较适合采用数据在数据库中已有的primary key。
  如果说，我们是在做一个系统，这个系统主要的数据存储就是es- -种，也就是说，数据产生出来以后，可能就没有id, 直接就放es- -个存储，那么这个时候，可能就不太适合说手
  动指定document id的形式了，因为你也不知道i d应该是什么，此时可以采取下面要讲解的让es自动生成i d的方式。
  (2) put /index/ type/id
  (3.2)、自动生成document id
  (1) post ./index/ type.
  (2)自动生成的id,长度为20个字符，URL安全，base64编码， GUID, 分布式系统并行生成时不可能会发生冲突
</code></pre>
<h4 id="source元数据">Source元数据</h4>
<pre><code>_source元数据:就是说，我们在创建一个document的时候， 使用的那个放在request body中的json串， 默认情况下，在get的时候，会原封不动的给我们返回回来。定制返回的结果，指定_source中，返回哪些field
</code></pre>
<h4 id="document的全量替换">Document的全量替换</h4>
<p>(1)语法与创建文档是一样的。如果document id不存在，那么就是创建:如果document. ig已经存在，那么就是舍量替换操作,替换document的json串内容<br>
(2) document是不可变的，如果要修改document的内容，第-种方式就是全量替换，直接对document重新建立索引，替换里面所有的内容。<br>
PUT /index/type/id?<br>
(3) es会将老的document标记为deleted,然后新增我们给定的一个document, 当我们创建越来越多的document的时候，es会 在适当的时机在后台自动删除标记为deleted的<br>
document<br>
2、document的强制创建<br>
(1)创建文档与全量替换的语法是一样的， 有时我们只是想新建文档，不想替换文档，如果强制进行创建呢?<br>
(2) PUT /index/ type/id?op__type=create,<br>
PUT /index/type/id/_create<br>
3、document的删除<br>
(1) DELETE  index/type/id<br>
(2)不会理解物理删除，只会将其标记为deleted，当数据越来越多的时候，在后台自动删除</p>
<p>1.Elasticsearch内部如何基于_version如何进行乐观锁并发控制</p>
<p>1.第一次创建一个document的时候，它的_version内部版本号就是1;<br>
2.以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1;哪怕是删除，也会对这条数据的版本号加1<br>
3.多线程并发更新数据时,先获取document数据和最新版本号， 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错或执行retry策略（retry_ on_ conf1ict）;<br>
3.别的线程更新失败后，执行retry策略<br>
retry策略<br>
1、再次获取document数据和最新版本号<br>
2、基于最新版本号再次去更新，如果成功那么就ok了<br>
3、如果失败,重复1和2两个步骤,最多,重复几次呢?可以通过retry那个参数的值指定,比如5次</p>
<h4 id="基于externa1lversion进行乐观锁并发控制">基于externa1lVersion进行乐观锁并发控制</h4>
<pre><code>es提供了一个feature, 就是说，你可以不用它提供的内部_version版本号来进行并发控制，可以基于你自己维护的一一个版本号来进行并发控制。
举个列子，加入你的数据在mysq1
里也有一份，然后你的应用系统本身就维护了-一个版本号，无论是什么自己生成的，程序控制的。
这个时候，你进行乐观锁并发控制的时候，可能并不是想要用es内部的_version来进行控制，而是用你自己维护的那个version来进行控制。
?version=1
?version=1&amp;version_type=externa1

version_type=externa1,唯一-的区别在于， version, 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错;

当version_type=externa1的时候， 只有当你提供的versi on比es中的_versi on大的时候，才能完成修改
es，_version=1?version=1， 才能更新成功
es，_version=1?version&gt; 1&amp;version_type=externa1, 才能成功，比如说?versi on=2&amp;version_type=externa1
</code></pre>
<h4 id="partialupdate">PartialUpdate</h4>
<p>全量替换语法：</p>
<pre><code>PUT /index/type/id,创建文档&amp;替换文档，就是-样的语法
</code></pre>
<p>partial update语法：</p>
<pre><code>post /index/ type/id/_ update
{
'要修改的少数几个fie1d即可，不需要全量的数据”：&quot;&quot;，
&quot;retry_ on_ conf1ict&quot;:&quot;5&quot;  //retry策略
}
</code></pre>
<p>般对应到应用程序中，每次的执行流程基本是这样的（和全量替换的原理一样）:</p>
<pre><code>(1)应用程序发起一个get请求，获取到document， 展示到前台界面，供用户查看和修改
(2)用户在前台界面修改数据，发送到后台
(3)后台代码，会将用户修改的数据在内存中进行执行，然后封装好修改后的全量数据
(4)然后发送PUT请求，到es中， 进行全量替换
(5) es将老的document标记为de1eted，然后重新创建一个 新的document
</code></pre>
<p>看起来，好像就比较方便了，每次就传递少数几个发生修改的fie1d即可，不需要将全量的document数据发送过去</p>
<p>2、图解partial update实现原理以及其优点</p>
<pre><code>partial update, 看起来很方便的操作，实际内部的原理是什么样子的，然后它的优点是什么|

其实es内部对partial update的实际执行,跟传统的全量替换方式，是几乎-样的

1、内部先获取document
2、将传过来的field更新到document的json中
3、将老的document标记为deleted
4、将修改后的新的document创建出来
</code></pre>
<p>partial update相较于全量替换的优点</p>
<pre><code>1、所有的查询、修改和写回操作,都发生在es中的一 个shard内部,避免了所有的网络数据传输的开销(减少2次网络请求) , 大大提升了性能
2、减少了查询和修改中的时间间隔,可以有效减少并发冲突的情况
</code></pre>
<p>基于groovy脚本，如何执行partial update</p>
<pre><code>es， 其实是有个内置的脚本支持的， 可以基于groovy脚本实现各种各样的复杂操作
基于groovy脚本，如何执行partia1 update.
es scripting module, 我们会在高手进阶篇去讲解，这里就只是初步讲解一-下
</code></pre>
<p>partial update乐观锁并发控制原理</p>
<p>1.第一次创建一个document的时候，它的_version内部版本号就是1;<br>
2.以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1;哪怕是删除，也会对这条数据的版本号加1<br>
3.多线程并发更新数据时,先获取document数据和最新版本号， 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错或执行retry策略（retry_ on_ conf1ict）;<br>
3.别的线程更新失败后，执行retry策略<br>
retry策略<br>
1、再次获取document数据和最新版本号<br>
2、基于最新版本号再次去更新，如果成功那么就ok了<br>
3、如果失败,重复1和2两个步骤,最多,重复几次呢?可以通过retry那个参数的值指定,比如5次</p>
<h4 id="批量操作">批量操作</h4>
<p>mget批量查询API(很重要，性能优化的一种方式)</p>
<pre><code>就是一条一条的查询，比如说要查询100条数据，那么就要发送100次网络请求，这个开销还是很大的
如果进行批量查询的话，查询100条数据，就只要发送1次网络请求，网络请求的性能开销缩减100倍
</code></pre>
<p>语法一：查询不同一个index不同type的Document</p>
<pre><code>GET /index/_mget
    {
    &quot;docs&quot;:[
        {
        &quot;_index&quot;：&quot;index&quot;，
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        },
        {
        &quot;_index&quot;：&quot;index&quot;，
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        }
}
</code></pre>
<p>语法二：查询同一个index不同type的Document</p>
<pre><code>GET /index/_mget
{
    &quot;docs&quot;:[
        {
            &quot;_type&quot;: &quot;type&quot;,
            &quot;_id&quot;:&quot;id&quot;
        },
        {
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        }
}
</code></pre>
<p>mget的重要性</p>
<p>可以说mget是很重要的，一 般来说，在进行查询的时候，如果一 次性要查询多条数据的话，那么一定要用batch批量操作的api<br>
尽可能减少网络开销次数，可能可以将性能提升数倍，其至数十倍，非常非常之重要</p>
<p>bulk批量增删改</p>
<p>1、bulk语法</p>
<pre><code>POST /_bulk 或则POST index/type/_bulk
delete&quot;: {” index&quot;:&quot; test_ index,，” type&quot; :“ test_ type'“?”J
create&quot; :index&quot; :” test_ index，”_ type' :” test_ type&quot;，”_ id&quot; :“ 12”} }test_ fie1d&quot;: &quot; test12”}
index&quot;: {_index&quot;:&quot; test_ index' '，”_type&quot; : &quot;test_ _type” }}，test_ field&quot; :auto-generate id test
index&quot; :_index&quot; :” test_ index”_type”: &quot;test_ type&quot;， ”id&quot;:“2”}}'test_ fie1d”:&quot; replaced test2”
update&quot; : {”_ index :“ test_ index'，“type”: &quot;test_ _type”，”id&quot;: &quot;1”， ”retry_ on_ conf1ict&quot; :3} }
{“doc&quot; : {&quot;test_ fie1d2” : &quot;bulk test1&quot;} }
</code></pre>
<p>每一-个操作要两个json串， 语法如下:</p>
<pre><code>'action&quot;: { 'metadata&quot;}}&quot;data&quot;}
举例，比如你现在要创建一 个文档，放bulk里面，看起来会是这样子的:

{&quot; index&quot;: {&quot;_ _index&quot;: &quot;test_ index&quot;，”type&quot;，&quot;test_ type&quot;， &quot; id&quot;:“1&quot;}}
{&quot; test_ fie1d1&quot;:“ test1&quot;，&quot;test_ fie1d2&quot;: &quot;test2&quot;}
</code></pre>
<p>一个操作的语法不能换行，不同操作的语法要换行</p>
<p>有哪些类型的操作可以执行呢?</p>
<pre><code>(1) delete: 删除一个文档
(2) create: PUT /index/type/id/ create， 强制创建
(3) index: 普通的put操作，可以是创建文档，也可以是全量替换文档
( 4) update: 执行的partial update操作
</code></pre>
<p>bulk size最佳大小</p>
<pre><code>bulk, reguest会加载到内存里， 如果太大的话，性能反而会下降，因此需要反复尝试一 个最佳的bulk size。 - -般从1000 5000条数据开始，尝试逐渐增加。另外，如果看大小的话
最好是在5^ 15MB之间。
</code></pre>
<p>document 总结</p>
<pre><code>到目前为止，你觉得你在学什么东西，给大家个真观的感觉，好像已经知道了es是分布式的， 包括一些基本的原理，然后化了不少时间在学习document本身相关的操作，增删改
查。一句话点出来，给大家归纳总结一 下，其实我们应该思考一 下，es的一个最最核心的功能，已经被我们相对完整的讲完了。
Blastigsearch件电智
来以
其实起到的第一个最核心的功能。就是、个分布式的文档数据存储系统。ES是 分布式的。文档数据存储系统。文档据，存储系统。
文档数据: es可以存储和操作json文档类型的数据， 而且这也是es的核心数据结构。
存储系统: es可以对json文档类型的数据进行存储，查询，创建，更新，删除，等等操作。其实已经起到了一个什么样的效果呢?其实ES满足了这些功能，就可以说已经是一个
NoSQL的存储系统了。
围绕着document在操作，其实就是把es当成了一个NoSQL存储引擎，一个 可以存储文档类型数据的存储系统，在操作里面的document。
s可以作为一个分布式的文档存储系统，所以说，我们的应用系统，是不是就可以基于这个概念，去进行相关的应用程序的开发了。
什么类型的应用程序呢?
I (①)数据量较大: es的分布式本质，可以帮助你快速进行护
有的
承载大量数据
(2)
教据精构家适备著随时可能会奔化计雪且教据替格之间的美系常基森出 如果聚们用传统数摄居奇那号不是很玩，因为要面临太量的表
(3)
对数据的
作较为简单，比
就是一些间
改查，用我们之前讲解的那些document操作就可以搞定
(4) NoSQL数据库，适用的也是类似于，上面的这种场景
举个例子，比如说像一些网站系统，或者是普通的电商系统，博客系统，面向对象概念比较复杂，但是作为终端网站来说，没什么太复杂的功能，就是一些简单的CRUD操作， 而且
数据量可能还比较大。这个时候选用ES这种NoSQL型的数据存储，比传统的复杂的功能务必强大的支持SOL的关系型数据库，更加合适一些。无论是性能，还是
春吐量，可能都会更|
好。
</code></pre>
<h3 id="elasticsearch分布式系统">Elasticsearch分布式系统</h3>
<h4 id="document数据路由原理">Document数据路由原理</h4>
<p>document路由到shard是什么意思？</p>
<p>我们知道一个index数据会被分为多片，每片都在一个shard中<br>
所以一个document，只能存放在一个shard中（primary shard）</p>
<p>后面primary shard 会同步到replica shard上</p>
<p>当客户端创建document的时候，此时需要决定，这个document<br>
要放在这个index哪个shard上。<br>
<img src="images/document_route.png" alt="document_route.png" loading="lazy"></p>
<p>(2)路由算法: shard = hash(routing) % number_of_primary_shards举个例子，一个index有3个primary shard, PO, P1, P2</p>
<pre><code>每次增册改查一 个document的时候， 都会带过来一 个routing number,
默认就是这个document的_id (可能是手动指定，也可能是自动生成)routing =. id, 假设. id=1

会将这个routing值， 传入一个hash函数中，产出- -个routing值的hash值， hash(routing) = 21

然后将hash函数产出的值对这个index的primary shard的数量求余数，21%3= 0就决定了，这个document就放在P0上。
</code></pre>
<p>决定一个document在哪个shard上， 最重要的一一个值就是routing值，默认是id,也可以手动指定，相同的routing值，</p>
<p>每次过来，从hash函数中， 产出的hash值-定是相同的无论hash值是几，无论是什么数字，对number_ _of. primary. shards求余数，结果-定是在0 *number_of_primary_shards-1之间这个范围内的。0,1, 2。</p>
<p>(3)_ id or custom routing value默认的routing就是id.</p>
<pre><code>也可以在发送请求的时候，手动指定一 个routing value, 比如说put /index/type/id?routing =useid

手动指定routing value是很有用的， 可以保证说，某- -类document- -定被路由到一-个shard上去， 那么在后续进行应用级别的负载均衡，以及提升批量读取的性能的时候，是很有
</code></pre>
<p>(4) primary shard数量不可变的谜底（路由算法只和primary. shards的数量有关）</p>
<pre><code>因为shard = hash(routing) % number_of_primary_shards决定了document 在哪个shard上，
如果改变，导致数据不在之前的shard上，导致查询的时候，无法找到，就会间接导致数据丢失。
private shard 一旦index建立，是不允许修改的，replica shard 是可以改变的
</code></pre>
<h4 id="document增删改内部原理">Document增删改内部原理</h4>
<figure data-type="image" tabindex="1"><img src="images/document_rud.png" alt="document_rud.png" loading="lazy"></figure>
<pre><code>(1)客户端任意选择-个node发送请求过去，，这个node就会变成coordinating. node (协调节点)
(2) coordinating, node,对document进行路由，,将请求转发给对应的node (有primary shard,因为是增删改操作，请求只能路由到primary shard上去)
(3)实际的node.上的pri mary shard处理请求，然后将数据同步到replica node
(4) coordinating node, 如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端
</code></pre>
<h4 id="写一致性原理以及quorum机制的深入解析">写一致性原理以及quorum机制的深入解析</h4>
<p>(1)我们在发送任何一一个增删改操作的时候，比如说put /index/type/id?consistency=one, 都可以带上一个consistency参数，指明我们想要的写-致性是什么 ?put /index/ type/id?consistency-quorum</p>
<p>consistency= one (primary shard)或者a11 (a11 shard)或者quorum (default)</p>
<p>one:要求我们这个写操作，只要有一个primary shard量active活跃可用的、 就可以执行<br>
all: 要求我们作，必须所有的primary shard和replica shard都是活跃的，才可以执行这个写操作，<br>
quorum: 默认的值，要求所有的shard中， 必须是大部分的shard都是活跃的，可用的，才可以执行这个写操作</p>
<p>(2) quorum机制， 写之前必须确保大多数shard都可用，</p>
<p>quorum = int( (primary+number_of_replicas) / 2 ) + 1， 当number_of_replicas&gt;1 quorum机制才生效<br>
quorum= int( (primary_number_of_replicas) / 2 )1、<br>
举个例子，3个primary, shard, number_of_replicas=1, 总共有3 + 3 * 1 = 6个shard<br>
quorum= int( (3+1)/2)<br>
所以，要求6个shard中至少有3个shard是active状态的， 才可以执行这个写操作</p>
<p>(3)如果节点数少于quorum数量，可能导致quorum不齐全， 进而导致无法执行任何写操作<br>
3个primary, shard, rep1ica=1, 要求至少3个shard号active;<br>
3个shard按照之前学习的shard&amp;replica机制，必须在不同的节点上，如果说只有1台机器的话，是不是有可能出现说3个shard都没法分配齐全，<br>
此时就可能会出现写操作无法执行的情况</p>
<p>1个primary_ shard, replica=3, quorum=((1+3) / 2) + 1=3，要求1个primary shard + 3个rep1ica shard = 4个shard,<br>
其中必须有3个shard是要处于active状态的。如果这个时候只有2台机器的话，会出现什么情祝呢?<br>
es提供了一 种特殊的处理场景，就是说当number_of_replicas&gt; 1时才生效，因为假如说，你就一 个primary shard, replica=1, 此时就2个shard.<br>
(1+1/2)+1=2，要求必须有2个shard是活跃的，但是可能就1个node, 此时就1个shard是活跃的，如果你不特殊处理的话，导致我们的单节点集群就无法工作</p>
<p>(4) quorum不齐全时，wait， 默认1分钟，timeout, 100， 30s<br>
等待期间，期望活跃的shard数量可以增加，最后实在不行，就会timeout<br>
我们其实可以在写操作的时候，加一个timeout参数，<br>
比如说put /index/type/id?timeout-30， 这个就是说自己去设定quorum不齐全的时候， es的timeout时长， 可以缩短，也可以增长</p>
<h4 id="document内部查询原理">Document内部查询原理</h4>
<figure data-type="image" tabindex="2"><img src="images/document_query.png" alt="img.png" loading="lazy"></figure>
<pre><code>1、客户端发送请求到任意一个node, 成为coordinate. node, coordinate node对document进行路由 ，将请 求转发到对应的node,
2、此时会使用round-robin随机轮询算法，在primary shard以及其所有rep1ica中随机选择一个，让读请求负载
3、接收请求的node返回document给coordinate node
4、coordinate node返回
</code></pre>
<p>和写不一样的是，写是找primary shard，读的时候primary shard和replica shard</p>
<p>5、特殊情况: document如果还在建立索引过程中，可能只有primary shard有, 任何一个repl1ica shard都没有， 此时可能会导致无法读取到document, 但是document完成引建立z后，primary shard和replica shard就都有了</p>
<h4 id="builapi的奇特json格式与底层性能优化关系">BuilApi的奇特json格式与底层性能优化关系</h4>
<p>1、bulk中的每个操作都可能要转发到不同的node的shard去执行<br>
2、如果采用比较良好的json数组格式<br>
允许任意的换行，整个可读性非常棒，读起来很爽，es拿到那种标准格式的ison串以后，要按照下述流程去进行处理<br>
(1)将json数组解析为ISONArray对象，这个时候，整个数据，就会在内存中出现一份-模一样的拷贝，-份数据是jison文本，一份数据是JSONArray对象2)解析json落组里的每个对每个请求中的document进行路由<br>
为路由到同一个shardE的多个请求，创建一个请求数组(4)将这个<br>
(5)将序列化后的请求数组发送到对应的节点上去</p>
<p>3、耗费更多内存，更多的jvm gc开销<br>
我们之前提到过bulk size最佳大小的那个问题，--般建议说在几千条那样，然后大小在10MB左右，所以说，可怕的事情来了。假设说现在100个bulk请求发送到了一个节点上去，然后每个请求是10MB，100个请求，就是1000MB = 1GB， 然后每个请求的json都copy 份为jsonarray对象， 此时内存中的占用就会翻倍，就会占用2GB的内存， 甚至还不止。因为弄成jsonarrayZ后，还可能会多搞一些其他的数据结构，2GB+的内存占用。</p>
<p>占用更多的内存可能就会积压其他请求的内存使用量，比如说最重要的搜索请求，分析请求，等等，此时就可能会导致其他请求的性能急速下降，<br>
另外的话，占用内存更多，就会导致java虚拟机的垃圾回收次数更多，跟频繁，每次要回收的垃圾对象更多，耗费的时间更多，导致es的java虚拟机停止工作线程的时间更</p>
<p>现在的奇持格式<br>
(action:{meta&quot;]}\n&quot;data&quot;}}n<br>
&quot;action&quot;:(meta&quot;}n'data&quot;'}\r</p>
<p>(1)不用将其转换为json对象，不会出现内存中的相同数据的拷见，直接按照换行往ison<br>
(2)对每两个组的json，读取meta,进行document路由<br>
(3)直接将对应的json发送到node上去</p>
<p>5、最大的优势在于，不需要将ison数组解析为一个TSONArray对象， 形成一份大数据的拷贝，很费内存空间，尽可能地保证性的</p>
<h3 id="elasticsearch搜索引擎">Elasticsearch搜索引擎</h3>
<h4 id="search结果的深入解析">Search结果的深入解析</h4>
<pre><code>took:整个搜索请求花费了多少毫秒
hits. total:本次搜索返回了几条结果
hits. max_score:本次搜索的所有结果中，最大的相关度分数是多少，每一条document对于search的相关度，越相关，score分数越大， 排位越靠前
hits. hits:默认查询前10条数据，完整数据，score降序排序
shards; shards. fa1的条件(pri mary和replica全部挂掉)，不影响其他shard。默认情况下来说，一个搜索请求，会打到一个index的所有primary shard上去，当然了，每个primary shard都可能会有一个或多 个rep1ic shard, 所以请求也可以到primary shard的其中一个rep1ica shard上去。
timeout:默认无timeout, 1atency平衡icompleteness, 手动指定tineout，
timeout 查询执行机制:指定每个shard就在指定的timed out时间范围内，将搜索到的部分数据直接返回给client，而不是等到所有的数据都搜索出来了在返回
确保说一次搜索，可以在用户指定的time out时间内完成，为时间敏感的搜索应用提供良好的支持
</code></pre>
<h4 id="multi-indexmulti-type搜索模式解析以及搜索原理">Multi-index&amp;multi-type搜索模式解析以及搜索原理</h4>
<figure data-type="image" tabindex="3"><img src="images/Multi-index.png" alt="img.png" loading="lazy"></figure>
<h4 id="分页搜索以及deep-paging性能问题深度图解">分页搜索以及deep paging性能问题深度图解</h4>
<figure data-type="image" tabindex="4"><img src="images/deep_paging.png" alt="img.png" loading="lazy"></figure>
<p>deep paging:搜索特别深，总共6w数据，每个shard分了2w，每页10条数据，<br>
这个时候你要搜索到1000页，每个shard都要返回10010条数据，那么会返回30030条数据，排序，<br>
汇总之后，取第1000页的数据，会出现性能问题</p>
<h4 id="速掌握query-string-search语法以及_all-metadata原理揭秘">速掌握query string search语法以及_all metadata原理揭秘</h4>
<p>基础语法：<br>
GET /index/type/_search?q=filed:value<br>
_all metadata原理：<br>
es中的_all元数据，在建立索引的时候，我们插入一条document，它里面包含了多个field,此时es会将多个field值串联起来<br>
作为_all field的值，同时建立索引<br>
后面如果在搜索的时候，没有对某个filed指定搜索，就默认搜_all field的,其中是包含了所有field的值</p>
<h4 id="mapping">mapping</h4>
<p>mapping:自动或者手动对index建立数据结构和相关配置。mapping里包含了每个field对应的数据类型以及如何分词和搜索的行为。<br>
dynamic mapping:自动为我们建立index，type，以及对应的mapping。mapping里包含了每个field对应的数据类型以及如何分词。</p>
<pre><code>(1)往es里面直接插入数据:会自动建立索引。同时建立type以及对应的mapping
(2) mapping中就自动定义每个filed的数据类型
(3)不同的数据类型(正如说text和date)，可能有的是exact value, full text
(4)exact value在建立倒排索引的时候，分词的时候，是将整个值-起作-一个关键词建立到倒排索引中的: full text, 会经历各种各样的处理，分词，normaliztion (时态转换，同义词转换，天小弓转换)，才会建立到倒排索引中
(5)同时呢，exact value和fu11 text类型的filed就决定了，在一个搜索过来的时候，对exact value fie1d或者是full text. filed进行搜索的行为也是不一样的，会跟建立倒排索引的行为保持一致;比如说exact value搜索的时候，  直接按照整索引行为，包括分词器，等等
(6)可以用dynamic mapping让其自动建立mapping,包括自动设置数据类型，也可以手动index和type的mapping, 自己对各filed进存设置，包括数据类型，包括数据类型，包括分词等等
</code></pre>
<p>总结：mapping决定了field数据类型，倒排索引的行为，还有搜索的行为。</p>
<p>mapping数据类型：</p>
<pre><code>text，byte，short,integer,long float ,double ,boolean ,date
</code></pre>
<p>查询 mapping</p>
<pre><code>GET index/_mapping/type
</code></pre>
<p>只能创建index时手动指定mapping或者添加field mapping，不能修改field mapping</p>
<p>string默认是分词的，也可以手动指定分词行为<br>
analyzed：分词<br>
no_analyzed:不分词<br>
no：不分词不被搜索</p>
<p>创建索引指定filed mapping</p>
<figure data-type="image" tabindex="5"><img src="images/mapping.png" alt="img.png" loading="lazy"></figure>
<p>添加field mapping</p>
<figure data-type="image" tabindex="6"><img src="images/add_field_mapping.png" alt="img.png" loading="lazy"></figure>
<p>查看分词效果</p>
<figure data-type="image" tabindex="7"><img src="images/sehngchanzhexierushuju.png" alt="img.png" loading="lazy"></figure>
<p>es支持两种模式的搜索：<br>
full_text:全文检索<br>
exact_value:精确搜索<br>
不同的filed 有点可能是full_text 有的可能是exact_value<br>
query string search 会用跟倒排索引一样的分词器去进行分词</p>
<h4 id="倒排索引的核心原理快速解密">倒排索引的核心原理快速解密</h4>
<p>倒排索引最简单的建立过程</p>
<figure data-type="image" tabindex="8"><img src="images/daopaisuoyin.png" alt="img.png" loading="lazy"></figure>
<p>normalization：在建立倒排索引的时候，会执行一个操作，也就是说对拆分出来的各个单词进行处理<br>
以提升后面搜索的时候能够搜到相关联文档的概率</p>
<p>我们在搜索的时候，会把词进行拆分，把每一个词去倒排索引中去匹配。</p>
<h4 id="分词器">分词器</h4>
<p>切分词语，<br>
normalization (提升recal1召回率)</p>
<h4 id="querydsl">QueryDSL</h4>
<p>（2）、query DSL（Domain Specified Language 特定领域的语言） 基于Http request body请求体，可以用json格式构建语法，可以构建各种复杂的语法</p>
<pre><code>    例如：  
    {
        &quot;query&quot;:{ //查询
        “match_all”:{ //
        },
        &quot;filter&quot; :{ // 过滤
            &quot;range&quot;{
                &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
            }
        }
    }
        &quot;sort&quot;:[ 排序
        {
        &quot;price&quot;:&quot;desc&quot;
        }
        ]
        &quot;from&quot;:1, 查询游标
        &quot;size&quot;:2 查询数量
        }
        &quot;_source&quot;:[&quot;&quot;,&quot;&quot;] :指定要查询出来的field
     }
</code></pre>
<p>bool:组合查询，其他的查询放在bool下<br>
must:必须匹配<br>
should：可以匹配也可以不匹配<br>
must_not:不要匹配<br>
match_all:全部查询<br>
match:全文检索，将搜素词拆分为一个个词之后去倒排索引中进行匹配<br>
match_phrase(短语搜索) :要求输入的搜索串，必须在指定字段文本中，完全一模一样的，才能算匹配<br>
term:不分词去倒排索引中匹配（比较少用，建立mapping的时候，可以指定那个field不分词）<br>
terms:不分词去倒排索引中匹配（比较少用，建立mapping的时候，可以指定那个field不分词）<br>
exists：搜索词不能为空<br>
sort:排序<br>
highlight:高亮<br>
from:查询游标<br>
size：查询数量<br>
_source:指定要查询出来的field</p>
<p>filter,仅仅只是按照搜索条件过滤出需要的数据而已，不计算任何相关度分数，对相关度没有任何影响<br>
query,会去计算每个document相对于搜索条件的相关度，并按照相关度进行排序<br>
-般来说，如果你是在进行搜索，需要将最匹配搜索条件的数据先返回，那么用query; 如果你只是要根据一些条件筛选出一部分数据，不关注其排序。那么用filter<br>
除非是你的这些搜索案件，你希望越符合这些搜索条件的document起排在前面返回，那么这些搜索条件放在query中;如果你不希望-一些搜索条 件来影响你的document排序，那么filter中即可<br>
3、fi1ter与 query性能<br>
fi1ter,不需要计算相关度分数:不需要按照相关度分数进行排序，同时还有内置的自动cache最常使用filter的功能<br>
query,相反，要计算相关度分数，按照分数进行排序，而且无法cache结果</p>
<p>不要bool，只要filter的话，</p>
<pre><code>{
&quot;query&quot;:{ //查询
  “constant_score”:{
    &quot;filter&quot; :{ // 过滤
    &quot;range&quot;{
    &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
    }
   },

}
</code></pre>
<p>定位DSL语法不合法的原因</p>
<pre><code>GET /index/type/_validate/query?explain
{
    DSL语句
}
</code></pre>
<h4 id="对stringfield排序">对StringField排序</h4>
<p>如果对string file 排序，结果往往是不准确的，因为分词后是多个单词，再排序就不是我们想要的结果<br>
通常解决办法是，将一个string filed索引两次，一个分词用来搜索，另一个不分词，用来排序</p>
<p>方式一：</p>
<pre><code>PUT /index/type/
{
   &quot;mapping&quot;:{
      type:text, /第一次设置分词
      fields:{    //第二次设置不分词
        &quot;raw&quot;:{
            type:string,
            index:&quot;not_analyzed&quot;
        },
      &quot;fielddata&quot;:true  //设置正排索引，为了排序
     }
   }
}
</code></pre>
<h4 id="相关度评分tfidf算法">相关度评分TF&amp;IDF算法</h4>
<p>relevance score算法， 简单来说，就是计算出，-个索引中的文本，与搜索文本，他们之间的关联匹配程度</p>
<p>Elasticsearch 使用的是 term frequency/ inverse document frequency算法， 简称为TF /IDF算法</p>
<p>Term frequency: 搜索文本中的各个词条在fie1d文本中出现了多少次，出现次数越多，就越相关<br>
Inverse document frequency: 搜索文本中的各个词条在整个索引的所有文档中出现了多少次，出现的次数越多，就越不相关<br>
Field-1ength norm: fie1d长度， fie1d越长， 相关度越弱</p>
<p>查看_score分数<br>
GET /test_index/test_type/_search?explain<br>
{<br>
query”: {<br>
'term”: {<br>
&quot;test_filed&quot;:&quot;&quot;<br>
}<br>
}<br>
}</p>
<h4 id="docvalues正排索引">DocValues正排索引</h4>
<p>搜索的吋候，要依靠倒排索引;排序的吋候，需要依靠正排索引，看到毎个document的毎个field, 然后迸行排序，<br>
所渭的正排索引,其是就是doc values<br>
在建:立索引的吋候，-一方面会建立倒排素引，以供搜索用; 一方面会建立正排索引，也就是doc values, 以供排序，聚合,辻濾等操作使用</p>
<p>doc values是被保存在磁盘上的。</p>
<p>如果内存足够，os会自劫将其缓存在内存中，性能逐是会很高;如果内存不足够，os会将其写入磁盈上</p>
<h4 id="queryphase">QueryPhase</h4>
<figure data-type="image" tabindex="9"><img src="images/queryPhase.png" alt="img_1.png" loading="lazy"></figure>
<p>(1)搜索请求发送到某一个coordinate node, 构构建一个priority queue, 长度以paging操作from和size为准，默认为10<br>
(2) coordinate_node将请求转发到所有shard,每个shard本地搜索，并构建一个本地的priority queue<br>
(3)各个shard将自己的priority queue返回给coordinate node， 并构建一个全局的priority queue</p>
<h4 id="fetchphase">FetchPhase</h4>
<figure data-type="image" tabindex="10"><img src="images/FetchPhase.png" alt="img_1.png" loading="lazy"></figure>
<p>（1）coordinate node构建完priority queue之后，就发送mget请求去所有shard上获取对应的document<br>
（2）各个shard将document返回给coordinate node<br>
（3）coordinate node将合并后的document结果返回给client客户端</p>
<h4 id="搜索相关参数梳理以及bouncingresults问题的解决方案">搜索相关参数梳理以及bouncingresults问题的解决方案</h4>
<p>1、preference<br>
决定了哪些shard会被用来执行搜索操作<br>
<em>primary,</em> primary_ first,_ 1oca1，_ on1y_ <em>node:xyz，</em> prefer_ node:xyz，_ shards:2,3<br>
bguncing. results问题，两个document排序， fie1d值相同; 不同的shard上，可能排序不同;每次请求轮询打到不同的replica shard上; 每次页面上看到的搜索结果的排序都不一<br>
样。这就是bouncing resu1t， 也就是跳跃的结果。<br>
搜索的时候，是轮询将搜索请求发送到每一-个replica shard (primary shard)，但是在不同的shard上，可能document的排序不同<br>
解决方案就是将preference设置为一个字符串，比如说user_ id, 让每个user每次搜索的时候，都使用同- -个replica shard去执行， 就不会看到bouncing results了<br>
2、timeout, 已经讲解过原理了，主要就是限定在一定时间内，将部分获取到的数据直接返回，避免查询耗时过张<br>
3、 routing, document文档路由， id路由，routing=user id, 这样的话可以让同一个user对应的数据到一个shard上去<br>
4、search_ type<br>
default: query_ <em>then</em> <em>fetch,<br>
dfs</em> query_ <em>then</em> fetch,可以提升revel ance sort精准度</p>
<h4 id="scoll技术滚动搜索大量数据">Scoll技术滚动搜索大量数据</h4>
<p>如果一次性要查出来比如10万条数据，那么性能会很差，此时一般会采取用sco11滚动查询，一批一批的查，直到所有数据都查询完处理完<br>
使用sco11滚动搜索，可以先搜索一批数据，然后下次再搜索一批数据，以此类推，直到搜索出全部的数据来，</p>
<p>scoll搜索会在第一次搜索的时候，保存一一个当时的视图快照，之后只会基于该旧的视图快照提供数据搜索，如果这个期间数据变更,是不会让用户看到的<br>
采用基于_doc进行排序的方式，性能较高<br>
每次发送scroll请求，我们还需要指定一个sco11参数， 指定一个时间窗口， 每次搜索请求只要在这个时间窗口内能完成就可以了<br>
GET /index/_search?scroll=1m<br>
&quot;query&quot;: {<br>
&quot;metch_a11&quot;: {},<br>
&quot;sort&quot;:[&quot;_doc&quot;],<br>
&quot;size&quot;: 1000<br>
」<br>
获得的结果会有一个scrollid, 下一次再发送scroll请求的时候，必须带上这个scrollid .<br>
GET /_search/scro11<br>
&quot;scroll&quot; :<br>
” scroll<br>
“cXV1 cn1UaGVuRmV0Y2g7NTsxMDk5NDpkUmpiR2F j0F NhNn1CM 1ZDMWpWYnRR0zEw0Tk 10mRSamJHYWM 4U2E2eUI zVkl{xa1Zi dFE7MTA50TM6ZF JqYkdhYzhTYTZ5Q jNWQzF qVmJOUTsxMTE5MDpBVUtwN21 x<br>
c1FLZV8yRGVjW1I2QUVB0zEw0Tk20mRSamJHYWM4U2E2eUI zVkMxa1Zi dFE7MDs='<br>
size会发送给每个shard, 因此每次最多会返回size * primary shard条数据</p>
<p>scoll，看起来挺像分页的，但是其实使用场景不-样。<br>
分页主要是用来一页一页搜索,给用户看的;<br>
sco11主要是用来一批一批检索数据，让系统进行处理的</p>
<h3 id="elasticsearch索引管理">Elasticsearch索引管理</h3>
<h4 id="索引的增删改">索引的增删改</h4>
<h4 id="修改分词起以及定制分词器">修改分词起以及定制分词器</h4>
<h4 id="深入探索type底层数据结构">深入探索type底层数据结构</h4>
<h4 id="mappingrootobject深入解析">MappingRootObject深入解析</h4>
<h4 id="定制化自己的dynamicmapping策略">定制化自己的dynamicMapping策略</h4>
<h2 id="elasticsearch高手进阶篇">Elasticsearch高手进阶篇</h2>
<h3 id="深度揭秘搜索技术">深度揭秘搜索技术</h3>
<p>TermFilter</p>
<p>GET /index/_search<br>
{<br>
&quot;query&quot; : {<br>
constant_score:{<br>
filter:{bool:{<br>
}<br>
}<br>
}<br>
}<br>
}</p>
<pre><code>es新版本内置的建立对于text类型的filed，会建立两次索引，一个是分词的，另一个是不分词的，不分词的是基于field.keyword,最多保留256个字符直接一个字符串放入到倒排索引中。
teamquery：根据exact value进行搜索，数字 boolean 日期有天然支持
text类型的filed需要建立索引是指定not_analyzed,才能用terms
新版本中设置field为keyword和not_analyzed一样就是不分词
term 匹配一个值
terms 匹配多个值
</code></pre>
<p>全文检索多字段搜索</p>
<pre><code>GET /index/_search
{
    bool:{
        &quot;should&quot;:{
            term:{field:value},
            term:{field:value},
        }
    }
}

and match 转term+must

GET /index/_search
{
  bool:{
    &quot;must&quot;:{
       query:'value',
        operator:and
    }
   }
}
等价于
GET /index/_search
{
    bool:{
        &quot;must&quot;:{
            term:{field:value},
            term:{field:value},
        }
    }
}
</code></pre>
<figure data-type="image" tabindex="11"><img src="images/duoziduansousuo.png" alt="img.png" loading="lazy"></figure>
<p>手动控制全文检索的精准度</p>
<figure data-type="image" tabindex="12"><img src="images/convert.png" alt="img.png" loading="lazy"></figure>
<p>boost的细粒度搜索条件控制</p>
<figure data-type="image" tabindex="13"><img src="images/boost.png" alt="img.png" loading="lazy"></figure>
<p>多shard场景下 relevance score 不准确问题大揭秘</p>
<pre><code>如何解决该问题？    
生产环境下，数据量大尽可能的实现均匀分配
测试环境下，将所有的primary设置为1
测试环境下搜索附带search_type = dfs_query_then_query参数，会将local IDF取出来计算global IDF
</code></pre>
<p>基于dis_max实现best_field策略进行多字段搜索</p>
<pre><code>dix_max取某一个query最大的分数
GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
        &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;},
        {match:&quot;content&quot;:&quot;java solution&quot;}
     ]
    }  ,
    tie_ breaker:0.3
}

}
</code></pre>
<figure data-type="image" tabindex="14"><img src="images/best_field.png" alt="img.png" loading="lazy"></figure>
<p>基于tie_ breaker参数优化dis_ max搜索效果</p>
<pre><code>使用tie_ breaker参数的意义在于将其他query分数乘以tie_ breaker 综合与
最高分数的那个query，综合一起计算，除了最高分外将其他query的分数也考虑进去

GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
      &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;},
        {match:&quot;content&quot;:&quot;java solution&quot;}
     ]
    }  ,
    tie_ breaker:0.3
}

}
</code></pre>
<p>实战基于multi match语法实现dis_max+tie_breaker<br>
best_fields 策略</p>
<pre><code>GET / index/_search
    {
    &quot;query&quot;:{
      &quot;multi_match&quot;:{
         &quot;query&quot;:&quot;aaa&quot;,
         &quot;fileds&quot;:[&quot;field1&quot;,&quot;field2&quot;],
         type:&quot;best_fields&quot;,
         &quot;tie_breaker&quot;:0.3,
        &quot;minimum_should_match&quot;:50%
     }
}
</code></pre>
<p>等价于</p>
<pre><code>GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
        &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;
        &quot;minimum_should_match&quot;:50%
        &quot;boost&quot;:2},
        {match:&quot;content&quot;:&quot;java solution&quot;}
    ]  ,
    }  ,
    tie_ breaker:0.3
}

}
minimum_should_match:去长尾，控制搜索的精准度，只要匹配到一定数量的关键数据才能返回
</code></pre>
<p>基于multi_ match+most field策略进行multi-field搜索</p>
<pre><code>GET / index/_search
    {
    &quot;query&quot;:{
      &quot;multi_match&quot;:{
        &quot;query&quot;:&quot;&quot;,
          filed:[&quot;field1&quot;,&quot;field2&quot;],
         type:&quot;most_field&quot;,
         &quot;tie_breaker&quot;:0.3,
        &quot;minimum_should_match&quot;:50%
     }
}
</code></pre>
<p>与best_fields的区别</p>
<pre><code>1.best_fields是对多个field进行搜索，搜索挑选某个field匹配度最高的那个分数，同时在多个query最高分相同的情况下，在一定
程度上考虑其他query的分数。简单来说，你对多个field进行搜索，就想搜索到某一个field尽可能的包含更多关键字的数据
优点：通过best_fields策略，以及综合考虑其他field，还有minimum_should_match，可以尽可能精准地将匹配结果推送到最前面
缺点：除了那些精准匹配的结果，其他差不多大的结果，排序结果不太均匀
实际的例子，百度之类的搜索引擎，最匹配的在前面，但是其他的就没有什么区分度了
2.most_fields,综合多个field一起进行搜索，尽可能多的让所有field的query参与到总分计算中来，此时就会是个大杂烩结果不一定精准，
某一个document的一个field包含了多个关键字，但是因为有其他document有更多的field匹配到了，所以排在了前面；所以需要建立sub_title.std这样的field，
尽可能的让某一个field匹配到query string，贡献更高的分数，将更精准的结果拍到前面
优点：尽可能的匹配更多的field的结果推送到前面整个结果是比较均匀分布的
缺点：可能那些精准匹配的结果无法推送到到前面
实际的例子wiki，明显就是most_fields策略，搜索的结果比较均匀，但是翻好几页才能找到最匹配的结果
</code></pre>
<p>使用most_ fields策 略进行cross-fields search弊端大揭秘</p>
<p>使用copy_ to 定制组合field解决cross- -fields搜索弊端</p>
<p>使用原生cross-field技术解决搜索弊端</p>
<p>phrase matching搜索技术</p>
<pre><code>match query 做全文检索时，只能搜索包含这些次的document，
如果需要这些词里得很近的document，那就要给他一个更高的relevance score 这里
就涉及到proximity match 近似匹配
 
GET /index/_search
{
    &quot;query&quot;:{
    match_phrase:{
        &quot;title&quot;:{
        &quot;query&quot;:&quot;java spark&quot;,
        &quot;slop&quot;:1
    }
  }
 }
}
slop:query string搜索文本中的几个term，要经过多少次移动才能与一个document匹配 
其实加了phrase match 就是 proximity match 近似匹配
</code></pre>
<p>混合使用match和近似匹配实现召回率与精准度的平衡</p>
<pre><code>召回率（recall）： 比如说你搜索一个java spark 总共有100个doc，能返回多少个结果作为doc，就是召回率。
精准度（precision）:比如你搜索一个java spark ,能不能尽可能的让包含java spark，或者java和spark离得很近的排在前面
近似匹配的时候，召回率比较低，精准度太高了
但是有时候可能我们希望的是匹配到几个term中的部分，就可以作为结果出来，这样可以提高召回率。同时我们也希望用上match_phrase根据距离提高分数的功能，
让几个term距离越近的分数越高，优先返回
就是优先返回召回率同时兼顾精准度
   GET /index/_search
{
    &quot;query&quot;:{
      bool:{
         must:{
            &quot;match&quot;:{
              &quot;field&quot;:{
                &quot;query&quot;:&quot; vaule&quot;,
                &quot;minimum_should_match&quot; :&quot;50%&quot;
          },
          should:{
            &quot;match_phrase&quot;:{
                &quot;field&quot;:{
                   &quot;query&quot;:&quot;value&quot;
                    &quot;slop&quot;:&quot;50&quot;
                }
            }
        }
      }
    }
  }
 }
}
</code></pre>
<p>使用rescore机制优化近似匹配搜索的性能</p>
<pre><code>match 和 match_phrase区别
    match：只要简单的匹配到了一个term，就可以将doc作为结果返回
    match_phrase：首先扫描到所有的term的doc list；找到包含所有的
    term 的doc list；然后对每个doc都计算每个term的position，是否符合指定范围
    slop，需要进行复杂的运算，来判断是否通过slop，
match query的性能要比match_phrase和 proximity match(有slop) 近似匹配要高很多，
因为后两者豆芽计算position 的距离。match query 比match_phrase性能搞10被，比proximity match 高20倍
但是别担心，因为es的性能都是毫秒级别的，match query一般就在几毫秒或者几十毫秒，所以是可以接受的

优化proximity match的性能一般就是减少要进行proximity match搜索的documeng 的数量
主要思路就是match query 先过滤出需要的数据，然后再用proximity match来根据term距离来提高doc分数
rescore：重打分
</code></pre>
<pre><code class="language-java">   GET/index/_search
        {
        &quot;query&quot;:{
                    &quot;match&quot;:{
                     &quot;field&quot;:&quot; vaule&quot;,
                     
               }
          },
        rescore:{
            &quot;window_size&quot;:50,
             rescore_query:{
                &quot;match_phrase&quot;:{
                &quot;field&quot;:{
                &quot;query&quot;:&quot;value&quot;
                &quot;slop&quot;:&quot;50&quot;
                }
            }
           }
        }
</code></pre>
<figure data-type="image" tabindex="15"><img src="images/rescoring.png" alt="img.png" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="images/chongdafen.png" alt="img.png" loading="lazy"></figure>
<p>实战前缀搜索、通配符搜索、正则搜索等技术</p>
<pre><code>前缀搜索

    GET /index/_search/
    {
        &quot;query&quot;:{
         &quot;prefix&quot;:{
            &quot;field&quot;:&quot;value&quot;
        }
      }
    }
prefix query 不计算relevance score 与prefix filter 唯一区别就是
filter 会cache bitset
前缀越短，要处理的doc越多，性能越差，尽可能的用长前缀搜索
 
通配符搜索：
跟前缀搜索类似，功能更加强大

GET /index/_search/
{
&quot;query&quot;:{
  &quot;wildcard&quot;:{
      &quot;field&quot;:&quot;value&quot;
      }
   }
}

 正则搜索
   GET /index/_search/
 {
    &quot;query&quot;:{
      &quot;regexp&quot;:{
          &quot;field&quot;:&quot;value&quot;
          }
       }
  }

wildcard 和regexp和prefix原理一致，都会扫描整个索引，性能很差
</code></pre>
<p>实战match_phrase_prefix实现search-time搜索推荐（少用）</p>
<pre><code>match_phrase_prefix原理跟match_phrase类似，唯一的区别就是把最后一个term超过这个数量的就不需要匹配了，限定性能
也可以指定slop，但是最后一个term会最为前缀
 max_expansions:指定prefix最多匹配多个term，超过这个数量就不再匹配了，限定性能
   GET /index/_search/
 {
    &quot;query&quot;:{
      &quot;match_phrase_prefix&quot;:{
          &quot;field&quot;:&quot;{
                &quot;query&quot;:&quot;value1 value2&quot;,
                &quot;slop&quot;:&quot;10&quot;,
                &quot;max_expansions&quot;:50,
             }
          }
       }
  }
默认情况下，前缀要扫描所有的倒排索引中的term，去找这个词打头的，但是这样性能太差，可以用max_expansions限定，最对匹配多少个。就停止搜索了。
</code></pre>
<p>实战通过ngram分词机制实现index-time搜索推荐</p>
<figure data-type="image" tabindex="17"><img src="images/ngram.png" alt="img.png" loading="lazy"></figure>
<p>深入揭秘TF&amp;IDF算法以及向量空间模型算法</p>
<p>深入揭秘lucene的相关度分数算法</p>
<p>实战掌握四种常见的相关度分数优化方法</p>
<p>实战用function_ score自定 义相关度分数算法</p>
<p>实战掌握误拼写时的fuzzy模糊搜索技术<br>
<img src="images/fuzzy.png" alt="img.png" loading="lazy"></p>
<h3 id="ik中文分词器">IK中文分词器</h3>
<h3 id="深入聚合数据分析">深入聚合数据分析</h3>
<p>bucket与metric核心概念</p>
<pre><code>bucket:对数据进行分组，每一组就是一个bucket
metric:对一个数据组进行统计，就是对一个bucket执行某种聚合分析操作，比如说求最大值，求最小值
select count(*) from table group by id 
bucket:group by id --&gt; 那些id相同的数据，就会被划分到一个bucket中
metric:count(*),对每个id 对应饿bucket中的所有数据，计算一个数量
</code></pre>
<p>聚合分组最基本语法</p>
<pre><code>GET /index/_search/
{
   size:0,
   &quot;aggs&quot;:{
      &quot;group_name&quot;: {
          &quot;terms&quot;:{
                &quot;field&quot;:&quot;value&quot;
            }
        }
    }
}
size：只获取聚合结果，而不要执行聚合的原始数据
aggs: 固定语法，要对一份数据执行分组聚合操作
group_name：就是对每个aggs，都要起一个名字，这个名字是自定义的，你取什么都OK 
terms:根据字段的值进行分组
filed:根据指定的字段的值进行分组
</code></pre>
<p>聚合查询结果分析：</p>
<pre><code>hits.hits:我们指定了size是0，所以hits.hits就是空的，否则会把执行聚合的那些原始数据给你返回回来
aggregations:聚合结果
group_name：我们执行的聚合的名称
buckets:我们执行的field划分出的buckets
doc_count:这个bucket分组内有多少数据
默认的排序规则:按照doc_count倒叙排序
</code></pre>
<p>聚合分组后，执行每组的metric聚合操作：</p>
<pre><code>GET /index/_search/
{
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
     &quot;terms&quot;:{
     &quot;field&quot;:&quot;value&quot;
      },
     &quot;aggs&quot;:{
        &quot;group_name_1&quot;:
            &quot;ave&quot;:{
                &quot;field&quot;:&quot;value&quot;
            }
        }
    }
  }
}
doc_count: 其实知识es的bucket操作默认执行的一个内置的metric
对每组bucket执行metric聚合统计操作
在一个aggs执行的bucket操作（terms），平级的json结构下，再加一个aggs，
这个aggs内部同样去个名字，执行metric操作avg（max，min），对之前的每个bucket中的数据的执行field，求一个平均值

select avg(field) from tabel group by filed
</code></pre>
<p>bucket嵌套实现多层下钻分析：</p>
<pre><code>下钻的意思是：已经分了一个组，比如说颜色的分组，然后还要对这个分组内的数据在分组，比如说一个颜色内有多个不同品牌的组
最后对每个最小粒度的分组进行聚合分析操作，这就叫做下钻分析。 

es实现下钻分析，就是对bucket进行多层嵌套，多次分组
     GET /index/_search/
{
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
         &quot;terms&quot;:{
         &quot;field&quot;:&quot;value&quot;
          },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;avg&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;max&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;min&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
            },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;terms&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                 &quot;aggs&quot;:{
                   &quot;group_name_1&quot;:
                    &quot;ave&quot;:{
                       &quot;field&quot;:&quot;value&quot;
                }
            },
            },
    }
  }
}
avg:计算组内平均值
max:计算组内最大值
min:计算组内最小值
sum:计算组内平均值
</code></pre>
<p>histogram区间统计</p>
<pre><code>histogram，类似terms，也是进行bucket分组操作，按照这个field的值的各个范围区间，进行bucket分组操作
按照数字区间：
&quot;histogram&quot;:{
         &quot;field&quot;:&quot;value&quot;
         &quot;interval&quot;:2000
         },
interval:2000 划分范围，比如0-2000，2000-4000 bucket
 去根据field的值看落在哪个区间，就会将这条数据放在哪个bucket中
按照日期区间；
    &quot;histogram&quot;:{
         &quot;field&quot;:&quot;value&quot;
         &quot;interval&quot;:&quot;month&quot;
         &quot;format&quot;:&quot;yyyy-MM-dd&quot;
        &quot;min_doc_count&quot;:0
        &quot;extended_bounds&quot;:{
            &quot;min&quot;:&quot;2017-01-10&quot;,
            &quot;max&quot;:&quot;2017-11-10&quot;,
        }
     },
    min_doc_count:即使某个日期interval一条数据也没有，那么这个区间也是要返回的，不然默认会过滤掉这个区间
    extended_bounds：划分bucket会限定起止日期
    extended_bounds.min：开始日期
    extended_bounds.max：截止日期
</code></pre>
<p>搜索+聚合</p>
<pre><code>es aggregation scope 任何的聚合都必须在搜索的结果中执行，搜索结果就是分析的scope

        GET /index/_search/
{
    query：{},
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
         &quot;terms&quot;:{
         &quot;field&quot;:&quot;value&quot;
          },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;avg&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;max&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;min&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
            },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;terms&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                 &quot;aggs&quot;:{
                   &quot;group_name_1&quot;:
                    &quot;ave&quot;:{
                       &quot;field&quot;:&quot;value&quot;
                }
            },
            },
    }
  }
}
</code></pre>
<p>排序</p>
<pre><code>es聚合排序默认是按照每组的doc_count降序来排的
如果按照指定字段来排序
GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;terms&quot;:{
              &quot;field&quot;:&quot;value&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            },
           &quot;aggs&quot;:{
                &quot;group_name_1&quot;:{
                 &quot;avg&quot;:{&quot;field&quot;:&quot;value&quot;}
                }

            }
        }

    }

    }
}
</code></pre>
<p>并行聚合算法、三角选择原则、近似聚合算法</p>
<pre><code>有些聚合算法，是很容易可以并行的，比如说max
有些聚合分析的算法是不好并行的，比如说count(distinct), 并不是说在每个node上，
直接就出一些distinct value，就可以了，因为有些数据可能会很多近似估计后的结构，
不完全准确，但是速度会很快，一一般是完全精准的算法的性能的十倍

三角选择原则：精准+实时+大数据
1.精准+实时：没有大数据，数据量很小，那么一般就是单机跑，随便你怎么玩就可以
2.精准+大数据：hadoop，批处理，非实时，可以处理海量数据，保证精准，可能会跑几个小时
3.大数据+实时：es 不精准，近似估计，可能会有百分之几的错误率

近似聚合算法
如果采用近似估计的算法，延时在100ms左右，0.5%错误
如果采用100%精准的算法：延时一般在5s到几十秒 几个小时，0%错误率
</code></pre>
<p>去重</p>
<pre><code>es去重，cardinality metric，对每个bucket中指定的filed去重，取去重后的count,类似count(distinct)
 GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;terms&quot;:{
              &quot;field&quot;:&quot;value&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            },
           &quot;aggs&quot;:{
                &quot;distinct_group_name&quot;:{
                 &quot;cardinality&quot;:{&quot;field&quot;:&quot;value&quot;,&quot;precision_threshold&quot;:&quot;100&quot;}
                }

            }
        }

    }

    }
}
precision_threshold: precision_threshold* 8内存的消耗
占用内存很小而且你的unique value如果在值以内，那么可以确保100%精准
precision_threshold 设置的值越大，占用内存越大，可以确保更多unique value的100%准确
</code></pre>
<p>HyperLog++（HLL）算法性能优化(一般)</p>
<pre><code>cardinality底层是HyperLog算法
会对所有的unique value取hash值，通过hash值近似的去求distinct count，
默认情况下 ，发送一个cardinality请求的时候，会动态的对所有的filed value2
取hash值，前移到建立索引的时候
 
put /index/_mapping
 {
    &quot;mapping&quot;:{
        properties:{
         &quot;type&quot;:&quot;text&quot;,
        &quot;fileds&quot;:{
            &quot;hash&quot;:{&quot;type&quot;:&quot;murmur3&quot;}
        }
    }
    }
}

查询时
    GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;cardinality&quot;:{
              &quot;field&quot;:&quot;type.hash&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            }
        }
    }
}
</code></pre>
<p>percentiles百分比算法</p>
<pre><code>GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;percentiles&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        }
    }，
    &quot;latency_ave&quot;:{
    &quot;avg&quot;:{field:&quot;value&quot;}
    }
}


  GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;percentiles&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        },
    &quot;aggs&quot;:{
        &quot;group_name_1&quot;:{
            &quot;percentile_ranks&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        },

    }，
    
}
</code></pre>
<p>基于doc value正排索引聚合分析内部原理</p>
<pre><code>核心原理
    与倒排索引类似，正排索引也会写入磁盘文件中，然后呢os cache先进行缓存，以提升 doc value正排索引的性能
    如果 os cache 内存大小不足够放下整个正排索引，就会将doc value数据写入到磁盘文件中

性能问题：
    es官网建议，es大量是基于os cache来进行缓存和提升性能的，不建议用JVM内存来进行缓存
    那样会导致GC和oom的问题
    一般来说给jvm更少的内存，给os cache更大的内存
    os cache可以提升doc value和倒排索引的缓存和查询效率

column压缩：
  1.所有的值相同，直接保留单值
  2.....
  3.
disable doc value
    如果的确不需要用到doc value，比如聚合，排序等操作，那么可以禁用，减少磁盘占用
    put /index/
    {
        &quot;mapping&quot;
            &quot;properties&quot;:{
               &quot;field&quot;:&quot;keyword&quot;,
                &quot;doc_values&quot;:false
            }
    }
doc_values:false 禁用倒排索引
</code></pre>
<p>string field 和fielddata原理</p>
<pre><code>对分词的field直接执行聚合操作，会报错，
大概的意思是说，你必须要打开fielddata，然后将正排索引的数据加入到缓存中，才可以对分词的field进行聚合操作
会消耗很大的内存

对不分词的field执行聚合操作，直接可以执行，不需要设置fielddata ：true

分词field + fielddata的工作原理
    如果你的某个fie1d不分词，那么在建立索引的时候，会自动生成doc value（正排索引），针对这些不分词的fie1d 执行聚合操作，直接就可以执行
    分词的fie1d，是没有doc value的，所以必须打开是使用fielddata，那么必须将fielddata = true ，那么es在进行聚合操作的时候，会现场对
    field建立一份正排索引，完全存于内存中，结构和doc value类似，如果是ngram或者是大量的term，那么必将
    占用大量的内存，导致性能很差

fielddata加载是lazy加载的，对一个analyzed field执行聚合时，才会加载，而且是field-level
一个index的field所有的doc都会被加载，而不是少数doc
不是index-time创建，是query-time创建

fielddata内存限制
    indices.fielddata.cache.size:20%,超出限制清楚内存已有的fielddata数据
    默认设置无限制，限制内存的使用，但是会导致频繁evict和reload，大量的IO性能损耗，以及内存碎片和gc 

监控fielddata内存使用
     GET /_stats/fielddata?fileds=*
     GET /_nodes/_stats/indices/fielddata?fileds=*
     GET /_nodes/_stats/indices/fielddata?level=indices&amp;fileds=*

Circuit breaker 
        如果一次query load的fielddata超过总内存，就会oom 
indices.breaker.fielddata.limit: fielddata内存限制默认是60%
indices.breaker.request.limit: 执行聚合操作的内存限制，默认40%
indices.breaker.total.limit: 综合上面两个，限制在70%以内

fielddata filter细粒度内存加载控制
    POST /index/_mapping
    {
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;filter&quot;: {
                &quot;frequency&quot;:{
                    &quot;min&quot;:&quot;0.01&quot;,
                    &quot;min_segment_size&quot;:500
                    }
                }
            }
        }
    }
   min:仅仅加载至少在1%的doc中出现过的term对于的fielddata
   min_segment_size：少于500doc的segment 不加载fielddata
   这两个参数比较底层，一般不设置

fielddata预加载机制，以及序号标记预加载
    如果真的要对某个分词的field进行聚合，那么在query-time的时候现场生产fielddata并加载到内存，速度可能比较慢，此时我们可以fielddata预加载
     POST /index/_mapping
    {
       &quot;properties&quot;:{
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;loading&quot;：&quot;eager&quot;
            }
        }
     }
    }


  POST /index/_mapping
    {
       &quot;properties&quot;:{
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;loading&quot;：&quot;eager_global_ordinals&quot;
            }
        }
     }
    }
</code></pre>
<p>海量bucket优化机制：从深度优化到广度优化</p>
<figure data-type="image" tabindex="18"><img src="images/sdyx.png" alt="img.png" loading="lazy"></figure>
<h3 id="数据建模实战">数据建模实战</h3>
<h3 id="完成建议">完成建议</h3>
<pre><code>基于complete suggest实现搜索提示

比如说我们在百度搜索 '大话西游' 百度会自动给你提示 ，
'大话西游电影'，'大话西游小说'，'大话西游手游'
不用你把所有你想要的文本都输入完，搜索引擎会自动提示你可能想要搜索的那个文本
PUT index
   {
    &quot;settings&quot;: {
        &quot;number_of_shards&quot;: 3,
        &quot;number_of_replicas&quot;: 2
    },
 
    &quot;mappings&quot;: {
        &quot;properties&quot; : {
        &quot;suggest&quot; : {
            &quot;type&quot; : &quot;completion&quot;
        },
          &quot;id&quot;: {
           &quot;type&quot;: &quot;integer&quot;
        }
    }
  }
}

或者

PUT index
   {
    &quot;settings&quot;: {
        &quot;number_of_shards&quot;: 3,
        &quot;number_of_replicas&quot;: 2
    },
 
    &quot;mappings&quot;: {
        &quot;properties&quot; : {
        &quot;title&quot; : {
             &quot;type&quot; : &quot;text&quot;,
            &quot;analyzed&quot;:&quot;ik_max_word&quot;
             &quot;fields&quot;: {
                    &quot;suggest&quot;: {
                        &quot;type&quot;: &quot;completion&quot;,
                        &quot;analyzer&quot;:&quot;ik_max_word&quot;
                    }
                }
        },
          &quot;id&quot;: {
           &quot;type&quot;: &quot;integer&quot;
        }
    }
  }
}
completion,es实现的时候，是非常高性能的，会建立不是倒排索引，也不是正排索引。
就是纯基于前缀搜索的一种特殊数据结构，而且会放在内存中，所以auto completion进行
前缀搜索提示性能是非常高的。


GET /index/_search/
{
  &quot;suggest&quot;:{
    &quot;my-suggest&quot;:{
        &quot;prefix&quot;:&quot;大话西游&quot;，
        &quot;completion&quot;:{
            &quot;field&quot;:&quot;suggest&quot;
        }

        }
    }

或者

GET /index/_search/
{
  &quot;suggest&quot;:{
    &quot;my-suggest&quot;:{
        &quot;prefix&quot;:&quot;大话西游&quot;，
        &quot;completion&quot;:{
            &quot;field&quot;:&quot;title.suggest&quot;
        }
      }
    }
}
</code></pre>
<h3 id="生产实践集群">生产实践集群</h3>
<h3 id="elasticsearch性能调优">Elasticsearch性能调优</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/redis/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/redis/">
        </link>
        <updated>2022-04-08T13:20:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="redis">redis</h1>
<h2 id="目录">目录</h2>
<ul>
<li>
<p><a href="#redis%E6%9E%B6%E6%9E%84">redis架构</a></p>
<ul>
<li><a href="#Redis%E6%8C%81%E4%B9%85%E5%8C%96">redis持久化</a>
<ul>
<li><a href="#RDB%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6">RDB持久化机制</a></li>
<li><a href="#AOF%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6">AOF持久化机制</a></li>
</ul>
</li>
<li><a href="#Redis%E4%B8%BB%E4%BB%8E">redis主从</a></li>
<li><a href="#Redis%E5%93%A8%E5%85%B5">redis哨兵</a></li>
<li><a href="#Redis%E9%9B%86%E7%BE%A4">redis集群</a></li>
</ul>
</li>
<li>
<p><a href="#Redis%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7">redis双写一致性</a></p>
</li>
<li>
<p><a href="#Redis%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF">redis缓存雪崩、穿透、击穿</a></p>
</li>
<li>
<p><a href="#Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">redis分布式锁的实现原理</a></p>
</li>
<li>
<p><a href="#redis%E5%AE%9E%E6%88%98">redis实战</a><br>
-<a href="#string">string</a><br>
-[setnx](#setnx redis分布式锁实现)<br>
-<a href="#mset,mget,msetnx">mset,mget,msetnx</a><br>
-<a href="#append">append</a><br>
-<a href="#incr">incr</a><br>
-<a href="#decr">decr</a><br>
-<a href="#exists">exists</a><br>
-<a href="#exists">del</a><br>
-<a href="#type">type</a><br>
-<a href="EXPIRE">EXPIRE</a><br>
-<a href="#hash">hash</a><br>
-<a href="#hset,hget">hset,hget</a><br>
-<a href="#hincr,hdecr">hincr,hdecr</a><br>
-<a href="#list">list</a><br>
-<a href="#lpush">lpush</a><br>
-[BRPOP BLPOP](#BRPOP BLPOP)<br>
-[RPOPLPUSH BRPOPLPUSH](#RPOPLPUSH BRPOPLPUSH)<br>
-[LINDEX LSET LINSERT LTRIM LREM ](#LINDEX LSET LINSERT LTRIM LREM )<br>
-<a href="#set">set</a><br>
-<a href="#sadd">sadd</a><br>
-[BRPOP BLPOP](#BRPOP BLPOP)<br>
-[RPOPLPUSH BRPOPLPUSH](#RPOPLPUSH BRPOPLPUSH)<br>
-[LINDEX LSET LINSERT LTRIM LREM ](#LINDEX LSET LINSERT LTRIM LREM )</p>
<p>-[sorted set](#sorted set)<br>
-<a href="#HyperLoglog">HyperLoglog</a>；<br>
-<a href="#bitmap">bitmap</a><br>
-<a href="#GeoHash">GeoHash</a></p>
</li>
</ul>
<h1 id="redis-2">redis</h1>
<h2 id="目录-2">目录</h2>
<h3 id="redis架构">Redis架构</h3>
<h4 id="redis持久化">Redis持久化</h4>
<p>redis持久化机制对于故障恢复意义</p>
<pre><code>    数据备份和故障恢复，
    如果没有持久化，redis遇到灾难性故障的时候，就会丢失所有的数据，
    如果通过持久化将数据搞一份在磁盘上，然后定期同步到云服务器上，那么就可以保证数据不丢失全部，
    还是可以恢复一部分
</code></pre>
<h5 id="rdb持久化机制">RDB持久化机制</h5>
<p>RDB持久化机制原理介绍：每隔几分钟，生成redis内存数据的一份完整的快照<br>
缺点：redis故障恢复时，数据对丢失的比AOF更多<br>
主进程在fork RDB文件时，如果文件过大，可能导致服务暂停数毫秒，甚至数秒<br>
优点：1.RDB会生成多个数据文件，每个文件都代表了某一时刻中redis的数据，这种多个数据文件的方式，特别适合做冷备。<br>
2.RDB对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。<br>
3.相对于AOF来说，直接基于RDB来重启和恢复redis进程，更加快速<br>
AOF存放的是指令日志，做数据恢复的时候，其实要回放和执行所有指令日志，来恢复出来内存中的所有数据。<br>
RDB，就是一份数据文件，恢复的时候，直接加载到内存中即可</p>
<p>一般不要让redis的RDB间隔时间太长</p>
<h5 id="aof持久化机制">AOF持久化机制</h5>
<p>AOF持久化机制原理介绍：AOF机制对每条写入命令作为日志，以append-only的模式写入os cache 中，fsync 在将os cache数据输入缓存一个日志文件中，在redis重启的时候，<br>
可以通过回放AOF日志中的写入命令来重构整个数据集。<br>
如果我们想要redis仅仅作为纯内存的缓存来使用，那么可以禁止RDB和AOF所有持久化机制<br>
如果想要同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重构数据，因为AOF的数据更加完整<br>
缺点：<br>
优点：1.更好的保证数据不丢失，即使redis进程挂了，最多丢失1m的数据<br>
2.AOF日志文件以append-only模式写入，写入性能非常高<br>
3.AOF日志文件即使过大，出现后台重写操作，也不会影响客户端读写，因为在rewrite log的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来，<br>
在创建新日志文件的时候，老日志文件还是照常写入，当新的merge后日志文件ready的时候，再交换新老日志文件即可</p>
<p>RDB和AOF如何选择：<br>
redis是支持两种模式的持久化</p>
<h4 id="redis主从">Redis主从</h4>
<p>redis replication --&gt;  主从架构---&gt;读写分离---&gt;水平扩容支持高并发<br>
读多写少：</p>
<pre><code>一主多从，主负责写，并且将数据同步复制到其它slave节点，从节点负责读，所有的读请求全部走slave。
进行扩容的
</code></pre>
<p>redis replication的核心机制：</p>
<pre><code>    1.redis采用异步方式复制数据到slave节点，不过从redis 2.8开始，slave节点会周期性的确认自己每次复制数据量
    2.一个master 可以配置多个slave node 
    3.slave node也可以连接其它slave node 
    4.slave node做复制的时候是不会block master node 的正常工作的
    5.slave node在做复制的时候是不会block对自己的查询操作，它会用旧的数据集提供服务，但是复制完成时候，需要删除旧的数据集，加载新的数据集，这个时候会暂停对外的服务。
    6.slave node主要是用来做横向扩容的，增加slave node可以提高吞吐量
</code></pre>
<p>master 持久化对于主从架构安全保障的意义</p>
<pre><code>如果采用了主从架构，那么建议开启master node持久化

master 节点如果没有开启持久化机制，redis宕机之后，恢复时数据就是空的，同步到时候slave node数据也是空的，数据100%丢失。
</code></pre>
<p>redis主从复制的原理、断点续传、无磁盘化复制、过期key处理<br>
1.redis主从复制的原理</p>
<pre><code>    当启动一个slave node的时候，它会发送一个fsync命令给master node ，
    如果是slave node重新连接master node，那么master node仅仅会复制给slave node部分缺少的数据。
    否则，如果是slave node第一次连接master node，那么会触发一次full resynchronized
    
    开始full resynchronized的时候，master会启动一个后台线程，开始生成一份rdb快照，同时还会将客户端的所有写命令缓存到内存中，RDB
    生成完成之后，master 会讲这个rdb发送给slave ，slave先写入到本地磁盘，然后加载到内存，然后master会讲内存中的缓存写命令发送给slave，
    slave node也会同步这些数据
</code></pre>
<p>2.redis的断点续传</p>
<pre><code>    从redis2.0开始就支持断点续传，如果主从复制的过程中，网络连接突然断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头复制一份。
    master node会在内存中保存一个backlog，master和slave都会保存一个replica offset 还有一个master node id，
    offset就是保存在backlog中，如果master和slave node网络突然断掉了，slave node会让master node从上次replica offset开始继续复制
    但是如果没有找到对应的offset，那么会执行一次resynchronized
</code></pre>
<p>3.无磁盘化复制</p>
<pre><code>RDB在内存中直接创建rdb，然后发送给slave，不会在自己本地落磁盘了
</code></pre>
<p>4.过期key处理</p>
<pre><code>slave不会过期key，只会等待master过期key，如果msater过期了一个key或者通过lru淘汰了一个key，那么会模拟一条del 命令发送给slave。
</code></pre>
<h4 id="redis哨兵">Redis哨兵</h4>
<p>sentinal，中文名是哨兵，<br>
哨兵是redis集群架构中的一个非常重要的组建，主要功能如下<br>
(1).集群监控，负责监控redis master node和slave node进程是否正常工作<br>
(2).消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员<br>
(3).故障转移，如果master node挂掉了，那么会自动转移到slave node<br>
(4).配置中心，如果故障转移发生了，通知client客户端新的master上</p>
<p>哨兵本身也是分布式的，作为哨兵集群去运行，互相协同工作<br>
(1).故障转移时，判断一个master node是宕机了，需要大部分哨兵都同意才行，涉及到分布式选举到问题<br>
(2).即使部分哨兵节点挂掉了，哨兵集群还能正常工作，如果一个作为高可用的机制的重要组成部分故障转移系统本身是单点的，那就很坑爹了</p>
<p>目前采用的是sentinal 2版本，sentinal2 相对于sentinel 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加的健壮和简单</p>
<p>2.哨兵的核心知识</p>
<pre><code>(1).哨兵至少需要3个实例，来保证自己的健壮性
(2).哨兵+redis的主从架构，是不会保证数据0丢失的，只能保证redis集群的高可用
(3).对于哨兵+redis这种主从复杂的部署架构，尽量在测试和生产环境，都进行充足的测试和演练
</code></pre>
<p>3.为什么redis哨兵集群只有两个节点时无法正常工作</p>
<pre><code>哨兵集群必须部署2个以上的节点
如果哨兵集群仅仅部署了2个哨兵实例，quorum =1 ：表示有（1）多少个哨兵觉得master宕机了，就可以进行切换了，这个时候会尝试进行故障转移
M1       R1 
S1       S2

master宕机，s1和s2中只要有1个哨兵认为master宕机，就可以进行切换，同时s1  和s2中会选举出一个哨兵
来执行故障转移
同时这个时候，需要majority =2,也就是大多数哨兵是运行的，2个哨兵的majority就是2，2个哨兵都运行着，就可以允许故障转移

但是如果整个m1和s1运行的机器宕机了，那么哨兵只要一个了，此时就没有majority来允许执行故障转移了
虽然还有一台机器r1，但是故障转移不会执行
</code></pre>
<p>经典的3个哨兵集群</p>
<pre><code>M1       R1      R2
S1       S2      S3
quorum =2 表示有（2）多少个哨兵觉得master宕机了，就可以进行切换了，这个时候会尝试进行故障转移
majority =2 2个哨兵的majority就是2，2个哨兵都运行着，就可以允许故障转移 ， 同时s2  和s3中会选举出一个哨兵
来执行故障转移
</code></pre>
<p>哨兵主备切换的数据丢失问题：异步复制，集群脑裂</p>
<p>异步复制导致的数据丢失问题</p>
<pre><code>这个旧的master node内存里的那些数据还没来的及给是slave node 就挂掉了。
slave node就成了master node，那些内存中没来得及复制的数据不就丢失了吗
</code></pre>
<p>集群脑裂导致的数据丢失问题</p>
<pre><code>脑裂，也就是master所在的机器突然脱离了正常的网络，跟其它slave node机器不能连接，但是实际上master node运行着，
此时哨兵可能就会认为master宕机了，然后开启选举，将其它slave node 切换成master 
这个时候，集群中就有两个master，也就是所谓的脑裂。
此时虽然某个slave node被切换成了master ，但是可能client 还没来得及切换到新的master，还继续写向旧的master，
因此旧master再次恢复的时候，会作为slave挂载到存的master上去，自己的数据会清空，重新从新的master复制数据
</code></pre>
<p>解决异步复制和脑裂导致的数据丢失问题</p>
<pre><code>    min-slaves-to-write 1 
    min-slaves-max-lag 10
    要求至少有1个slave node，复制数据和同步的延迟不超过10s
    如果说一旦所有的slave，复制数据和同步数据都超过了10s，那么这个时候master将不在接受任何请求
    以上两个配置可以减少异步复制和脑裂的数据丢失问题

    (1).减少异步复制的数据丢失问题  
    min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就可以拒绝写请求，
    这样就可以把master宕机时由于部分数据未同步到slave node导致的数据丢失降低在可控范围内。
    (2).减少脑裂的数据丢失问题
    如果一个master出现了脑裂，跟其它slave node丢了连接，那么上面的两个配置可以确保的说，如果不能继续给指定数量的slave发送数据，而且slave node
    超过10s没有给自己ack消息，那么就直接拒绝客户端的写请求
    这样脑裂后旧的master就不会接受新的client 的新数据，也就避免了数据丢失
    以上的配置就确保了，如果跟任何一个slave node丢失了连接，在10s之内发现slave没有给自己ack，那么久拒绝新的写请求
</code></pre>
<p>sdown和odown转换机制</p>
<pre><code>sdown是主观宕机，就是一个哨兵就是自己觉得一个master宕机了，那么就是主观宕机
odown是客观宕机，如果quorum数量的哨兵都觉得一个mastar宕机了，那么就是客观宕机
sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-masterHost-down-millisecondssecond
指定的毫秒数之后，就主观认为master宕机了
sdown到odown的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其它哨兵也认为那个master sdown 
那么就任务odown 
</code></pre>
<p>哨兵和slave自动发现机制</p>
<pre><code>    哨兵互相之间的发现是通过redis 的pub/sub系统实现的，每个哨兵都会放_sentinel_:hello这个
    channel里发送一个消息，这个时候其它哨兵就可以消费到这条消息，并感知其它哨兵的存在
    每隔两秒钟，每个哨兵都会往自己监控的某个master+slave对应的 _sentinel_:hello channel 里发送一个消息，
    内容是自己的host  ip 和runid，还有这个对应master的监控配置
    每个哨兵也会监听自己监控的某个master+slave对应的 _sentinel_:hello channel，然后去感知到同样在监听这个master +slave的其它哨兵的存在。
    每个哨兵还会跟其它哨兵交换对master的监控配置，互相进行监控配置的同步
</code></pre>
<p>slave --&gt; master选举算法</p>
<p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举出一个slave来<br>
会考虑slave的一些信息</p>
<pre><code>(1).跟master断开连接的时长
(2).slave node优先级
(3).run id
(4).复制的offset

接下来会对slave进行排序

（1).按照slave的优先级进行排序，slave node priority越低优先级越高
（2).如果slave node priority相同，那么看replica offset ，哪个slave复制了越多的数据，offset越靠后，优先级就越高。
 (3).如果 上面两个条件都相同，那么选择一个run id比较小的那个slave
</code></pre>
<p>slave配置的自动纠正</p>
<pre><code>哨兵会自定纠正slave的一些配置，比如slave node如果要成为潜在的master候选人，哨兵会确保slave node在复制现有master的数据
，如果slave连接到错误的master上，比如故障转移之后，哨兵会确保他们连接到正确的master上
</code></pre>
<p>quorum和majority</p>
<pre><code>每一次一个哨兵要做主备切换，首先要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，
，这个哨兵还的得到majority哨兵的授权，才能正式执行切换，
但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵quorum是5，那么必须5个哨兵都同意授权，才能进行切换。
</code></pre>
<p>configuration epoch</p>
<pre><code>哨兵会对一套redis master +slave 进行监控，有相应监控的配置
会执行切换的那个哨兵，会从要切换到新的master（slave -&gt; master）那里会得到一个configuration epoch。这就是一个version号，每次切换的version必须是唯一的。
如果第一个选举出来的哨兵都失败了，那么其它哨兵，会等待failover-timeout时间，然后接替者继续切换此时会从新获取一个新的configuration epoch
作为新的版本号
</code></pre>
<p>configuration 传播</p>
<pre><code>    哨兵切换之后，会在自己本地更新生成最新的master配置，然后同步给其它的哨兵，所以就是通过之前所说的pub/sub消息机制
    这里之前的version号就很重要了，因为各种消息是通过channel发布和监听的，所以一个哨兵完成一次新的切换之后，
    新的master配置是跟着新的version号的，其它哨兵都是根据版本号大小更新自己的master配置
</code></pre>
<h4 id="redis集群">Redis集群</h4>
<p>主从架构的缺点：master节点的数据和slave节点的数据是一摸一样的，<br>
master最大能容纳多大的数据量，那么slave最多能容纳多大数据量</p>
<p>redis Cluster 可以支持多个master ，每个master都会挂载多个slave<br>
也支持读写分离的架构，对于每个master来说，写就写到master，然后读就从master对应的slave上读<br>
高可用，因为每个master都有slave节点，那么如果master挂掉，redis cluster 会自动将slave切换成master</p>
<p>redis cluster （多master+读写分离+高可用）</p>
<p>Redis cluster 主要针对海量数据+高并发+高可用的场景</p>
<p>Redis cluster介绍</p>
<pre><code>(1).自动将数据分片，每个master上放一部分数据
(2).提供内置的高可用支持，部分master不可用时，还可以继续工作
在redis cluster架构下，每个redis要开放两个端口号，一个是6379 另一个是加10000的端口号16379。
16379端口号是用于节点间通信的，也就是cluster bus的东西，集群总线，cluster bus的通信，用于进行故障检验，配置更新
故障转移授权
</code></pre>
<p>redis 数据分布算法<br>
1.hash算法<br>
2.一致性hash算法</p>
<h3 id="redis双写一致性">Redis双写一致性</h3>
<p>1.读的时候，先读缓存，缓存没有，在读数据库，设置缓存<br>
2.更新时候，先删除缓存，然后在更新数据库<br>
如果直接更新缓存，在更新数据库，如果在更新缓存的成功了，更新数据库失败了，下次读取的时候，直接读缓存，那么数据还是旧数据，缓存和数据库不一致</p>
<h3 id="redis缓存雪崩-穿透-击穿">Redis缓存雪崩、穿透、击穿</h3>
<h4 id="缓存雪崩">缓存雪崩，</h4>
<pre><code>是指缓存机器意外发生了全盘宕机，缓存挂了，导致请求全部落在数据库，数据库也支撑不住。
</code></pre>
<p>解决方案如下：<br>
事前：redis高可用，主从+哨兵，redis cluster避免全盘数据崩溃<br>
事中：本地缓存+hystrix限流降级，避免mysql被打死<br>
事后：redis持久化，一旦重启，自动从磁盘中加载数据到缓存，快速恢复缓存数据</p>
<h4 id="缓存穿透">缓存穿透</h4>
<pre><code>很多请求是黑客恶意发送的，缓存中查不到，每次去数据库也查不到
，这种恶意的请求就直接把数据库打死
</code></pre>
<p>解决办法；<br>
只要数据库没查到，就设置一个空值到缓存，返回设置一个过期时间，这样的话，下次有相同的key</p>
<h4 id="缓存击穿">缓存击穿</h4>
<pre><code>    某个key非常热点，访问非常频繁，处于集中式高并发访问的情况
    当这个key在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库
</code></pre>
<p>解决方案如下：</p>
<pre><code>    可以将热点数据设置为永远不过期，或者基于redis or zookeeper实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而
    其它请求也能通过该key访问数据
</code></pre>
<h4 id="redis分布式锁的实现原理">Redis分布式锁的实现原理</h4>
<p>如果说公司里落地生产环境用分布式锁的时候，一般都会使用开源类库，比如redis的分布式锁，一般就是用redisson框架就好了，非常简单易用。</p>
<pre><code class="language-java">
 /**
   * @author ChengJianSheng
   * @date 2019-07-30
   */
    @Slf4j
   @Service
  public class OrderServiceImpl implements OrderService {
     @Autowired
     private StockService stockService;
     @Autowired
     private OrderRepository orderRepository;
     @Autowired
     private RedissonClient redissonClient;
     /**
       * 乐观锁
       */
             @Override
     public String save(Integer userId, Integer productId) {
                 int stock = stockService.getByProduct(productId);
                 log.info(&quot;剩余库存：{}&quot;, stock);
                 if (stock &lt;= 0) {
                         return null;
                 }
                 //  如果不加锁，必然超卖
                 RLock lock = redissonClient.getLock(&quot;stock:&quot; + productId);
                 try {
                         lock.lock(10, TimeUnit.SECONDS);
                         //扣减库存
                        redissonClient.decr();
                         String orderNo = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;).toUpperCase();
                         if (stockService.decrease(productId)) {
                                 OrderModel orderModel = new OrderModel();
                                 orderModel.setUserId(userId);
                                 orderModel.setProductId(productId);
                                 orderModel.setOrderNo(orderNo);
                                 Date now = new Date();
                                 orderModel.setCreateTime(now);
                                 orderModel.setUpdateTime(now);
                                 orderRepository.save(orderModel);
                                 return orderNo;
                             }
            
                     } catch (Exception ex) {
                         log.error(&quot;下单失败&quot;, ex);
                     } finally {
                         lock.unlock();
                     }
        
                 return null;
             }
         }

</code></pre>
<p>⼆、Redisson 实现 Redis 分布式锁的底层原理</p>
<p>（1）加锁机制<br>
首先一个客户端1会hash算法，选择一台机器，紧接着发送一段lua脚本到redis上<br>
<img src="img_1.png" alt="img_1.png" loading="lazy">，<br>
这一段脚本就是保证复杂业务的原子性，</p>
<p>RLock lock = redisson.getLock(&quot;myLock);<br>
先会走一个判断 exists mylock，如果你要加的那个锁的那个key不存在的话你就执行加锁</p>
<pre><code>hset mylock 客户端id：1 1
如果出现了一个这样的数据结构说明加锁成功
</code></pre>
<p>（2）锁互斥机制<br>
同样客户端过来尝试加锁，执行一段同样的lua脚本，会咋样？<br>
先会走一个判断 exists mylock，如果你要加的那个锁的那个key不存在的话你就执行加锁<br>
发现myLock这个锁key已经存在了。</p>
<pre><code>接着走第二个if判断，判断一下myLock锁key的hash数据结构中，是否包含了客户端2 的id 
但是很明显，那里只包含了客户端1的id
所以客户端2 会获取到pttl myLock返回一个数字，这个数字代表了myLock这个锁key的剩余生存是时间，比如还剩15000 毫秒的生存时间
此时客户端2 ，会进入一个while循环，不停的尝试加锁
</code></pre>
<p>（3）watch dog ⾃动延期机制</p>
<pre><code>客户端1加锁的锁key默认生存时间才30s，如果超过了30s，客户端1还想持有这把锁怎么办？
简单，客户端1一旦加锁成功，就会启动一个watch dog 看门狗，它是一个后台线程，会每隔10s检查一下
如果客户端1还持有锁key，那么就会不断延长锁key的生存时间
</code></pre>
<p>（4）可重⼊加锁机制<br>
如果客户端1已经持有了锁，再次加锁，依然执行命令，加锁次数累计加1</p>
<p>（5）锁释放机制<br>
如果执行lock.unLock()，就可以释放分布式锁，此时的业务逻辑也非常简单<br>
其实说白了，就是每次都对myLock数据结构的那个加锁次数减1。<br>
如果发现加锁次数是0了，那么说明客户端不再持有锁了，此时就会用<br>
del mylock 命令，从redis里面删除这个key</p>
<p>（6）此种⽅案 Redis 分布式锁的缺陷</p>
<pre><code>其实上⾯那种⽅案最⼤的问题，就是如果你对某个 redis master 实例，写⼊了 myLock 这种锁 key 的 value，此时会异步复制给对应的 master slave 实例。
但是这个过程中⼀旦发⽣ redis master 宕机，主备切换，redis slave 变为了 redis master。 接着就会导致，客户端 2 来尝试加锁的时候，在新的 redis master 上完成了加锁，⽽客户端 1
也以为⾃⼰成功加了锁。 此时就会导致多个客户端对⼀个分布式锁完成了加锁。 这时系统在业务语义上⼀定会出现问题，导致各种脏数据的产⽣。 
所以这个就是 redis cluster，或者是 redis master-slave 架构的主从异步复制导致的 redis 分布式 锁的最⼤缺陷：在 redis master 实例宕机的时候，可能导致多个客户端同时完成加锁。
</code></pre>
<figure data-type="image" tabindex="1"><img src="img.png" alt="img.png" loading="lazy"></figure>
<h3 id="redis实战">Redis实战</h3>
<h4 id="string">String</h4>
<h5 id="setnxredis分布式锁实现">Setnx(redis分布式锁实现)</h5>
<pre><code>分布式锁
命令：
set mykey newval nx
set mykey newval xx

java：
//加锁
jedis.set(&quot;locks_test&quot;, &quot;value_test&quot;,SetParams.setParams().nx())
//释放锁
jedis.del(&quot;locks_test&quot;);
必须是这个key此时是不存在的，才能设置成功，如果说key要是存在了，此时设置失败
</code></pre>
<h5 id="msetmgetmsetnx">mset,mget,msetnx</h5>
<pre><code>命令
mset a 10 b 20 c 30
mset a 10 b 20 c 30

java 
mset:一下子设置多个key-value对
mget:一下子获取多个key的value 
msetnx:就是多个key都不存在的情况下，一次性设置多个key的value,只要key都不存在才能成功
mset和mgt相当于batch批量设置和查询，比如说加入你要一次性要往redis里塞入
20条数据
//新增或修改
jedis.mset(&quot;key:key&quot;,&quot;value&quot;,&quot;key:key1&quot;,&quot;value2&quot;)
//新增，key不能存在
jedis.msetnx(&quot;key:key&quot;,&quot;value&quot;,&quot;key:key1&quot;,&quot;value2&quot;)
//获取
jedis.mget(&quot;key:key&quot;,&quot;key:key1&quot;)
// 获取value长度
jedis.strlen(&quot;key:key&quot;)
//截取 value的字符
jedis.getrange(&quot;key:key&quot;，0，5)
</code></pre>
<h5 id="append">append</h5>
<pre><code>日志审计
redis append api 就是不停的把数据追加到指定的key里去
jedis.append(key,value);
</code></pre>
<h5 id="incr">incr</h5>
<pre><code>生成唯一id/（点赞）
命令：
set counter 100
incr counter
incrby counter 50

INCR 命令将字符串值解析成整型，将其加一，最后将结果保存为新的字符串值，类似的命令有INCRBY, DECR 和 DECRBY。实际上他们在内部就是同一个命令，只是看上去有点儿不同。
INCR是原子操作意味着什么呢？就是说即使多个客户端对同一个key发出INCR命令，也决不会导致竞争的情况。例如如下情况永远不可能发生：『客户端1和客户端2同时读出“10”，他们俩都对其加到11，然后将新值设置为11』。最终的值一定是12，read-increment-set操作完成时，其他客户端不会在同一时间执行任何命令。
对字符串，另一个的令人感兴趣的操作是GETSET命令，行如其名：他为key设置新值并且返回原值。这有什么用处呢？例如：你的系统每当有新用户访问时就用INCR命令操作一个Redis key。你希望每小时对这个信息收集一次。你就可以GETSET这个key并给其赋值0并读取原值。

java
jedis.incr(&quot;key&quot;);
</code></pre>
<h5 id="decr">decr</h5>
<pre><code>抢购
命令：
set counter 100
自增
incr counter
</code></pre>
<h5 id="exists">exists</h5>
<pre><code>命令
exists mykey
EXISTS命令返回1或0标识给定key的值是否存在
</code></pre>
<h5 id="del">del</h5>
<pre><code>使用DEL命令可以删除key对应的值，DEL命令返回1或0标识值是被删除(值存在)或者没被删除(key对应的值不存在)。
</code></pre>
<h5 id="type">type</h5>
<pre><code>TYPE命令可以返回key对应的值的存储类型：
命令
type mykey
</code></pre>
<h5 id="expire">EXPIRE</h5>
<pre><code>EXPIRE来设置超时时间(也可以再次调用这个命令来改变超时时间，使用PERSIST命令去除超时时间 )。
命令
set key some-value
expire key 5
也可以在创建值的时候设置超时时间:
set key 100 ex 10

TTL命令用来查看key对应的值剩余存活时间。
ttl key
</code></pre>
<h4 id="hash">hash</h4>
<p>Hash 便于表示 objects，实际上，你可以放入一个 hash 的域数量实际上没有限制（除了可用内存以外）。所以，你可以在你的应用中以不同的方式使用 hash</p>
<h5 id="hsethget">hset,hget</h5>
<pre><code>值得注意的是，小的 hash 被用特殊方式编码，非常节约内存。
# 获取
hget user:1000 username
hgetall user:1000
hmget user:1000 username birthyear no-such-field
# 将value +10
hincrby user:1000 birthyear 10

HMSET 指令设置 hash 中的多个域，而 HGET 取回单个域。HMGET 和 HGET 类似，但返回一系列值：



基于token令牌的登陆会话机制：
用户平时在访问我们的系统，在处理任何一个请求之前，必须检查这个请求是否带上了一个令牌，
如果带上了这个令牌，那么此时必须在redis里检查一下，这个令牌是否在redis里合法，有效的session会话。

如果有这个session会话，那么此时可以允许这个请求被处理，说明这个人已经登陆过我们的系统，登陆之后在会在
redis里放一个有效的session会话，
如果说没有这个session会话，此时就会导致用户被迫强制登陆
如果用户登陆之后，就会返回浏览器或者客户端一块令牌，同时在redis里初始化ession会话，后续客户端
就会在指定时间范围内发送请求的时候，带上一块令牌，每次令牌和服务端的session校验通过就可以执行请求
过一段时间过后，服务端的redis里的session会话就会过期，过期之后又回导致你重新登陆。
</code></pre>
<h4 id="list">list</h4>
<p>常用案例</p>
<pre><code>秒杀活动下利用公平队列的抢购机制   待办事项  

秒杀系统有很多实现方式，其中一种技术方案，就是对所有涌入系统的秒杀抢购请求，都放入redis里的一个linhuatest
数据结构中去，进行公平队列排队，然后入队之后等待秒杀结果，专门搞一个消费者从redis 里面按顺序
获取抢购请求，按顺序进行库存扣减，扣减成功了，就让抢购成功。

如果说你要是不要公平队列的话，可能会导致你很多抢购请求进来，大家都在尝试去扣减库存
 此时可能先涌入进来的请求并没有先对redis进行抢购请求，此时可能后进入的请求先执行了抢购请求，此时就是不公平的

公平队列：基于redis里的list数据结构，搞一个队列，抢购请求先进队列，先入先出，先进来的人先抢购，此时就是公平的。

对于抢购队列，就用lpush list 就可以了，然后对出队的队列进行抢购
</code></pre>
<h5 id="lpush">lpush</h5>
<pre><code> LPUSH 命令可向list的左边（头部）添加一个新元素，而RPUSH命令可向list的右边（尾部）添加一个新元素。最后LRANGE 命令可从list中取出一定范围的元素:
//从左边(头部)添加元素
lpush mylist A
//从右边(尾部)添加元素
rpush mylist A
//从尾部开始，指定范围获取元素
lrange mylist 0 -1

注意:LRANGE 带有两个索引，一定范围的第一个和最后一个元素。这两个索引都可以为负来告知Redis从尾部开始计数，因此-1表示最后一个元素，-2表示list中的倒数第二个元素，以此类推。

rpop mylist
lpop mylist
pop,它从list中删除元素并同时返回删除的值。可以在左边或右边操作



List上的阻塞操作
可以使用Redis来实现生产者和消费者模型，如使用LPUSH和RPOP来实现该功能。但会遇到这种情景：list是空，这时候消费者就需要轮询来获取数据，这样就会增加redis的访问压力、增加消费端的cpu时间，而很多访问都是无用的。
 为此redis提供了阻塞式访问 BRPOP 和 BLPOP 命令。 消费者可以在获取数据时指定如果数据不存在阻塞的时间，如果在时限内获得数据则立即返回，如果超时还没有数据则返回null, 0表示一直阻塞。

同时redis还会为所有阻塞的消费者以先后顺序排队。

如需了解详细信息请查看 RPOPLPUSH 和 BRPOPLPUSH。
</code></pre>
<h5 id="brpop-blpop">BRPOP BLPOP</h5>
<pre><code>BRPOP 是一个阻塞的列表弹出原语。 它是 RPOP 的阻塞版本，因为这个命令会在给定list无法弹出任何元素的时候阻塞连接。 该命令会按照给出的 key 顺序查看 list，并在找到的第一个非空 list 的尾部弹出一个元素。

请在 BLPOP 文档 中查看该命令的准确语义，因为 BRPOP 和 BLPOP 基本是完全一样的，除了它们一个是从尾部弹出元素，而另一个是从头部弹出元素。

BRPOP list1 list2 0

返回值
多批量回复(multi-bulk-reply): 具体来说:

当没有元素可以被弹出时返回一个 nil 的多批量值，并且 timeout 过期。
当有元素弹出时会返回一个双元素的多批量值，其中第一个元素是弹出元素的 key，第二个元素是 value。
</code></pre>
<h5 id="rpoplpush-brpoplpush">RPOPLPUSH BRPOPLPUSH</h5>
<h5 id="lindex-lset-linsert-ltrim-lrem">LINDEX LSET LINSERT LTRIM LREM</h5>
<pre><code>LINDEX：返回指定位置的数据
LSET：设置指定位置的数据
LINSERT：往指定位置插入数据
LTRIM：然后保留指定的数据，删掉一些数据
LREM：删掉一些数据
</code></pre>
<h4 id="set">set</h4>
<pre><code>案例 抽奖  公共关注  推荐关注 微博关系 点赞 uv
无序且不重复的数据集合
</code></pre>
<h5 id="sadd">sadd</h5>
<pre><code> 添加元素
 sadd myset 1 2 3

返回所以元素
smembers myset


现在我已经把三个元素加到我的 set 中，并告诉 Redis 返回所有的元素。可以看到，它们没有被排序 —— Redis 在每次调用时可能按照任意顺序返回元素，因为对于元素的顺序并没有规定。

判断元素是否存在
sismember myset 30

返回所以元素
srem myset

取交集
sinter tag:1:news tag:2:news tag:10:news tag:27:news 

对多个集合取并集
sunionstore game:1:deck deck

取差集
sdiffstore new——set  set1 set2

获取随机元素

spop game:1:deck   随机从set里弹出几个元素

srandmember
</code></pre>
<h5 id="scard">scard</h5>
<pre><code> scared 获取key数据总数
</code></pre>
<h4 id="sorted-set">sorted set</h4>
<pre><code>案例  推荐商品  排行榜  自动补全

sorted set不能又重复数据，加入进去的每一个数据都可以带一个分数，它在里面的数据都是按照分数排序的、
有序的set 自动按照分数来排序，相当于你可以定制它的排序规则

添加
zadd hackers 1940 &quot;Alan Kay&quot;

查询   从索引0 到最后一个元素 分数排序
zrange hackers 0 -1

如果我想按相反的顺序，从最小的到最大的顺序，怎么办？使用ZREVRANGE而不是ZRANGE：
zrevrange hackers 0 -1

询问元素在有序元素集中的位置
zrank hackers &quot;Anita Borg&quot;


搜索结果返回分数
zrange hackers 0 -1 withscores
zrevrange hackers 0 -1 withscores

搜索指定分数范围内的数据
zrangebyscore hackers -inf 1950

根据指定分数搜索后删除
zremrangebyscore hackers 1940 1960

ZRANGEBYLEX，我们可以查询字典范围：
zrangebylex hackers [B [P

将分数自增
zincrby
</code></pre>
<h4 id="hyperloglog">HyperLoglog</h4>
<pre><code>案例  日活 网站垃圾数据去重或者过滤

HyperLoglog ，数据结构+概率算法 组合而成的，去重统计 近似数

 如果基于set来计数，太耗费内存，基于HyperLoglog算法来计数，是近似数，有
  0.8%误差，但是误差不会太大，可以给出一个相对准确的近似数，而且就占12KB内存

每次看到新元素时，都要使用PFADD将其添加到计数中。
pfadd hll a b c d 
    
每次要检索迄今为止使用PFADD添加的唯一元素的当前近似值时，都要使用PFCOUNT
pfcount hll


pfmerge  
</code></pre>
<h4 id="bitmap">bitmap</h4>
<pre><code>bitmap位图：二进制里的一位一位的，字符串，int ，long double 都可以用二进制表示
在二进制中都是表示多少位，一个字节是8位的二进制数
int 就是四个字节 就是32位
我可以直接在redis里操作二进制的位数据。

可以把网站里的每一种操作，每天执行过的用户放在一个位图里，
一个用户仅仅代表一位而已

案例 ：基于位图用户行为记录程序
如果说你要记录一下，在系统里执行一些特殊操作，每天执行过某个操作的用户有多少个人
操作日志，审计日志，
记录下来每个用户每天做了哪些操作

 设置位图
 setbit key offset 1
 表示把 这个offset 对应位图的位置设置位1

getbit key value
</code></pre>
<h4 id="geohash">GeoHash</h4>
<pre><code>geoadd key longitude latitude user 
geoadd key longitude latitude shop 
geodist key user shop init ='KM'_ 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/mysql/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/mysql/">
        </link>
        <updated>2022-04-08T13:18:19.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mysql">mysql</h1>
<h2 id="目录">目录</h2>
<ul>
<li>
<p><a href="#Mysql%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84">mysql基础架构</a></p>
<ul>
<li><a href="#Mysql%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1">mysql架构设计</a></li>
<li><a href="#InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1">InnoDB存储引擎的架构设计</a>
<ul>
<li>[buffer pool](#buffer pool)</li>
<li>[redo log](#redo log)</li>
<li>[undo log](#undo log)</li>
</ul>
</li>
<li><a href="#%E4%BA%8B%E5%8A%A1">事务</a>
<ul>
<li><a href="#%E5%A4%9A%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E6%88%96%E8%80%85%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98">多事务并发更新或者查询的数据问题</a>
<ul>
<li><a href="#%E8%84%8F%E5%86%99">脏写</a></li>
<li><a href="#%E8%84%8F%E8%AF%BB">脏读</a></li>
<li><a href="#%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB">不可重复读</a></li>
<li><a href="#%E5%B9%BB%E8%AF%BB">幻读</a></li>
</ul>
</li>
<li><a href="#SQL%E6%A0%87%E5%87%86%E4%B8%AD%E5%AF%B9%E4%BA%8B%E5%8A%A1%E7%9A%844%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">SQl对事务的四种隔离级别</a>
<ul>
<li><a href="#%E8%AF%BB%E6%9C%AA%E6%8F%90%E4%BA%A4">read uncommitted</a></li>
<li><a href="#%E8%AF%BB%E5%B7%B2%E6%8F%90%E4%BA%A4">read committed</a></li>
<li><a href="#%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB">repeatable</a></li>
<li><a href="#%E4%B8%B2%E8%A1%8C%E5%8C%96">serializable</a></li>
</ul>
</li>
<li><a href="#%E9%80%8F%E5%BD%BB%E5%89%96%E6%9E%90Mysql%E7%9A%84MVCC%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6">透彻剖析Mysql的MVCC事务隔离机制</a>
<ul>
<li>[undo log版本链](#Undo log版本链)</li>
<li><a href="#ReadView%E6%9C%BA%E5%88%B6">ReadView机制</a></li>
<li>[Read Committed隔离级别是如何基于ReadView机制实现的？](#Read Committed隔离级别是如何基于ReadView机制实现的？)</li>
<li><a href="#MySQL%E6%9C%80%E7%89%9B%E7%9A%84RR%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%EF%BC%8C%E6%98%AF%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8EReadView%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F">MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？</a></li>
</ul>
</li>
<li><a href="#%E5%A4%9A%E4%B8%AA%E4%BA%8B%E5%8A%A1%E6%9B%B4%E6%96%B0%E5%90%8C%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%97%B6%EF%BC%8C%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E9%94%81%E9%81%BF%E5%85%8D%E8%84%8F%E5%86%99%E7%9A%84%EF%BC%9F">多个事务更新同一行数据时，是如何加锁避免脏写的？</a>
<ul>
<li><a href="#%E5%85%B1%E4%BA%AB%E9%94%81">共享锁</a></li>
<li><a href="#%E7%8B%AC%E5%8D%A0%E9%94%81">独占锁</a></li>
</ul>
</li>
<li><a href="#%E7%B4%A2%E5%BC%95">索引</a>
<ul>
<li><a href="#%E7%A3%81%E7%9B%98%E4%B8%8A%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">磁盘上数据页的存储结构</a></li>
<li><a href="#%E9%A1%B5%E5%88%86%E8%A3%82%E7%9A%84%E8%BF%87%E7%A8%8B">页分裂的过程</a></li>
<li><a href="#%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95">主键索引</a></li>
<li><a href="#B+%E6%A0%91%E5%AE%9E%E7%8E%B0%E7%B4%A2%E5%BC%95%E7%9A%84%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84">B+树实现索引的物理结构</a></li>
<li><a href="#%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95">聚簇索引</a></li>
<li><a href="#%E9%92%88%E5%AF%B9%E4%B8%BB%E9%94%AE%E4%B9%8B%E5%A4%96%E7%9A%84%E5%85%B6%E4%BB%96%E5%AD%97%E6%AE%B5%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8E%9F%E7%90%86">针对主键之外的其他字段建立索引的原理</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">索引的优缺点</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E5%88%99">索引的使用规则</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99">索引的设计规则</a></li>
<li><a href="#%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92">执行计划</a></li>
<li><a href="#sql%E8%B0%83%E4%BC%98">sql调优</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#mysql%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B">mysql数据模型</a>
<ul>
<li><a href="#VARCHAR%E8%BF%99%E7%A7%8D%E5%8F%98%E9%95%BF%E5%AD%97%E6%AE%B5%EF%BC%8C%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E5%88%B0%E5%BA%95%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84">VARCHAR这种变长字段，在磁盘上到底是如何存储的</a></li>
<li><a href="#%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E5%A4%9A%E4%B8%AANULL%E5%AD%97%E6%AE%B5%E5%80%BC%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%EF%BC%9F">一行数据中的多个NULL字段值在磁盘上怎么存储？</a></li>
<li><a href="#%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E4%B8%AD40%E4%B8%AAbit%E4%BD%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%B4%E4%BB%A5%E5%8F%8A%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84%EF%BC%9F">磁盘文件中40个bit位的数据头以及真实数据是如何存储的？</a></li>
<li><a href="#%E8%A1%8C%E6%BA%A2%E5%87%BA">行溢出</a></li>
<li><a href="#%E8%A1%A8%E7%A9%BA%E9%97%B4">表空间</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5">生产实践</a></p>
<ul>
<li><a href="#%E7%9C%9F%E5%AE%9E%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%BA%E5%99%A8%E9%85%8D%E7%BD%AE%E5%A6%82%E4%BD%95%E8%A7%84%E5%88%92%EF%BC%9F">真实生产环境下的数据库机器配置如何规划？</a></li>
<li><a href="#%E4%BA%92%E8%81%94%E7%BD%91%E5%85%AC%E5%8F%B8%E7%9A%84%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%9A%84%EF%BC%9F%EF%BC%9F">互联网公司的生产环境数据库是如何进行性能测试的？</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E5%AF%B9%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C360%E5%BA%A6%E6%97%A0%E6%AD%BB%E8%A7%92%E5%8E%8B%E6%B5%8B%EF%BC%9F">如何对生产环境中的数据库进行360度无死角压测？</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%B8%BA%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E9%83%A8%E7%BD%B2%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%EF%BC%9F">如何为生产环境中的数据库部署监控系统？</a></li>
<li>[如何通过多个Buffer Pool来优化数据库的并发性能？](#如何通过多个Buffer Pool来优化数据库的并发性能？)</li>
<li>[如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？](#如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？)</li>
<li>[在生产环境中，如何基于机器配置来合理设置Buffer Pool？](#在生产环境中，如何基于机器配置来合理设置Buffer Pool)</li>
<li><a href="#Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%B1%82%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E4%BB%A5%E5%8F%8AIO%E8%B0%83%E5%BA%A6%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86">Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E7%9A%84RAID%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E5%88%9D%E6%AD%A5%E4%BB%8B%E7%BB%8D">数据库服务器使用的RAID存储架构初步介绍</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84RAID%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E7%94%B5%E6%B1%A0%E5%85%85%E6%94%BE%E7%94%B5%E5%8E%9F%E7%90%86">数据库服务器上的RAID存储架构的电池充放电原理</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E6%95%85%E9%9A%9C%E7%9A%84%E5%AE%9A%E4%BD%8DToomanyconnections">数据库无法连接故障的定位，Too many connections</a></li>
<li><a href="#%E7%BA%BF%E4%B8%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%80%A7%E8%83%BD%E6%8A%96%E5%8A%A8%E4%BC%98%E5%8C%96">线上数据库不确定性的性能抖动优化</a></li>
</ul>
</li>
<li>
<p><a href="#mysql%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84">mysql主从架构</a></p>
<ul>
<li><a href="#%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8E%9F%E7%90%86">主从架构的原理</a></li>
<li><a href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%E7%9A%84%E6%90%AD%E5%BB%BA">主从复制架构的搭建</a></li>
<li><a href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%95%B0%E6%8D%AE%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98">主从复制数据延迟问题</a></li>
<li><a href="#%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84">高可用架构</a></li>
<li><a href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">分库分表</a></li>
</ul>
</li>
</ul>
<h1 id="目录-2">目录</h1>
<h2 id="mysql基础架构">Mysql基础架构</h2>
<h3 id="mysql架构设计">Mysql架构设计</h3>
<p>一个不变的原则：网络连接必须让线程处理 mysql架构的整体设计原理<br>
<img src="image/mysqlshejiyuanli.png" alt="img_1.png" loading="lazy"></p>
<h3 id="innodb存储引擎的架构设计">InnoDB存储引擎的架构设计</h3>
<figure data-type="image" tabindex="1"><img src="image/InnoDByuanlli.png" alt="img.png" loading="lazy"></figure>
<p>实际上，执行器是非常核心的一个组件，负责跟存储引擎配合完成一个sql语句在磁盘与内存层面的全部数据更新操作。</p>
<p>拆分成两个阶段：</p>
<p>上图的1，2，3，4是执行更新语句的时候干的事， 5，6是从你提交事务开始的，属于提交事务阶段</p>
<pre><code>redo log 是一种偏向物理性值的重做日志，本身属于InnoDB存储引擎特有的一个东西。

redo log 主要记录下你对数据做了哪些修改，这个此时还在内存缓存区

bin log 叫做归档日志，它里面记录的时偏向逻辑性的日志，类似  对users 表中的id =10的一行数据，进行了更新操作，操作以后的值是什么   

bin log 日志不是InnoDB 存储引擎特意的日志文件，是属于 mysql server 自己的日志文件
</code></pre>
<p>提交事务时，redo log日志的刷盘策略：</p>
<pre><code>  这个策略通过innodb_flush_log_at_trx_commit 来配置
  0：提交事务的时候，不会把redo log buffer 里的数据刷入磁盘文件，此时你可能提交事务了，结果mysql宕机了，此时内存中的数据全部丢失。
  1：提交事务的时候，就必须把redo log 从内存中刷入到磁盘文件里去，只要事务提交成功，那么redo log 就必然在磁盘里。
  2：提交事务的时候，把redo日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件，可能1s之后才会把os cache里的数据写入到磁盘文件
</code></pre>
<p>对于数据库这种严格的系统而言，一般建议redo 日志刷盘策略设置为1，保证事务提交之后，数据绝对不能丢失</p>
<p>提交事务时，bin log日志的刷盘策略：</p>
<pre><code>  这个策略通过sync_binlog参数来控制binlog的刷盘策略，它的默认值是0
  0:提交事务的时候，新进入 os cache 内存缓存，后刷回到磁盘（bin log会丢失）
  1:提交事务的时候，强制把binlog直接写入磁盘文件里去（bin log不会丢失）
</code></pre>
<h4 id="buffer-pool">buffer pool</h4>
<figure data-type="image" tabindex="2"><img src="image/bufferpool.png" alt="img_1.png" loading="lazy"></figure>
<p>数据库buffer pool 里面会包含很很多个缓存页，同时每个缓存页还有一个数据描述，也可以叫做数据控制</p>
<p>初始化buffer pool</p>
<pre><code>数据库只要已启动，就会按照你设置的buffer pool 的大小稍微再加大一点去找操作系统申请一块内存区域，作为buffer pool的内存区域

然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16kb的大小以及对应800个字节左右的描述数据的大小，在buffer pool 中划分出来一个个缓存页和一个个对应的数据描述

只不过这个时候，buffer pool中一个个缓存页的都是空的，里面什么都没有，要等数据库运行起来，我们对数据进行增删改查的操作的时候，才会把数据对应的磁盘文件读取出来，放入buffer pool 的缓存页
</code></pre>
<p>哪些缓存页是空闲的？ free链表</p>
<p>从磁盘上的数据页放入到buffer pool的缓存页，必然涉及到一个问题，那就是哪些缓存页是空闲的？</p>
<pre><code>所以数据库会为buffer pool 设计一个**free链表**，它是一个双向链表的数据结构，这个free链表里，每个节点就是一个空闲的
缓存页的描述数据块的地址，也就是说，只要你的一个缓存页是空闲的，那么它的描述数据块地址就会被放入free链表中。
</code></pre>
<p>磁盘上的数据页是如何读到缓存页中？</p>
<pre><code> 其实有了free链表之后，这个问题就很简单了，首先需要重free链表中获取描述数据块，然后就可以获取这个描述数据块对应的空闲缓存页
 写缓存页，添加描述信息
</code></pre>
<p>那怎么知道一个数据是否加载到缓存页？</p>
<pre><code>数据库会维护一个**哈希表数据结构**，他会用表空间+数据页号作为key，然后缓存的地址作为value

也就是说每次你读取一个数据页缓存之后，都会在这个哈希表中写入一个key-value，下次在使用数据页只需要从哈希表中读取数据即可 
</code></pre>
<p>哪些缓存页是脏页</p>
<pre><code>内存中更新的脏页数据，都是要被刷回磁盘文件的。
但是不肯呢个所有的缓存页都刷回磁盘，因为有的缓存页可能是因为查询的时候，而被读到buffer pool 里面去的，可能根本没有修改过

所以数据库这里引入了另外一个跟free链表类似的**flush 链表**，**这个flush链表的本质也是通过缓存页的描述数据块的两个指针，让被修改过的缓存页描述数据块组成一个双向链表**
</code></pre>
<p>引入LRU算法来判断哪些缓存页是不常用的（缓存命中率）</p>
<pre><code>怎么判断哪些缓存页不是经常使用，哪些缓存页是脏页？
引入LRU链表

LRU：least recently used 最近最少使用的意思

工作原理：

假如我们从磁盘加载一个数据页到缓存页的时候，就会把这个缓存页描述数据放到LRU的头部，
那么只要有数据缓存页的时候，他就会在LRU链表里，而且最近被在加载的缓存页，都会放到
LRU的头部去。

然后假定某个缓存页的描述数据块本来是放在LRU尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这个缓存页挪动到HttpServletRequest
尾部，也就是说最近被访问过的缓存页，一定在LRU的头部。
</code></pre>
<p>LRU算法带来的问题</p>
<pre><code>预读带来的巨大问题

预读会导致，一直没被访问的数据放在LRU链表的头部，在空闲缓存页全部使用完时，会将链表尾部的数据刷入磁盘，清空缓存页。但是有可能这个数据时经常被使用的
</code></pre>
<p>哪些情况会触发Mysql的预读机制</p>
<pre><code>1.innodb_read_ahead_threshold他的默认值是56，意思是就是如果顺序的访问一个区里的多个数据页，访问的数据页的数量可能超过这个阈值
此时就会触发预读机制，把下一个相邻区中所有额数据页都加载到缓存中去。

2.如果Buffer Pool里缓存了12个联系的数据页，而且这些数据都是比较频繁被访问的，此时就会出发预读机制，把这个区里的其他数据页都加载到缓存里区。
这个机制是通过参数innodb_random_read_ahead来控制的，默认时OFF，也就是这个规则是关闭的
</code></pre>
<p>另外一种可能导致频繁访问的缓存页被淘汰的场景体验一下</p>
<p>那就是<strong>全表扫描</strong></p>
<pre><code>  类似  SELECT * FROM USERS 他一下子吧这个表里的所有数据页，都加载到Buffer Pool里去
</code></pre>
<p>Mysql基于冷热数据分离方案优化LRU算法</p>
<pre><code>真正的LRU链表，会被拆分成两个部分,一个部分是热数据，一个部分是冷数据，这个冷数据比例是由

innodb_old_blocks_pct参数来控制的，它默认的是37，也就是说冷数据的占比37%。

实际上这个时候，第一次加载时，缓存页会被放到冷数据链表的头部。
</code></pre>
<p>冷数据区域的缓存页何时被加载到热数据区域</p>
<pre><code>innodb_old_blocks_time 默认设置为1000，也就是1000毫秒

也就是数据加载到冷数据区域，过了1s后，你再访问这个缓存页，他就会被放到热数据区域的链表头部
</code></pre>
<figure data-type="image" tabindex="3"><img src="image/LRU.png" alt="img.png" loading="lazy"></figure>
<p>LRU链表的热数据区域是如何进行优化的？</p>
<pre><code>经常被访问的数据时热数据，不经常被访问的数据是冷数据，所以在设计缓存的时候，经常会考虑 **热数据的缓存预加载**
也就是说，每天统计出来哪些商品被访问次数最多，然后晚上的时候，系统启动一个定时作业，把热门商品的数据，预加载到redis里。
那么第二页是不是对热门访问的商品自然就优先走redis

 LRU链表的热数据区域的访问规则被优化了一下，即你只要在热数据区域的后3/4部分缓存页被访问了，才会给你移动到链表头部

如果你是热数据区域的前面的1/4的缓存页被访问，他是不会移动到链表头部的。

这样可以尽可能减少链表中的节点移动了。
</code></pre>
<p>定时LRU尾部的部分缓存页刷入磁盘</p>
<pre><code>第一个时机：有一个后台线程，他会运行一个定时任务，这个定时任务每个一段时间，就会把LRU链表的冷数据区域的尾部一些缓存页刷入到磁盘里去，清空几个缓存页，把他们加入到free链表中。

只要缓存页被刷盘，那么这个缓存页必然会加搭配free链表中，从flush链表中一处，从LRU链表中移除。

因为LRU链表中的热数据可能是被频繁修改的，难道他们永远都不刷入到磁盘了吗？

第二个时机，这个后台线程同时也会在Mysql不怎么繁忙的时候，找个时间把flush链表中的缓存页刷入磁盘，这样被你修改过的数据迟早都会刷入磁盘。
</code></pre>
<h4 id="redo-log">redo log</h4>
<p>redo log:在事务提交成功之后，保存一条日志记录，防止机器宕机导致数据丢失。顺序写，性能高。</p>
<p>redo log长什么样？</p>
<pre><code>redo log里面记录的就是：**表空间号+数据页号+偏移量+修改了几个字节的值+具体的值**

修改了几个字节的值，redo log就划分了不同的类型，MLOG_1BYTE:就是修改了一个字节的值，以此类推
但是如果你修改了一大串的值，类型就是MLOG_WRITE_STRING,就是代表你一下子在那个数据页的某个偏移量位置插入或者修改了一大串的值

日志类型(就是类似MLOG_1BYTE)，表空间号，数据页号，数据页中的偏移量。具体修改的数据
</code></pre>
<p>redo log写磁盘的过程</p>
<pre><code>其实mysql内有另外一个数据结构，叫做 redo log block
一个 redo log block是512字节，这个redo log block字节分为三个部分
一个是12字节的header块头，一个是496字节的body块体，一个是4字节trailer块尾
在这里面，12个字节的header投又分为4个部分：
    1.包括4个字节的block no，就是块唯一编码
    2.2个字节的data length，就是block里写入了多个字节数据；
    3.2个字节的first record group ，这个是说每个事务都会有多个redo log ，一个是redo log group，另一组redo log。那么在这个block里的第一组redo log的偏移量，就是这两个字节存储的；
    4.4个字节的checkpoint on
</code></pre>
<figure data-type="image" tabindex="4"><img src="image/redolog.png" alt="img.png" loading="lazy"></figure>
<p>redo log block 与磁盘文件的关系</p>
<figure data-type="image" tabindex="5"><img src="image/redo_log_block2.png" alt="img.png" loading="lazy"></figure>
<p>平时我们执行完增删改之后，要写入磁盘的redo log，其实应该是先进入到redo log block这个数据结构里，然后再进入磁盘文件</p>
<p>redo log buffer 类似申请出一块连续的空间，然后里面划分出N多个空的redo log block</p>
<p>通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认也就是16MB</p>
<figure data-type="image" tabindex="6"><img src="image/redo_log_block3.png" alt="img_1.png" loading="lazy"></figure>
<p>redo log buffer中的缓冲日志，到底是什么时候写入磁盘的？</p>
<pre><code>（1）如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在
缓冲里了，此时就会把他们刷入到磁盘文件里去
（2）一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事
务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改
（PS：当然，之前最早最早的时候，我们讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的
文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数，我们之前都讲过的 ，大家回过
头去看看 ）
（3）后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去
（4）MySQL关闭的时候，redo log block都会刷入到磁盘里去
</code></pre>
<p>redo log占用磁盘越来越大怎么办？</p>
<p>实际上默认情况下，redo log都会写入到一个目录中文件按里，这个目录可以通过</p>
<pre><code>show variables like 'datadir'
</code></pre>
<p>可以通过修改</p>
<pre><code>innodb_log_group_home_dir
</code></pre>
<p>参数来设置redo log这个目录</p>
<p>指定每个redo log文件的大小，默认是48M</p>
<pre><code>innodb_log_file_size
</code></pre>
<p>指定日志文件的数量</p>
<pre><code>innodb_log_file_in_group
</code></pre>
<figure data-type="image" tabindex="7"><img src="image/redologsetting.png" alt="img.png" loading="lazy"></figure>
<h4 id="undo-log">undo log</h4>
<p>INSERT 语句的undo log 类型是TRX_UNDO_INSERT_REC ，这个undo log里包含了一下的东西：</p>
<pre><code>    1.这条日志的开始位置
    2.主键的各列长度和值
    3.表idx
    4.undo log 日志编号
    5.undo log 日志类型
    6.这条日志的结束位置
</code></pre>
<figure data-type="image" tabindex="8"><img src="image/undolog.png" alt="img.png" loading="lazy"></figure>
<p>现在事务要是回滚，直接从undo log 日志中拿出这个id，找到对应的数据删掉</p>
<h3 id="事务">事务</h3>
<h4 id="多事务并发更新或者查询的数据问题">多事务并发更新或者查询的数据问题</h4>
<p>多个事务要是对缓存页里的同一条数据同时进行更新或者查询，此时会产生哪些问题？</p>
<pre><code>  实际上会设计到脏读，脏写，不可重复读，幻读
</code></pre>
<h5 id="脏写">脏写</h5>
<pre><code>事务B修改了事务A修改过的值，此时事务A还没提交，所以事务A随时会回滚，导致事务B修改过的值也没了
</code></pre>
<figure data-type="image" tabindex="9"><img src="image/zangxie.png" alt="img.png" loading="lazy"></figure>
<h5 id="脏读">脏读</h5>
<pre><code>事务B查询了事务A修改过的数据，但是此时事务A还没有提交，所以事务A随时回滚，导致事务B再次查询就读不到事务A修改的数据了
</code></pre>
<figure data-type="image" tabindex="10"><img src="image/zangdu.png" alt="img.png" loading="lazy"></figure>
<p>其實一句话总结：</p>
<pre><code>无论是脏写还是脏读，都是因为一个事务去更新或者查询了另外一个还没有提交的事务更新过的数据
    
因为另外一个事务还没提交，所以他随时可能反悔回滚，那么必然导致你更新的数据没了，或者你之前查询到的数据就没了，这种就是脏读和脏写。
</code></pre>
<h5 id="不可重复读">不可重复读</h5>
<pre><code>   针对已经提交的事务修改的值，被你的事务给读到了，你的事务多次查询，多次读到的是别人已经提交事务
   修改过的值，导致每次查询的值不一样
</code></pre>
<figure data-type="image" tabindex="11"><img src="image/bukechongfudu.png" alt="img_1.png" loading="lazy"></figure>
<h5 id="幻读">幻读</h5>
<h4 id="sql标准中对事务的4个隔离级别">SQL标准中对事务的4个隔离级别</h4>
<p>SQL标准中滚定了4种事务隔离级别，并不是Mysql的事务隔离级别，mysql的事务隔离级别有点差别。</p>
<p>在SQL标准中，规定的4种事务隔离级别，就是说多个事务并发运行的同时，互相是如何隔离的，从而避免事务并发问题</p>
<p>这四种级别包括：</p>
<h5 id="read-uncommitted-读未提交是不允许脏写的">read uncommitted 读未提交：是不允许脏写的</h5>
<pre><code>也就是说，不可能两个事务在没有提交的情况下去更新同一行数据的值，
但是这种隔离级别下，可能发生脏读，不可重复度，幻读。
</code></pre>
<h5 id="read-committed-rc-读已提交不可能发生脏写和脏读">read committed  RC 读已提交：不可能发生脏写和脏读</h5>
<pre><code>也就是说人家事务没有提交修改的值，你是绝对读不到的
这种隔离级别下不会发生脏读和脏写，但是可以发生不可重复读和幻读
</code></pre>
<h5 id="repeatable-read-rr-可重复读不可能发生脏读脏写不可重复读">repeatable read RR 可重复读：不可能发生脏读脏写，不可重复读</h5>
<pre><code>你的事务多次查询一个数据的值，哪怕别的事务修改这个值还提交了，没有，你不会读到人家事务提交事务修改过的值
你的事务一旦开始，多次查询一个值，会一直读到同一个值。
</code></pre>
<h5 id="serializable-串行化">serializable 串行化</h5>
<pre><code> 这种隔离级别，根本不允许你多个事务并发执行，只能串起来执行
</code></pre>
<h4 id="spring对事务的支持">spring对事务的支持</h4>
<p>在@Transaction(isolation =isolation.DEFAULT),默认是default，表示数据库是什么就是什么 isolation.READ_UNCOMMITTED isolation.READ_COMMITTED<br>
isolation.REPEATABLE_READ isolation.SERIALIZABLE</p>
<h4 id="透彻剖析mysql的mvcc事务隔离机制">透彻剖析Mysql的MVCC事务隔离机制</h4>
<h5 id="undo-log版本链">Undo log版本链</h5>
<pre><code>我们每条数据其实都有两个隐藏字段，一个是trx_id,一个是roll_pointer ，
這個trx_id就是最近一次更新过这条数据的事务id，
roll_pointer 就是指向你了你更新这个事务之前生成的undo log。
所以不管多个事务并发执行时如何执行的，
起码先搞清楚一点，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段trx_id和roll_pointer，
同时之前多个数据快照对应的undo log，会通过roll_pointer指针串联起来，形成一个很重要的版本链
</code></pre>
<h5 id="readview机制">ReadView机制</h5>
<p><a href="https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e86040203a20_GmWrGMJe/1?from=p_5e0c2a35dbbc9_MNDGDYba&amp;type=6">ReadView机制</a></p>
<p>你在在执行事务的时候，就会生成一个ReadView，里面比较重要的东西有四个</p>
<pre><code>1.一个是m_ids，这个就是说此时有哪些事务在mysql里执行还没有提交的
2.一个是min_trx_id，就是m_ids里最小的值；
3.一个是max_trx_id,这是说mysql下一个要生成的事务id，就是最大的事务id
4.一个是create_trx_id，就是你这个事务的id
</code></pre>
<p>现在两个事务并发执行过来，一个是事务A（id = 45），一个是事务B（id = 59），事务B要更新这行数据<br>
事务A是要去读取这行数据的值</p>
<p>现在事务A直接开启ReadView，这个ReadView里的m_ids就包含事务A和事务B的两个id，45和59，<br>
然后min_trx_id就是45，max_trx_id 就是60 create_trx_id 就是45 是事务A自己</p>
<p>这个时候事务A第一次查询这行数据，会走一个判断，就是判断这行数据的trx_id，是否小于 ReadView<br>
中的min_trx_id，此时发现trx_id =32是小于 ReadView中的min_trx_id 就是45的<br>
说明你在事务开启之前，修改这行数据的事务早就提交了，所以此时你就可以看到这行数据</p>
<p>接着事务B开始动手了，他把这行数据的值改为了B，然后这行数据trx_id设置为自己的id，也就是59，<br>
同时roll_pointer指向了修改之前生成的undo log，接着这个事务B就提交了。</p>
<p>接着事务A再次查询，此时查询的时候发现一个问题，就是此时数据行里的trx_id = 59 ，那么这个trx_id是大于ReadView里的<br>
min_trx_id（45），同时又小于ReadView里的max_trx_id（60）的，说明更新这条数据的事务很有可能跟自己差不多同时开启的，<br>
于是会看一下m_ids列表中有45 和 59 两个事务id，直接证实了，这条修改数据的事务是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的。</p>
<p>既然这行数据不能查询，那查什么？<br>
简单，顺着这条数据的roll_pointer顺着undo log日志链往下找，就会找到最近一条undo log，trx_id =32，<br>
此时发现trx_id =32 是小于ReadView里的min_trx_id =45 的 说明这个undo log版本必然是在事务A开启之前就执行且提交了。<br>
好了，那么就查询最近的那个undo log里的值好了，这就是undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值。</p>
<p>如果事务A ，更新值A,trx_id修改为45，同时保存之前事务B修改值的快照。<br>
那么此时A来查询这条数据，会发现trx_id =45 居然和自己的ReadView里的create_trx_id = 45 的值是一样的。<br>
说明这行数据就是自己修改的，自己修改的值当然可以i看到</p>
<p>如果在事务A执行的过程中，突然开启了是一个事务C，这个事务C的id =78，然后它更新了那行的值为值C，还提交了<br>
这个时候，事务A再去查询，会发现当前数据的trx_id = 78，大于了自己的ReadView中的max_trx_id（60）此时说明了什么，<br>
说明是这个事务A开启之后，然后有一个事务更新了数据，自己当然是看不到的。<br>
此时就会顺着undo log多版本链条往下找，自然先找到值A之前修改过的那个版本，因为那个trx_id = 45 跟自己的<br>
ReadView里的create_trx_id是一样的，所以此时直接读取自己修改的那个版本</p>
<figure data-type="image" tabindex="12"><img src="image/ReadViewjizhi.png" alt="img.png" loading="lazy"></figure>
<pre><code>通过undo log多版本链条，加上你开启事务时候生产的一个ReadView，然后再有一个查询的时候，根据ReadView进
行判断的机制，你就知道你应该读取哪个版本的数据。
而且他可以保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。假如说是你事务
开启之前，就有别的事务正在运行，然后你事务开启之后 ，别的事务更新了值，你是绝对读不到的！或者是你事务开
启之后，比你晚开启的事务更新了值，你也是读不到的！
</code></pre>
<h5 id="read-committed隔离级别是如何基于readview机制实现的">Read Committed隔离级别是如何基于ReadView机制实现的？</h5>
<pre><code>每次查询都生成新的ReadView，那么如果 在你这次查询之前，有事务修改了数据还提交了，你这次查询生成的ReadView里，那个m_ids列表当然不包含这个已
经提交的事务了，既然不包含已经提交的事务了，那么当然可以读到人家修改过的值了。
这就是基于ReadView实现RC隔离级别的原理，实际上，基于undo log多版本链条以及
ReadView机制实现的多事务并发执行的RC隔离级别、RR隔离级别，就是数据库的MVCC多版本并发控制机制。
</code></pre>
<h5 id="mysql最牛的rr隔离级别是如何基于readview机制实现的">MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？</h5>
<p>默认的ReadView 就是这个机制</p>
<pre><code>默认情况下，有人在更新数据的时候，你去读取这一行数据,直接默认就是开启mvcc机制的。
也就是说，此时一行数据的读和写两个操作默认是不会加锁互斥的，因为mysql的mvcc机制就是为了解决这个问题，避免频繁加锁互斥。
此时你读取数据，完全可以根据你的ReadView，去在undo log版本链条里找一个你能读取的版本，完全不用顾虑别人在不在更新。
就算你真的等他更新完毕了还提交了，基于mvcc机制，你也读取不到他更新的值啊！因为ReadView机制是不允许的，所以你默认情况下的读
，完全不需要加锁，不需要care其他食物的更新加锁问题，直接介于mvcc机制读某个快照就可以了

如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥
    
查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法
select * from table for update

当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h4 id="多个事务更新同一行数据时是如何加锁避免脏写的">多个事务更新同一行数据时，是如何加锁避免脏写的？</h4>
<p>多个事务同时更新一行数据，此时都会加锁（X 锁，也就是Exclude独占锁），然后都会等待排队，必须一个事务执行完毕了，提交了，释放了锁，才能唤醒别的事务继续执行。</p>
<p>加锁</p>
<figure data-type="image" tabindex="13"><img src="image/jiasuo.png" alt="img.png" loading="lazy"></figure>
<p>释放锁-加锁<img src="image/shifangsuojiasuo.png" alt="img.png" loading="lazy"></p>
<h5 id="共享锁">共享锁</h5>
<pre><code>如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥


默认情况下，有人在更新数据的时候，你去读取这一行数据,直接默认就是开启mvcc机制的。
也就是说，此时一行数据的读和写两个操作默认是不会加锁互斥的，因为mysql的mvcc机制就是为了解决这个问题，避免频繁加锁互斥。

如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥
    
查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法
select * from table for update

当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h5 id="独占锁">独占锁</h5>
<pre><code>当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法

select * from table for update

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h4 id="在表级别加锁">在表级别加锁</h4>
<p>多个事务并发更新数据的时候，都要在行级别加独占锁，独占锁是互斥的，所以不可能发生脏写问题，一个事务提交了才会释放自己的独占锁，唤醒下一个事务的执行。<br>
如果你此时去读取别的事务在更新的数据，有两种可能：<br>
1.第一种可能就是基于MVCC机制进行事务隔离，读取快照版本，这个是比较常见的；<br>
2.第二种可能是查询的同时基于特殊语法去加独占锁或者共享锁。</p>
<p>一般而言，不太建议在数据卷粒度去通过行锁实现复杂的业务锁机制，而更加建议通过redis，zookeeper来用分布式锁来实现复杂业务下的锁机制</p>
<p>比较正常的情况而言，其实还是多个事务并发运行更新一行数据，默认加独占锁互斥，同时其他事物基于mvcc机制进行快照版本读实现事务隔离<br>
、表锁其实是InnoDB存储引擎的概念</p>
<h4 id="索引">索引</h4>
<h5 id="磁盘上数据页的存储结构">磁盘上数据页的存储结构</h5>
<figure data-type="image" tabindex="14"><img src="image/shujuyedecunchu.png" alt="img.png" loading="lazy"></figure>
<pre><code>大量的数据页按照顺序一页一页的存放的，然后相邻的两个数据页会采用采用双向列表的格式互相引用

然后一个数据页内部会存储一行行的数据，也就是我们平时在表里插入的一行行数据就会存储在数据页里

然后数据页里的每一行数据都会按照主键大小进行排序村粗，同时每一行数据都有一个指针指向下一行数据

的位置，组成一个单向链表。

然后每个数据页都会有一个页目录，里面根据数据行的主键存放一个目录，同时数据行是被分割存储在不同槽位里去的

如果是主键查找，在数据页的页目录里,根据主键值直接定位到槽位，遍历槽位数据行，就可以找到数据
如果是非主键查找，只能进入数据页根据单向链表查找数据
</code></pre>
<p>在没有索引的情况下查找数据</p>
<pre><code>第一个数据页遍历所有数据页查找，将数据页加载到缓存页中
如果是主键查找，在数据页的页目录里,根据主键值直接定位到槽位，遍历槽位数据行，就可以找到数据
如果非主键查找，再单向遍历查找那条数据，如果没有那条数据，再加载下一个数据页到缓存页里来
以此类推，循环往复， 其实就是一个全表扫描
</code></pre>
<h4 id="页分裂的过程">页分裂的过程</h4>
<pre><code>假如我们不停的再表里插入数据，接着数据越来越多，此时就要在搞一个数据页了
但是此时就会遇到一个问题，索引运作的一个核心基础就是要求你后一个数据页的主键值大于前面一个数据页的主键值
但是如果你的主键是自增的，还可以保证这一点，因为你新插入的后一个数据页的主键值一定都大于前一个数据页的主键值。
但是如果你的主键不是自增的，所以可能会出现你的后一个数据页的主键值里，有点小于前一个数据页的主键值。
所以此时就会出现一个过程叫做也分裂
就是万一你的主键值都是你自己设置的，那么在增加一个新的数据页的时候，实际上会把前一个数据页主键值较大，挪到新的数据页里来
然后把你新插入的主键值较小的数据挪动到上一个数据页里去。保证了新数据页里的主键值一定都比上一个数据页里的主键值大。
</code></pre>
<h4 id="主键索引">主键索引</h4>
<pre><code>我们先拿最基础的主键索引来分析，把索引原理和查询原理搞清楚

mysql针对主键设计了一个索引，针对主键的索引实际上就是主键目录这个目录呢
把每个数据页的页号，还有数据页里最小主键的值放在一起，组成一个索引目录
</code></pre>
<figure data-type="image" tabindex="15"><img src="image/zhujiansuoyin.png" alt="img.png" loading="lazy"></figure>
<pre><code>通过主键查找时，通过二分查找，对比之后，确定id到底在那个数据页，
通过页目录直接定位到数据对应的槽位，遍历槽位数据行，就可以找到数据
</code></pre>
<h4 id="b树实现索引的物理结构">B+树实现索引的物理结构</h4>
<pre><code>很多索引数据不可能一直放在索引页里，会进行分裂

在更高索引层级里，保存每个索引页里最小的主键值，如果最顶层的索引页里存放下层索引页的也好太多了怎么办？
继续分裂，加一层索引页，这就形成了B+树，
这是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是由很多个数据页组成的一颗B+树
</code></pre>
<h4 id="聚簇索引">聚簇索引</h4>
<p>更新数据时，自动维护的聚簇索引</p>
<pre><code>当我们要查找某个主键id 的值时，通过二分查找很容易找到对应的索引页，通过索引页就能快读定位到数据页
实际上索引页和数据页之间是有指针连接起来的
另外呢,对于同一层级的索引页互相之间都是基于指针组成双向链表的
</code></pre>
<figure data-type="image" tabindex="16"><img src="image/index1.png" alt="img.png" loading="lazy"></figure>
<pre><code>加入把索引页和数据页综合起来看,他们连接在一起,看起来就如同一颗完整的大B+树一样

在B+树里最底层的一层就是数据页,数据页也就是B+树里的叶子节点了

也就是说,上图所有的索引页+数据页组成的B+树就是**聚簇索引**

这个聚簇索引默认时按照主键来组织的,所以你在增删改的时候,一方面会更新数据页,另一方面其实会给你自动维护
B+树结构的聚簇索引,给新增和更新索引页,这个聚簇索引是默认给你建立的.
</code></pre>
<h4 id="针对主键之外的其他字段建立索引的原理">针对主键之外的其他字段建立索引的原理</h4>
<pre><code>根据主键搜索数据的原理其实很清晰了,其实就是从聚簇索引的根节点进行二分查找,一路找到对应的数据页里,
基于页目录直接定位到主键对应的数据就可以了
</code></pre>
<p>主键之外的其他字段建立索引的原理</p>
<pre><code>其实原理是一样的,简单来说,你插入数据的时候,一方面会把完整的数据插入到聚簇索引的叶子节点的数据页里面去,
同时维护好聚簇索引,另一方面会为其他字段建立索引,重新建立一颗B+树.

比如你基于name建立一个索引,那么此时你插入数据的时候,就会重新搞一个B+树(这是独立与聚簇索引的另一个索引的B+树),
B+树的叶子节点也是数据页,但是这个数据页里仅仅存放主键字段和name字段.
</code></pre>
<figure data-type="image" tabindex="17"><img src="image/qitasuoyin.png" alt="img.png" loading="lazy"></figure>
<pre><code>搜索的时候过程和主键字段一模一样,不就是从name字段的索引B+树里根节点开始一层一层往下找,一直找到
叶子节点的数据页里,定位到name字段对应的主键值.
此时还需要进行回表操作,这个回表就是根据主键值,再到聚簇索引里面从根节点开始,一路找到叶子接待你的数据页,
定位到主键对应的完整数据行.
一般吧普通字段的索引称为二级索引,一级索引就是聚簇索引
</code></pre>
<p>多个字段联合起来,建立联合索引,比如:age+name</p>
<pre><code>联合索引的运行原理也是一样的,只不过是建立了一颗独立的B+树,叶子节点里面存放了id+name+age的数据,
然后默认按照name排序,name一样就按照age排序
查询的时候和普通索引一样的原理
</code></pre>
<p>联合索引的查询原理，以及使用索引的全职匹配规则</p>
<pre><code>假如莫得sql语句的where 条件里的几个字段的名称和顺序，都是跟你的索引里的字段一样，同时你还用等号值做匹配，那就是全职匹配
通过第一个字段值，二分查找找到对应的数据页，再在数据页里面二分查找找到对应的其他值找到id之后，进行查找聚簇索引回表操作，查询出剩下的其他字段
</code></pre>
<p>这就是InnoDB存储引擎的索引的完整实现原理了.</p>
<h4 id="索引的优缺点">索引的优缺点</h4>
<p>优点：不需要全表扫描，性能提升很快<br>
缺点消耗磁盘空间，增删改的速度很比较差（因为要维护B+树结构）</p>
<h4 id="索引的使用规则">索引的使用规则</h4>
<p>设计原则：</p>
<pre><code>设计系统时，索引的设计

1.一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，才能发挥出B+树快速二分查找的优势来

2.尽量使用那些字段值比较小的列来设计索引

3.设计索引别太多，建议两三个联合索引就应该覆盖掉你这个表的全部查询了。

否则索引太多，必然导致你增删改的时候性能很差，因为要很多个索引树。

4.另外很关键一点，建议大家主键一定是自增的，别用UUID之类的
因为主键自增，那么你的聚簇索引不会频繁的分裂，主键都是有序的，就会自然新增一个列而已，如果你用得视UUID，那么会
导致聚簇索引频繁的页分裂
</code></pre>
<p>where 使用原则：</p>
<pre><code>1.联合索引的等值匹配规则
    where语句中的几个字段名称和联合索引的条件里的几个字段的名称和顺序，都是跟你的索引里的字段一样，同时你还用等号值做匹配，那就是全职匹配

2.最左侧列匹配
   这个意思是我们的联合索引是KEY(index_key1,index_key2,index_key3)
   那么不一定必须要在where语句里查询三个字段来查，其实只需要根据最左侧的部分字段来查也是可以的
   where index_key1 = '' and index_key2 = '' 是没有问题的
   但是 你要用 where index_key3 那就不行了，因为在联合索引B+树里，是必须先按index_key1，再按index_key2，
   不能跳过前面两个字段直接按照最后一个index_key3 来查
   另外 where index_key1 = '' and index_key3 = '' ,那么饿只要index_key1在索引里能搜到，剩下的index_key3
    没办法在索引中找到
   所以，在建立所以的过程中，你必须建立好联合索引的字段，以及平时你写sql的时候要按照哪几个字段来查

3.最左前缀匹配规则
  即如果你要用like语法来查  like '1%'，是可以用到索引的  ，但是 like '%1'，没法用索引

4.范围查找规则
    同最左侧匹配

5.等值匹配+范围匹配规则
 同最左侧匹配
</code></pre>
<p>order 在sql进行排序，如何使用索引</p>
<pre><code>通常情况下，我们建立INDEX(xxx1,xxx2,xxx3)这样的联合索引，
这个时候默认情况下索引树里本身就是依次按照xxx1,xxx2,xxx3三个字段的值进行排序的
这个时候 用order by xxx1 ,xxx2,xxx3，在联合索引的索引树里都排好了，直接取出数据，
再去聚簇索引里面回表查询所有字段
但是这里有一个限定规则，因为联合索引里的字段值在索引树里都是从小到大一次排序的，
所以order by 要么都降序，要么都升序
不能有的字段降序，有的字段升序，那是不能用索引的
</code></pre>
<p>group by 在在sql中进行分组，如何使用索引<br>
通常而言 group by 后的字段，最好也是按照联合索引最左侧的字段开始，按顺序排列开来，这样的话就可以完美的<br>
运用上索引直接提取一组一组数据，然后对每组数据进行聚合就可以了。</p>
<p>覆盖索引</p>
<pre><code>覆盖索引是不是一种索引，他就是一种基于索引的查询方式罢了。
仅仅需要联合索引里面的几个字段的值，那么其实只要扫描联合索引的索引树就可以了
这种查询的方式就是覆盖索引，这样就不需要回表
</code></pre>
<p>最好使用覆盖索引<br>
即使真的要回表到聚簇索引，那你尽可能的用limit 和where 之类的语句<br>
限定一下回表到聚簇索引的次数，这样性能也要好一些</p>
<h4 id="索引的设计规则">索引的设计规则</h4>
<p>1.一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，才能发挥出B+树快速二分查找的优势来</p>
<p>2.尽量使用那些字段值比较小的列来设计索引</p>
<p>3.设计索引别太多，建议两三个联合索引就应该覆盖掉你这个表的全部查询了。</p>
<p>否则索引太多，必然导致你增删改的时候性能很差，因为要很多个索引树。</p>
<p>4.另外很关键一点，建议大家主键一定是自增的，别用UUID之类的<br>
因为主键自增，那么你的聚簇索引不会频繁的分裂，主键都是有序的，就会自然新增一个列而已，如果你用得视UUID，那么会<br>
导致聚簇索引频繁的页分裂</p>
<h4 id="执行计划">执行计划</h4>
<p>每一次提交sql给mysql，他内核的查询优化器，都会针对这个sql语句的语义去生成一个执行计划，<br>
这个执行计划就代表了，如何筛选过滤如何使用函数，如何进行排序，如何进行分组。</p>
<p>执行计划里包含哪些内容：<br>
1.数据的访问方式：</p>
<p>const - ref -range - index -- all</p>
<pre><code>const:肯定是通过了主键或者唯一索引，速度超高
ref:普通索引  或者主键唯一索引 搞了is null 或者 is not null
range:利用索引来进行范围筛选，一旦索引做了范围筛选，那么这种方式就是range
index:只要遍历组合索引就可以，不需要回表到聚簇索引中去，针对这种只需要遍历二级索引就能拿到你想要的数据，而不需要回源到聚簇索引的访问方式
all:直接全表扫描
</code></pre>
<p>const ，ref ，range :本质上都是居于索引树的二分查找和多层跳转来查询的，所以性能都是很高的<br>
接着接下来就是index 速度上比上面三种压迫差一些，因为他是走遍历二级索引树的叶子节点的方式来执行的<br>
那肯定比基于索引树的二分查找要慢多了，但是还是比全表扫描好一些。</p>
<p>多表关联的sql是如何执行的？</p>
<p>select * from tabel1 t1, table2 t2 where t1.xx = xxx,t2.xxx= xxx and t1.xxx2 = t2.xxx2</p>
<p>sql关联语法的实现原理（嵌套循环关联）：</p>
<pre><code>1.首先根据t1.xxx 表里查询出来一批数据，此时可能是const， ref ,index 或者all，具体看你的索引怎么建立的，他会挑一种执行计划的访问方式。
2.筛选出t1表的数据后，比如说找到两条数据，根据每条数据xxx2的值，以及t2.xxx2这个条件去t2表里找x2字段值和xxx 都匹配的字段值
这时就把两个表的数据关联起来了，另一条数据也是如法炮制。
</code></pre>
<p>记住，他可能是先从表里查一波数据，这个表叫做”驱动表“，再根据这波数据去另一个表查一波数据进行关联，另一个表叫做”被驱动表“</p>
<p>内连接：inner join 意思是两个表的数据必须完全关联上，才能返回回来<br>
外连接：outer join 可分为左外连接（左连接），右外连接（有连接）<br>
如果你是之前的那种内连接，那么连接条件可以放在where语句里，但是外连接一般是把连接条件放在ON字句里的</p>
<p>其实一般写多表关联，主要就是内连接和外连接，连接的语义和实现过程</p>
<p>mysql是如何根据成本优化执行计划的？</p>
<p>全表扫描的成本计算：</p>
<pre><code>show like status like '表名';
rows:表里的记录数
data_length:代表表的聚簇索引的字节数大小 默认是byte

全表扫描的 IO成本：数据页的数量* 1.0 +微调值
         CPU成本：行记录数 * 0.2 + 微调值
总成本= IO成本+CPU成本
</code></pre>
<p>索引的成本计算：</p>
<p>1.基于IN查询的子查询方式的优化：</p>
<p>sql物化表：存储引擎通过内存来存放，如果结果集太大，则可能采用普通B+树聚簇索引的方式存放在磁盘里<br>
但是无论如何，这个物化表都会建立索引。</p>
<p>2.对子查询的另一种优化方式：半连接</p>
<p>在互联网公司，比较崇尚的是尽量写简单的sql，复杂的逻辑用java系统来实现就可以了<br>
sql能单表就不要多表关联，能多表关联就尽量别写子查询，多考虑用java代码在内存里实现<br>
一些数据的复杂计算逻辑，而不是都放在sql里做。</p>
<p>执行计划落实到底层无非就是先访问哪张表，用哪个索引还是全表扫描，拿到数据之后如何去聚簇索引中回表<br>
是否要基于临时磁盘文件做分组聚合或者排序</p>
<p>查看执行计划的内容</p>
<p>id：每个select 都会对应一个id<br>
select_type:说的就是这一条执行计划对应查询的是个什么查询类型<br>
table：就是表名，意思是要查询哪张表<br>
partitions:是表分区的概念<br>
type:当前这个表的访问方式，比如说 const ref range index all<br>
possible_keys:可能选择的索引<br>
key：实际上选择的索引<br>
key_len:就是索引的长度<br>
ref:就是使用某个字段的索引进行等值匹配搜索的时候，跟索引列等值匹配的那个目表值得一些信息<br>
rows:是预估通过索引或者别的方式访问这个表的时候，大概可能取多少条数据，<br>
filtered:就是通过搜索条件过滤后得剩下数据得百分比<br>
extra：一些额外得信息</p>
<p>select_type:</p>
<pre><code>一般单表或者多表连接查询，他们得select_type都是SIMPLE，就是简单得查询
如果是union 语句，第一条执行计划针对表1，select_type 就是 PRIMARY
                第二条执行计划针对表2，select_type 就是 UNION
                第三条执行计划就是针对两个查询结果依托 一个临时表去重
                第三条执行计划 select_type 就是 union_result
如果是子查询，第一条执行计划 select_type 就是 PRIMARY
            第二条执行计划 select_type 就是SUBQUERY  
            select_type 是DERIVED 针对子查询得结果集会物化一个内部临时表
</code></pre>
<h4 id="sql调优">Sql调优</h4>
<pre><code>在sql调优的时候，核心就是分析执行计划里哪些出现了全表扫描，或者扫描的数据过大，尽可能的通过合理
优化索引保证执行计划每个步骤都是基于索引执行，避免扫描过多的数据
</code></pre>
<p>如果mysql使用了错误得执行计划应该怎么办？<br>
使用 force index 语法就可以了</p>
<p>select * from table fore index (index) where  index = &quot;&quot;</p>
<p>为什么mysql 默认会选对主键得聚簇索引进行扫描？</p>
<h3 id="mysql物理存储">mysql物理存储</h3>
<h4 id="varchar这种变长字段在磁盘上到底是如何存储的">VARCHAR这种变长字段，在磁盘上到底是如何存储的</h4>
<p><strong>引⼊变长字段的长度列表，解决⼀⾏数据的读取问题：</strong></p>
<pre><code>将数据的长度转成16进制表示，放在数据存储的前面
</code></pre>
<p><strong>多个变长字段是如何存储的？</strong></p>
<pre><code>此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储⼏个变长字段的长度，⼀定要注意⼀点，他这⾥是逆
序存储的！
</code></pre>
<p>0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a</p>
<p><strong>mysql的一行行数据紧凑存储有什么好处？</strong></p>
<pre><code>多行紧凑的原因有： 序列化反序列时的开销小；不易有内存碎片；定位数据时比较快速
</code></pre>
<h4 id="一行数据中的多个null字段值在磁盘上怎么存储">一行数据中的多个NULL字段值在磁盘上怎么存储</h4>
<p><strong>为什么一行数据的NULL值不能直接存储？</strong></p>
<pre><code>肯定不是按照字符串的方式存储，会浪费空间。
</code></pre>
<p><strong>NULL值是以二进制Bit来存储的？</strong></p>
<pre><code>bit值是1 说明是NULL，如果是0 说明不是NULL
</code></pre>
<p><strong>磁盘上的⼀⾏数据到底如何读取出来的？</strong></p>
<pre><code>我们结合上⾯的磁盘上的数据存储格式来思考⼀下，⼀⾏数据到底是如何读取出来的呢？
再看上⾯的磁盘数据存储格式：
0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN

⾸先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析⼀下，就知道有⼏个变长字段，哪⼏个变长
字段是NULL，因为NULL值列表⾥谁是NULL谁不是NULL都⼀清⼆楚。
此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪⼏个字段是NULL的，此时
根据这些信息，就可以从实际的列值存储区域⾥，把你每个字段的值读取出来了。
如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字
段，就按照定长长度来读取，这样就可以完美的把你⼀⾏数据的值都读取出来了！
</code></pre>
<h4 id="磁盘文件中40个bit位的数据头以及真实数据是如何存储的">磁盘文件中40个bit位的数据头以及真实数据是如何存储的</h4>
<pre><code>每一行数据在磁盘上存储的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，  
然后会有NULL值列表，对于允许NULL值得字段都会有一个bit位标识那个字段是否为NULL，也是逆序排序得
</code></pre>
<p>每一行数据存储得时候，还得有一个bit位得数据头，这个数据头是用来描述这行数据的。</p>
<pre><code>第一位bit和第二位bit都是预留位，是没有任何含义的。
接下来的bit位是delete_mask：他标识这行数据是否被删除了
下一个bit位是min_rec_mask：在B+树里每一层的非页字节点里最小值都有这个标记
接下来是4个bit位是n_owned：记录了一个记录数
接下来13个bit位是heap_no，他代表是当前这行数据在数据堆里的位置
然后是3个bit位record_type：也就是这行数据的类型
   0:代表普通类型
   1：代表是B+树非叶子节点
   2：代表是最小值的数据 
   3：代表最大值的数据
最后16位bit是next_record:这个是他下一条数据的指针
</code></pre>
<h4 id="一行数据实际在磁盘上的存储">一行数据实际在磁盘上的存储</h4>
<p><img src="image/mysqlcipancunchu.png" alt="img.png" loading="lazy">变长字段列表 NULL值列表 数据头 真实数据</p>
<p>在实际存储一行数据的时候，会在他真实数据部分，添加一些隐藏字段</p>
<pre><code>DB_ROW_ID 字段：这是一个行的唯一标识，是数据库内部的一个标识，不是你的主键ID字段，入股我们没有指定主键和
unique key 唯一索引的时候，他的内部就会自动加一个DB_ROW_ID

DB_TRX_ID字段，这个跟事务相关，他是说这是哪个事务更新的数据，这是事务ID。

DB_ROLL_PTR，这是回滚指针，用来进行事务回滚的
</code></pre>
<h4 id="行溢出">行溢出</h4>
<p>行溢出：就是一行的数据存储太多的内容，一个数据页都放不下，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页。</p>
<h4 id="表空间">表空间</h4>
<pre><code>表空间：我们平时创建的那些表，其实就是都有一个表空间的概念，在磁盘上对会对应'表明.ibd'，这样的一个磁盘数据文件。’

‘一个表空间磁盘文件里，其实会有很多很多的数据页，为了便于管理，表空间又引入了**数据区（extent）**
一个数据区对应64个连续的数据页，每个数据页的大小是16kb，所以一个数据区就是1mb，然后256个数据区被划分为一组。

当我们需要执行CRUD操作的时候，说白，就是从磁盘上表空间的数据文件里，去加载一些数据页出来到buffer pool的缓存页里区使用
</code></pre>
<figure data-type="image" tabindex="18"><img src="image/shujuqu.png" alt="img.png" loading="lazy"></figure>
<h3 id="生产实践">生产实践</h3>
<h4 id="真实生产环境下的数据库机器配置如何规划">真实生产环境下的数据库机器配置如何规划</h4>
<p>普通应用的机器选择？</p>
<pre><code>就经验而言，普通的系统 4核8G ，每秒抗几百的请求没问题，
数据库通常是在8核16G以上正常的是16核32G
</code></pre>
<p>高并发场景数据库应该选择什么样的机器？</p>
<pre><code>磁盘，io，网络压力会比较大，最好采用ssd固态硬盘
</code></pre>
<h4 id="互联网公司的生产环境数据库是如何进行性能测试的">互联网公司的生产环境数据库是如何进行性能测试的？</h4>
<p>请求测试指标：QPS、TPS</p>
<pre><code>QPS：Query Per Second，每秒可以处理多少个请求，也就是说这个数据库每秒可以处理多少个sql

TPS：Transaction Per Second 。其实就是每秒可处理的事物
</code></pre>
<p>IO相关压测性指标</p>
<pre><code>IOPS：这个是机器随机IO并发处理能力
这个指标很关键，你在内存中更新的脏数据，最后都会由后台IO在不确定时间，刷回到磁盘里去。这个是随机IO的过程，
如果说IOPS指标太低了，那么会导致脏数据刷回磁盘的效率不高。


吞吐量：这个指机器的磁盘存储每秒可以读写多少个字节的数据
这个指标也很关键，因为大家通过学习都知道，我们在平时执行各种sql的时候，提交事物的时候，其实都会有大量会写redo log日志之类的，这些日志都会直接写磁盘

latency：这个指标说的往磁盘里写入一条数据的延迟。
这个指标同样很重要，因为我们执行sql语句和提交事物的时候，都需要顺序写redo log 次哦盘文件，所以此时
你写一条日志到磁盘文件里去，到底延迟是1ms还是100us，这就是对你的数据库sql语句执行性能是有影响的
</code></pre>
<p>其它指标</p>
<pre><code>CPU负载：PU负载是⼀个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标
都还正常，但是此时CPU负载特别⾼，那么也说明你的数据库不能继续往下压测更⾼的QPS了，否则CPU是吃不消的。

网络负载：这个主要是要看看你的机器带宽情况下，在压测到⼀定的QPS和TPS的时候，每秒钟机器的⽹卡会输⼊多少
MB数据，会输出多少MB数据，因为有可能你的⽹络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，⽹
卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了

内存负载：：这个就是看看在压测到⼀定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过⾼了，说明也
不能继续压测下去了
</code></pre>
<h4 id="如何对生产环境中的数据库进行360度无死角压测httpsapppukyptrl1086pcxiaoe-techcomdetaili_5e383c5357307_mjhluwmb1fromp_5e0c2a35dbbc9_mndgdybatype6">如何对生产环境中的数据库进行360度无死角压测？（https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e383c5357307_MjhluwMb/1?from=p_5e0c2a35dbbc9_MNDGDYba&amp;type=6）</h4>
<p>在linux 安装sysbench</p>
<pre><code>curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash
sudo yum -y install sysbench
sysbench --version
如果上⾯可以看到sysbench的版本号，就说明安装成功了

QPS：Query Per Second，每秒可以处理多少个请求，也就是说这个数据库每秒可以处理多少个sql

TPS：Transaction Per Second 。其实就是每秒可处理的事物
</code></pre>
<p>如何为生产环境中的数据库部署监控系统</p>
<pre><code>Prometheus：其实就是一个监控数据采集和存储系统，它可以利用采用缉拿空数据采集组件从你指定的Mysql数据库中采集他需要的监控数据
然后他自己由一个时序数据库，他会把采集道德监控数据放到自己的时序数据库中，本质就是存储在磁盘文件里。

Grafana：就是一个可视化的监控数据展示系统，他可以Prometheus采集到的大量mysql监控数据展示成各种精美报告，可以让我们直接看到mysql的监控情况。
</code></pre>
<h4 id="如何通过多个buffer-pool来优化数据库的并发性能">如何通过多个Buffer Pool来优化数据库的并发性能</h4>
<p>多线程并发访问一个Buffer Pool的时候必然会加锁，然后很多线程可能要串行着排队，一个个的依次执行操作。</p>
<p>一般来说，Mysql默认的规则是，如果你给Buffer Pool分配的内存大小小于1GB，那么最多就会给你一个Buffer Pool</p>
<p>但是如果你的机器内存就很大，那么此时你是可以同时设置多个Buffer Pool</p>
<pre><code>  innodb_buffer_pool_size = 8589934592
  innodb_buffer_pool_instance = 4
</code></pre>
<p>我们给Buffer Pool 设置了8GB的总内存，然后设置了4个Buffer Pool，也就是说每个Buffer Pool的大小是2GB</p>
<p>所以在生产实践中设置多个Buffer Pool 来优化高并发访问的性能，是mysql一个很重要的优化技巧。</p>
<h4 id="如何通过chunk来支持数据库运行期间的buffer-pool动态调整">如何通过chunk来支持数据库运行期间的Buffer Pool动态调整</h4>
<p>实际上Buffer Pool是由很多个chuck组成的，他的大小是innodb_buffer_pool_chunk_size 来控制的默认值是128M</p>
<pre><code>所以实际上我们可以做一个假设，比如现在我们给Buffer Pool 设置一个总大小是8GB，然后4个Buffer Pool ，那么每个Buffer Pool 就是2GB
 此时每个Buffer Pool 是由一系列的128M chuck组成的，也就是说每个Buffer Pool 会有16个chuck，然后每个Buffer Pool里的每个chuck里就是一系列
数据描述和缓存页，每个Buffer Pool里的多个chuck共享一套 free flush lru 链表 
</code></pre>
<h4 id="在生产环境中如何基于机器配置来合理设置buffer-pool">在生产环境中，如何基于机器配置来合理设置Buffer Pool</h4>
<p>Buffer Pool 的大小一般设置为机器大小的50-60%</p>
<p>确定了Buffer pool 的总大小之后，就得考虑设置多少个buffer pool以及chuck</p>
<p>一般来说： buffer pool总大小 = （chuck大小 * buffer pool数量）的倍数</p>
<h4 id="linux操作系统的存储系统软件层原理剖析以及io调度优化原理">Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理</h4>
<p>Linux的存储系统分为VFS层、⽂件系统层、Page Cache缓存层、通⽤Block层、IO调度层、Block设备驱动 层、Block设备层，</p>
<figure data-type="image" tabindex="19"><img src="image/linuxcunchujiegou.png" alt="img.png" loading="lazy"></figure>
<p>当mysql发起随机读写或者一次顺序写redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给linux操作系统的VFS层</p>
<p>VFS层：根据你是对哪个目录中的文件执执行磁盘IO操作，把IO请求交给具体的文件系统。</p>
<pre><code>举个例⼦，在linux中，有的⽬录⽐如/xx1/xx2⾥的⽂件其实是由NFS⽂件系统管理的，有的⽬录⽐如/xx3/xx4⾥的⽂件
其实是由Ext3⽂件系统管理的，那么这个时候VFS层需要根据你是对哪个⽬录下的⽂件发起的读写IO请求，把请求转
交给对应的⽂件系统，如下图所⽰

接着⽂件系统会先在Page Cache这个基于内存的缓存⾥找你要的数据在不在⾥⾯，如果有就基于内存缓存来执⾏读
写，如果没有就继续往下⼀层⾛，此时这个请求会交给通⽤Block层，在这⼀层会把你对⽂件的IO请求转换为Block IO
请求，如下图所⽰

接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这⼀层⾥默认是⽤CFQ公平调度算法的
也就是说，可能假设此时你数据库发起了多个SQL语句同时在执⾏IO操作。
有⼀个SQL语句可能⾮常简单，⽐如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的⼀个block
⾥的数据就可以了
但是有的SQL语句，⽐如说select * from xx where xx1 like &quot;%xx%&quot;可能需要IO读取磁盘上的⼤量数据。
那么此时如果基于公平调度算法，就会导致他先执⾏第⼆个SQL语句的读取⼤量数据的IO操作，耗时很久，然后第⼀
个仅仅更新少量数据的SQL语句的IO操作，就⼀直在等待他，得不到执⾏的机会。
所以在这⾥，其实⼀般建议MySQL的⽣产环境，需要调整为deadline IO调度算法，他的核⼼思想就是，任何⼀个IO操
作都不能⼀直不停的等待，在指定时间范围内，都必须让他去执⾏。
所以基于deadline算法，上⾯第⼀个SQL语句的更新少量数据的IO操作可能在等待⼀会⼉之后，就会得到执⾏的机会，
这也是⼀个⽣产环境的IO调度优化经验。
我们看下图，此时IO请求被转交给了IO调度层


最后IO完成调度之后，就会决定哪个IO请求先执⾏，哪个IO请求后执⾏，此时可以执⾏的IO请求就会交给Block设备驱
动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，如下图所⽰。

然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上⾯的层级反向依次返回，最终
MySQL可以得到本次IO读写操作的结果
</code></pre>
<figure data-type="image" tabindex="20"><img src="image/RAIDchongfangdian.png" alt="img.png" loading="lazy"></figure>
<h4 id="数据库服务器使用的raid存储架构初步介绍">数据库服务器使用的RAID存储架构初步介绍</h4>
<pre><code>所以MySQL数据库软件都是安装在一台linux服务器上的，然后启动MySQL的进程，就是启动了一个MySQL数据库

MySQL运行过程中，他需要使用CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供的接口，依托于操作系统来使用和运行的，然后linux操作系统负责操作底层的硬件。
</code></pre>
<figure data-type="image" tabindex="21"><img src="image/mysql_1.png" alt="img.png" loading="lazy"></figure>
<pre><code>数据库部署在机器上的时候，存储都是搭建的RAID存储架构

RAID就是一个磁盘冗余阵列

RAID这个技术，大致理解为用来管理机器里的多块磁盘的一种磁盘阵列技术！

有了他以后，你在往磁盘里读写数据的时候，他会告诉你应该在哪块磁盘上读写数据，
</code></pre>
<figure data-type="image" tabindex="22"><img src="image/img_1.png" alt="img_1.png" loading="lazy"></figure>
<pre><code>有了RAID这种多磁盘阵列技术之后，我们是不是就可以在一台服务器里加多块磁盘，扩大我们的磁盘存储空间了？

当我们往磁盘里写数据的时候，通过RAID技术可以帮助我们选择一块磁盘写入，在读取数据的时候，我们也知道从哪块磁盘去读取。
</code></pre>
<p>除此之外，RAID技术很重要的一个作用，就是他还可以<strong>实现数据冗余机制</strong></p>
<pre><code>所谓的数据冗余机制，就是如果你现在写入了一批数据在RAID中的一块磁盘上，然后这块磁盘现在坏了，无法读取了，那么岂不是你就丢失了一波数据？如下图所示

![img.png](image/mysql_3.png)
</code></pre>
<p>所以其实有的RAID磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的.<br>
这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的，不需要你操心， 如下图。</p>
<figure data-type="image" tabindex="23"><img src="image/mysql_4.png" alt="img.png" loading="lazy"></figure>
<p>所以RAID技术实际上就是管理多块磁盘的一种磁盘阵列技术，他有软件层面的东西，也有硬件层买的东西，比如有RAID卡这种硬件设备。</p>
<p>具体来说，RAID还可以分成不同的技术方案，比如RAID 0、RAID 1、RAID 0+1、RAID2，等等，一直到RAID 10，很多种不同的多磁盘管理技术方案</p>
<h4 id="数据库服务器上的raid存储架构的电池充放电原理">数据库服务器上的RAID存储架构的电池充放电原理</h4>
<p>RAID緩存模式設置為write back，意思是先寫緩存再寫磁盤整列<br>
<img src="image/RAIDchongfangdian.png" alt="img.png" loading="lazy"></p>
<p>鋰電池會性能减弱，所以需要对锂电池的配置订定时充放电。</p>
<p>充电的过程中 RAID缓存级别会从write back 变成write through，这个时候IO直接些磁盘。性能会下降，导致数据库抖动出现性能抖动。</p>
<h4 id="raid锂电池充放电导致的mysql数据库性能抖动的优化">RAID锂电池充放电导致的MySQL数据库性能抖动的优化</h4>
<p>RAID 0：同时些很多快磁盘，读写并发能力强，容易丢失数据 RAID 1：两块磁盘为镜像关系，所写的数据在另一块磁盘上都有，形成数据冗余，防止数据丢失，分摊读写的压力。</p>
<p>RAID 10 = RAID 0 + RAID 1：写的时候使用RAID 0 的思路，备份使用RAID 1 的思路。</p>
<p>对于RAID 锂电池充放电问题导致的存储性能抖动，一般有三种解决方案：</p>
<pre><code>1.给RAID卡把锂电池换成电容，电容是不用频繁充放电的，不会导致充放电的性能抖动，还有就是电容可以支持透明充放电，就是自动检查电量，自动进行充电，不会说在充放电的时候让写IO直接走磁盘，但是更换电容很麻烦，而且电容比较容易老化，这个其实一般不常用

2.手动充放电，这个比较常用，包括一些大家知道的顶尖互联网大厂的数据库服务器的RAID就是用了这个方案避免性能抖动，就是关闭RAID自动充放电，然后写一个脚本，脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本手动触发充放电，这样可以避免业务高峰期的时候RAID自动充放电引起性能抖动

3.充放电的时候不要关闭write back，就是设置一下，锂电池充放电的时候不要把缓存级别从write back修改为write through，这个也是可以做到的，可以和第二个策略配合起来使用
</code></pre>
<h4 id="数据库无法连接故障的定位toomanyconnections">数据库无法连接故障的定位TooManyConnections</h4>
<p>TooManyConnections 说明数据库连接池已经满了，你的业务系统不能与他建立更多的连接了。</p>
<p>检查mysql的配置文件 my.conf，里面有个关键的参数max_connections就是mysql建立的最大连接数。</p>
<p>查看mysql实际最大连接数</p>
<pre><code>show variables like 'max_connections'
</code></pre>
<p>mysql无法设置max_connections期望值，只能强行限制为214？为什么？</p>
<pre><code>    简单来说，就是因为底层linux操作系统把进程可以打开的文件句柄数限制为1024了导致mysql最大连接数时214
    为什么linux的最大文件句柄限制为1024的时候，MySQL的最大连接数是214呢？ 
    原因其实是mysql内部源码写死的，它在源码中就是有一个公式，算下来如此罢了
</code></pre>
<p>如何解决经典的Too Many Connections故障，背后的原理是什么？</p>
<pre><code>    ulimit -HSn 65535
    然后就可以用如下命令检查最大文件句柄数是否被修改了
    cat /etc/security/limits.conf
    cat /etc/rc.local
    如果都修改好了之后，可以在mysql的my.cnf里确保max_connections参数也调整好了，然后就可以重启服务器，重启mysql，
    这样的话，linux的最大文件句柄就会生效了，mysql最大连接数也会生效了
</code></pre>
<h4 id="线上数据库不确定性的性能抖动优化">线上数据库不确定性的性能抖动优化</h4>
<p>sql语句性能会出现不正常的莫名其妙的抖动，平时可能即使毫秒，现在居然要几秒钟，根本原因有两种：</p>
<p>1.第一个可能buffer pool缓存页都满了，此时你的sql查询了很多数据，一下把很多缓存页flush到磁盘上去，刷磁盘太慢了，就会导致你的查询语句执行的很慢。</p>
<p>2.第二种可能是你执行更新语句的时候，redo log在磁盘上的所有文件都写满了，此时需要回到第一个redo log文件覆盖写，覆盖写可能就涉及到第一个redo log文件里有很多<br>
redo log日志对应的更新操作改动了缓存页，那写缓存页还没有flush到磁盘，此时就必须把哪些缓存页的flush到磁盘，才能执行后续的更新语句，那么这一等待<br>
必然会导致更新执行很慢</p>
<p>如何尽可能的优化Mysql的一些参数，减少这种缓存页flush到磁盘带来的性能抖动的问题？</p>
<pre><code>1.对于不是数据库的机器一定要采用ssd的磁盘，
2.innodb_io_capacity 这个参数是告诉数据库采用多大的io速率把缓存页flush到磁盘里去的
    可以使用fio工具测试磁盘最大随机io速率之后，就知道他每秒可以执行多少次随机io
3.innodb_flush_neighbors,意思是在flush缓存页到磁盘德时候，可能会把缓存页临近的其他缓存页也刷到磁盘
但是这样有时候会导致flush缓存也太多了，实际上如果你使用的是SSD固态硬盘，并没必要让他同时刷进临近的缓存页，
可以把innodb_flush_neighbors设置为0，禁止刷进缓存页
</code></pre>
<h2 id="mysql主从架构">mysql主从架构</h2>
<h3 id="主从架构的原理">主从架构的原理</h3>
<p>大致来说：就是主库接受增删改的操作，把增删改操作binlog写入本地文件，然后从库发送请求来拉取binlog,接着从库上重复执行一遍binlog的操作，就可以还原出一样的数据。</p>
<h3 id="主从复制架构的搭建最基础架构">主从复制架构的搭建(最基础架构)</h3>
<p>事前准备：</p>
<pre><code>1.首先确保主库和从库的server_id是不同的，这个是必然的
2.主库必须打开binlog功能，你必须打开binlog功能，主库才会写binlog到本地磁盘，接着按照如下步骤
</code></pre>
<p>1.在主库上创建一个主从复制的账号</p>
<pre><code>create user 'backup_user'@'192.168.31.%' identified by 'backup_123';
grant replication slave on *.* to 'backup_user'@'192.168.31.%';
flush privileges;
</code></pre>
<p>2.如果主库跑了一段时间，现在要挂一个从库，应该在凌晨时，对主库和从库做一个数据备份和导入</p>
<pre><code>可以使用mysqldump工具把主库在这个时刻的数据全量备份，但是此时一定是不允许操作主库的，主库的数据时不能有变动的
/usr/local/mysql/bin/mysqldump --single-transaction -uroot -proot --master-data=2 -A &gt; backup.sql

注意，mysqldump工具就是在你的Mysql安装目录的bin目录下，然后用上述命令对你的主库所有的数据都做一个备份，
备份会以sql语句的方式进入指定的backup.sql 文件，只要执行backup.sql 就可以恢复出来跟主库一样的数据了

--master-data=2，是说备份的sql文件里，要记录一下此时主库的binlog文件和position号这是为了主从复制做准备的

接着从库执行下面的命令取执行主库进行复制

CHANGE MASTER TO MASTER_HOST='192.168.31.229',
MASTER_USER='backup_user',MASTER_PASSWORD='backup_123',MASTER_LOG_FILE='mysqlbin.000015',MASTER_LOG_POS=1689;

可能有人会疑惑，上面的master机器的ip地址我们是知道的，master上用于执行复制的用户名和密码是我们自己创建
的，也没问题，但是master的binlog文件和position是怎么知道的？这不就是之前我们mysqldump导出的
backup.sql里就有，大家在执行上述命令前，打开那个backup.sql就可以看到如下内容：
MASTER_LOG_FILE='mysql-bin.000015',MASTER_LOG_POS=1689
然后你就把上述内容写入到主从复制的命令里去了。
接着执行一个开始进行主从复制的命令：start slave，再用show slave status查看一下主从复制的状态，主要看到
Slave_IO_Running和Slave_SQL_Running都是Yes就说明一切正常了，主从开始复制了。
接着就可以在主库插入一条数据，然后在从库查询这条数据，只要能够在从库查到这条数据，就说明主从复制已经成
功了。
这仅仅是最简单的一种主从复制，就是异步复制，就是之前讲过的那种原理，从库是异步拉取binlog来同步的，所以
肯定会出现短暂的主从不一致的问题的，比如你在主库刚插入数据，结果在从库立马查询，可能是查不到的。
</code></pre>
<p>只要你搭建出来主从复制架构，就可以实现读写分离了<br>
可以用mycat 或者sharding-sphere之类的中间件，就可以实现你的系统写入主库，从库去读取</p>
<p>主从架构默认是异步的复制方式，意思是说主库把日志写入到binlog文件，接着自己提交事务返回了，他不管从库是否受到日志</p>
<p>如果主库宕机，从库切换为主库，可能发生数据丢失。</p>
<h5 id="主从半复制生产实践">主从半复制（生产实践）</h5>
<p>因此一般来说，搭建主从复制都是采用半同步的方式复制的，这个半同步的意思是，你主库写入数据，日志进入binlog之后，起码确保binlog<br>
日志复制到从库，才提交事务。</p>
<p>这个半同步复制的方式有两种</p>
<pre><code>    1.第一种叫做AFTER_COMMIT方式，他不是默认的，他的意思是说，主库写入日志到binlog，等待binlog日志复制到从库
    主库就提交自己的本地事务，接着就等待从库返回给自己一个成功的响应，然后主库就返回提交事务成功的响应给客户端。
</code></pre>
<p>（传统的搭建方式）<br>
搭建半复制也很简单，在搭建好异步复制的基础上，安装好版复制的插件就可以了，先在主库上安装半复制插件同时还得开启半复制功能</p>
<pre><code>install plugin rpl_semi_sync_master soname 'semisync_master.so';
set global rpl_semi_sync_master_enabled=on;
show plugins;
</code></pre>
<p>可以看到你安装了这个插件那就ok了</p>
<p>接着从库上页安装这个插件以及开启半复制功能：</p>
<pre><code>install plugin rpl_semi_sync_master soname 'semisync_master.so';
set global rpl_semi_sync_master_enabled=on;
show plugins;
</code></pre>
<p>接着要重启从库的IO线程：stop slave io_thread; start slave io_thread;</p>
<p>然后在主库上检查一下半同步复制是否正常运行：show global status like '%semi%';，如果看到了<br>
Rpl_semi_sync_master_status的状态是ON，那么就可以了。</p>
<p>到此半同步复制就开启成功了，其实一般来说主从复制都建议做成半同步复制，因为这样配合高可用切换机制，就可以保证数<br>
据库有一个在线的从库热备份主库的数据了，而且主要主库宕机，从库立马切换为主库，数据不丢失，数据库还高可用。</p>
<p>（GTID）搭建方式</p>
<p>首先在主库进行配置;</p>
<pre><code> gtid_mode=on
 enforce_gtid_consistency=on
 log_bin=on
 server_id=单独设置一个
 binlog_format=row
 接着在从库进行配置：
 gtid_mode=on
 enforce_gtid_consistency=on
 log_slave_updates=1
 server_id=单独设置一个

 接着按照之前讲解的步骤在主库创建好用于复制的账号之后，就可以跟之前一样进行操作了，比如在主库dump出来一
 份数据，在从库里导入这份数据，利用mysqldump备份工具做的导出，备份文件里会有SET
 @@GLOBAL.GTID_PURGED=***一类的字样，可以照着执行一下就可以了。
 接着其余步骤都是跟之前类似的，最后执行一下show master status，可以看到executed_gtid_set，里面记录的是执行
 过的GTID，接着执行一下SQL：select * from gtid_executed，可以查询到，对比一下，就会发现对应上了。
 那么此时就说明开始GTID复制了

其实大家会发现无论是GTID复制，还是传统复制，都不难，很简单，往往这就是比较典型的MySQL主从复制的搭建方
式了，然后大家可以自行搜索一下MyCat中间件或者是Sharding-Sphere的官方文档，其实也都不难，大家照着文档
做，整合到Java代码里去，就可以做出来基于主从复制的读写分离的效果了。
那些中间件都是支持读写分离模式的，可以仅仅往主库去写，从从库去读，这都没问题的。
如果落地到项目里，那么就完成了一个主从架构以及读写分离的架构了，此时按照我们之前所说的，如果说你的数据
库之前对一个库的读写请求每秒总共是2000，此时读写分离后，也许就对主库每秒写TPS才几百，从库的读QPS是
1000多。
那么万一你要是从库的读QPS越来越大，达到了每秒几千，此时你是不是会压力很大？没关系，这个时候你可以给主
库做更多的从库，搭建从库，给他挂到主库上去，每次都在凌晨搞，先让系统停机，对外不使用，数据不更新。
接着对主库做个dump，导出数据，到从库导入数据，做一堆配置，然后让从库开始接着某个时间点开始继续从主库复
制就可以了，一旦搭建完毕，就等于给主库挂了一个新的从库上去，此时继续放开系统的对外限制，继续使用就可以
了，整个过程基本在1小时以内。
如果在凌晨比如2点停机1小时，基本对业务是没有影响的。
</code></pre>
<h4 id="主从复制数据延迟问题">主从复制数据延迟问题</h4>
<p>为什么会产生主从延迟问题？</p>
<pre><code>其实很简单，其实你主库是多线程写入的，速度很快，从库是单个线程缓慢拉去数据，所以才会导致从库的复制数据的速度是比较慢的
</code></pre>
<p>主从复制的延迟实践监控</p>
<pre><code>这个可以用一个工具进行监控，比较推荐的是percona-toolkit工具集里的pt-hearbeat工具，他会在主库创建一个hearbeat表，
然后会有一个线程定时更新这个表里的时间戳字段，从库上就会有一个monitor线程会负责检查从库同步过来的hearbeat表里的时间戳。
把时间戳和当前时间对比一下就知道
</code></pre>
<p>如何缩小主从同步的延迟时间？</p>
<pre><code>其实就是让从库也用多线程并行复制数据就可以了，这样从库复制的速度很快，延迟就会很低了。
mysql5.7就已经支持并行复制了，可以在从库里设置slave_parallel_workers &gt;0,
然后把slave_parallel_type设为LOGICAL——CLOCK。
</code></pre>
<h4 id="高可用架构">高可用架构</h4>
<p>主从复制说白了就是允许主库把数据复制到从库上，然后允许我们的系统往主库里写数据，从库里读数据，实现一个读写分离的模式。</p>
<p>那么读写分离的模式确定了，接着就可以考虑一下数据库的高可用架构了，所谓的高可用架就是说数据库突然宕机，比如说主库或者从库宕机了，那么数据库还能正常使用吗？</p>
<p>如果主库真的宕机了，那就真的麻烦了，因为主库一旦宕机，你就没法写入数据，从库毕竟是不允许写入数据的，只允许读取。</p>
<p>所以数据库的高可用架构，可以实现主库宕机的同时，把从库切换为主库，然后所有的请求都基于现在的这台服务器去经行去读和写入。，</p>
<p>一般生产环境用于数据库高可用架构额管理工具MHA，是日本人写的，用peer脚本写一个工具，这个工具就是战门用于监控主库的状态，如果</p>
<p>感觉不对，就可以把从库切换为从库。</p>
<p>这个MHA也是需要单独部署的，分为两种节点，一个是Manager节点，一个是Node节点，Manager节点一般都是单独部署一台机器的<br>
Node节点一般都是部署在每天Mysql机器上的，因为Node节点通过通过解析各个Mysql的日志来进行一些操作</p>
<p>Manager节点会通过探测集群里的Node节点去判断各个Node所在机器上的MySQL运行是否正常，如果发现某个Master故障，就直接把Slave提升为Master，然后让<br>
其他Slave都挂到新的Master上去，完全透明。</p>
<h4 id="分库分表">分库分表</h4>
<p>要实现分库分表需要数据库中间件支持的，业内常用的一般有Sharding-Sphere以及Mycat两种，都是国内开源的。</p>
<p>一般建议Mysql单表数据量不超过1000万，最好在500万以内，如果内控制在100万以内，那是最佳的选择了，单表控制在100万以内，性能上不会有太大的问题，<br>
前提是你要建立好所有就行，其实保证Mysql高性能通常没有什么高深的技巧，就是控制数据量不要太大，另外只要保证你的查询用上了索引，所以一般就不会有问题。</p>
<p>一般分库分表时往往要考虑三个维度：<br>
1.一个是必然要按照主键id为粒度去分库分表，也就是把主键id进行hash后，对表数量进行取模，然后把数据均匀的分布到这些表中，<br>
再把这些表分散到多台数据库里。<br>
2.另外两个维度是用户端和运营端<br>
用户端：用户可能要查询自己的订单<br>
运营端：公司可能要查询所有的订单<br>
如何解决，针对用户端，你就需要按照(userids，主键id)这个表结构去做一个索引映射表，</p>
<p>userid和主键id的一一对应映射关系要放到这个表里，然后针对userid为粒度取进行分表分库</p>
<p>也就是对userid进行hash后取模，然后把数据均匀分散到很多索引映射表，再把表放到很多数据库里。</p>
<p>然后每次用户端拿出app查询自己的订单，直接根据userid取hash后取模路由到一个索引映射表，找到用户的userid</p>
<p>这里当然可以做一个分页了，先拿到所有的主键id，再根据主键id取对应的数据库里，去分库分表的表里提取完整数据。</p>
<p>至于运营端，一般都是根据N多个条件对数据经行搜索，此时跟上次将的一样，可以把数据的搜索条件放到es里面</p>
<p>然后用es来进行复杂搜索，找出一波主键id，再根据主键id去分库分表里找到完整数据。</p>
<p>分库分表的玩法基本都是这套思路，按业务id分库分表，建立索引映射表的同时进行分库分表，数据同步到es做复杂搜索，</p>
<p>基本这套玩法就可以保证你的分库分表的场景下，各种业务都可以执行</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[idea 找不到符号]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/idea-zhao-bu-dao-fu-hao/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/idea-zhao-bu-dao-fu-hao/">
        </link>
        <updated>2022-04-07T13:12:32.000Z</updated>
        <content type="html"><![CDATA[<p>在使用IDEA的时候，经常出现过找不到包或者找不到符号的情况，可以尝试以下几种方式来解决</p>
<p>1.如果项目使用的是Maven可以使用Maven-Reimport<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337559961.png" alt="" loading="lazy"><br>
2.还可以 Invalidate and Restart （无效并重新启动）<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337602794.png" alt="" loading="lazy"><br>
3.重新编译<br>
1.打开Project Structure --&gt;Modules 找到项目编译输出目录<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337677309.png" alt="" loading="lazy"><br>
2.将target目录下文件清空<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337720835.png" alt="" loading="lazy"><br>
3.右键项目重新build<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337751258.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[函数式编程]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/han-shu-shi-bian-cheng/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/han-shu-shi-bian-cheng/">
        </link>
        <updated>2022-04-05T13:58:04.000Z</updated>
        <content type="html"><![CDATA[<pre><code>行为参数化就是让一个方法接受多种不同的行为作为参数，并且在内部使用他们，完成不同行为的能力。
行为参数化可以让代码更好的适应不断变化的要求，减轻未来的工作量。
</code></pre>
<pre><code class="language-java">

</code></pre>
<p>-传递代码就是将新行为作为参数传递给方法。<br>
但是在Java8之前实现起来很啰嗦，在java8之前可以适应匿名内部类来减少，1.8可以使用lambda表达式来</p>
<p>关于stream的使用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[随笔]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/sui-bi/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/sui-bi/">
        </link>
        <updated>2022-04-05T07:58:50.000Z</updated>
        <content type="html"><![CDATA[<p>有些人并不是你的花 ，你只是途径了它的绽放。<br>
2022.04.04</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Cloud Alibaba底层原理]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/spring-cloud-alibaba-di-ceng-yuan-li/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/spring-cloud-alibaba-di-ceng-yuan-li/">
        </link>
        <updated>2022-03-27T12:30:32.000Z</updated>
        <content type="html"><![CDATA[<p>Spring Cloud Alibaba底层原理</p>
<p>组件</p>
<p>nacos：服务注册中心 配置中心</p>
<p>dubbo：RPC调用框架  负载均衡  远程调用</p>
<p>sentinel:限流</p>
<p>seata：分布式事务管理</p>
<figure data-type="image" tabindex="1"><img src="/Users/develop/code/java-stack/docs/framework/images/springcloudAlibaba.png" alt="img_1.png" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[UML]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/uml/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/uml/">
        </link>
        <updated>2022-03-27T11:32:04.000Z</updated>
        <content type="html"><![CDATA[<p>统一建模语言(Unified Modeling Language，UML)是一种为面向对象系统的产品进行说明、可视化和编制文档的一种标准语言，是非专利的第三代建模和规约语言。UML是面向对象设计的建模工具，独立于任何具体程序设计语言。</p>
<p>UML系统开发中有三个主要的模型： [3]<br>
功能模型：从用户的角度展示系统的功能，包括用例图。 [3]<br>
对象模型：采用对象，属性，操作，关联等概念展示系统的结构和基础，包括类别图、对象图。 [3]<br>
动态模型：展现系统的内部行为。包括序列图，活动图，状态图。 [3]</p>
<p>序列图（也叫左时序图，顺序图）</p>
<p>为什么要绘制时序图？<br>
我们编码的时候，知道有的用例的业务逻辑按照比较确定的时间先后顺序进行展开。这时候，我们就需要知道我们设计的系统中的不同类之间传递消息（可以认为是不同对象函数间的调用）要按照怎么样的顺序、传递什么消息、返回什么消息。这时候用时序图是最好不过的了</p>
<p>时序图的定义：</p>
<p>时序图是描述消息时间顺序的交互图。在图形上，时序图是一张表，其中显示的对象沿横轴排列，从左到右分布在图的顶部；而消息则沿纵轴按时间顺序排序。创建时序图时，以能够使图尽量简洁为依据布局。</p>
<p>时序图创建步骤</p>
<p>1、确定交互过程的上下文；</p>
<p>2、识别参与过程的交互对象；</p>
<p>3、为每个对象设置生命线；</p>
<p>4、从初始消息开始，依次画出随后消息；</p>
<p>5、考虑消息的嵌套，标示消息发生时的时间点，则采用FOC（focus of control）；</p>
<p>6、说明时间约束的地点。</p>
<p>时序图的元素<br>
我们在画时序图时会涉及7种元素：角色(Actor)、对象(Object)、生命线(LifeLine)、控制焦点(Activation)、消息(Message)、自关联消息、组合片段。其中前6种是比较常用和重要的元素，剩余的一种组合片段元素不是很常用，但是比较复杂。我们先介绍前6种元素，在单独介绍组合片段元素。</p>
<p>角色(Actor)<br>
系统角色，可以是人或者其他系统，子系统。以一个小人图标表示。<br>
对象(Object)<br>
对象位于时序图的顶部,以一个矩形表示。对象的命名方式一般有三种：<br>
1 对象名和类名。例如：华为手机:手机、loginServiceObject:LoginService。<br>
2 只显示类名，不显示对象，即为一个匿名类。例如：:手机、:LoginSservice。<br>
3 只显示对象名，不显示类名。例如：华为手机:、loginServiceObject:。<br>
生命线(LifeLine)<br>
时序图中每个对象和底部中心都有一条垂直的虚线，这就是对象的生命线(对象的时间线)。以一条垂直的虚线表。<br>
控制焦点(Activation)<br>
控制焦点代表时序图中在对象时间线上某段时期执行的操作。以一个很窄的矩形表示。<br>
消息(Message)<br>
表现代表对象之间发送的信息。消息分为三种类型。<br>
同步消息(Synchronous Message)<br>
消息的发送者把控制传递给消息的接收者，然后停止活动，等待消息的接收者放弃或者返回控制。用来表示同步的意义。以一条实线+实心箭头表示。<br>
异步消息(Asynchronous Message)<br>
消息发送者通过消息把信号传递给消息的接收者，然后继续自己的活动，不等待接受者返回消息或者控制。异步消息的接收者和发送者是并发工作的。以一条实线+大于号表示。<br>
返回消息(Return Message)<br>
返回消息表示从过程调用返回。以小于号+虚线表示。<br>
自关联消息<br>
表示方法的自身调用或者一个对象内的一个方法调用另外一个方法。以一个半闭合的长方形+下方实心剪头表示。</p>
<p>组合片段<br>
组合片段用来解决交互执行的条件和方式，它允许在序列图中直接表示逻辑组件，用于通过指定条件或子进程的应用区域，为任何生命线的任何部分定义特殊条件和子进程。组合片段共有13种，名称及含义如下：</p>
<p><img src="https://zuolinlin.github.io/zuo.github.io//post-images/1648381778972.png" alt="" loading="lazy"><br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1648381787741.png" alt="" loading="lazy"></p>
<p>常用组合片段举例</p>
<p>抉择（Alt）<br>
抉择在任何场合下只发生一个序列。 可以在每个片段中设置一个临界来指示该片段可以运行的条件。else 的临界指示其他任何临界都不为 True 时应运行的片段。如果所有临界都为 False 并且没有 else，则不执行任何片段。Alt片段组合可以理解为if..else if...else条件语句</p>
<p>选项（Opt）<br>
包含一个可能发生或不发生的序列。Opt相当于if..语句。</p>
<p>循环（Loop）<br>
片段重复一定次数，可以在临界中指示片段重复的条件。Loop相当于for语句。</p>
<p>并行（Par）<br>
并行处理，片段中的事件可以并行交错。Par相当于多线程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[navicat]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/navicat/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/navicat/">
        </link>
        <updated>2022-03-23T14:23:02.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>使用navicat生成逆向模型</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[git]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/git/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/git/">
        </link>
        <updated>2022-03-23T14:22:17.000Z</updated>
        <content type="html"><![CDATA[<p>Git高速下载地址：https://npm.taobao.org/mirrors/git-for-windows/</p>
<p><a href="hhttps://blog.csdn.net/unique_perfect/article/details/104833391">Git以及Github的使用</a></p>
]]></content>
    </entry>
</feed>