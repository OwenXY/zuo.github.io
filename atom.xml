<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zuolinlin.github.io/zuo.github.io/</id>
    <title>zuolinlin</title>
    <updated>2022-04-08T13:21:18.569Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zuolinlin.github.io/zuo.github.io/"/>
    <link rel="self" href="https://zuolinlin.github.io/zuo.github.io/atom.xml"/>
    <subtitle>你要问我如何去二仙桥，我会告诉你走成华大道，可你要问人生，我也说不清。</subtitle>
    <logo>https://zuolinlin.github.io/zuo.github.io/images/avatar.png</logo>
    <icon>https://zuolinlin.github.io/zuo.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, zuolinlin</rights>
    <entry>
        <title type="html"><![CDATA[redis]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/redis/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/redis/">
        </link>
        <updated>2022-04-08T13:20:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="redis">redis</h1>
<h2 id="目录">目录</h2>
<ul>
<li>
<p><a href="#redis%E6%9E%B6%E6%9E%84">redis架构</a></p>
<ul>
<li><a href="#Redis%E6%8C%81%E4%B9%85%E5%8C%96">redis持久化</a>
<ul>
<li><a href="#RDB%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6">RDB持久化机制</a></li>
<li><a href="#AOF%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6">AOF持久化机制</a></li>
</ul>
</li>
<li><a href="#Redis%E4%B8%BB%E4%BB%8E">redis主从</a></li>
<li><a href="#Redis%E5%93%A8%E5%85%B5">redis哨兵</a></li>
<li><a href="#Redis%E9%9B%86%E7%BE%A4">redis集群</a></li>
</ul>
</li>
<li>
<p><a href="#Redis%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7">redis双写一致性</a></p>
</li>
<li>
<p><a href="#Redis%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF">redis缓存雪崩、穿透、击穿</a></p>
</li>
<li>
<p><a href="#Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">redis分布式锁的实现原理</a></p>
</li>
<li>
<p><a href="#redis%E5%AE%9E%E6%88%98">redis实战</a><br>
-<a href="#string">string</a><br>
-[setnx](#setnx redis分布式锁实现)<br>
-<a href="#mset,mget,msetnx">mset,mget,msetnx</a><br>
-<a href="#append">append</a><br>
-<a href="#incr">incr</a><br>
-<a href="#decr">decr</a><br>
-<a href="#exists">exists</a><br>
-<a href="#exists">del</a><br>
-<a href="#type">type</a><br>
-<a href="EXPIRE">EXPIRE</a><br>
-<a href="#hash">hash</a><br>
-<a href="#hset,hget">hset,hget</a><br>
-<a href="#hincr,hdecr">hincr,hdecr</a><br>
-<a href="#list">list</a><br>
-<a href="#lpush">lpush</a><br>
-[BRPOP BLPOP](#BRPOP BLPOP)<br>
-[RPOPLPUSH BRPOPLPUSH](#RPOPLPUSH BRPOPLPUSH)<br>
-[LINDEX LSET LINSERT LTRIM LREM ](#LINDEX LSET LINSERT LTRIM LREM )<br>
-<a href="#set">set</a><br>
-<a href="#sadd">sadd</a><br>
-[BRPOP BLPOP](#BRPOP BLPOP)<br>
-[RPOPLPUSH BRPOPLPUSH](#RPOPLPUSH BRPOPLPUSH)<br>
-[LINDEX LSET LINSERT LTRIM LREM ](#LINDEX LSET LINSERT LTRIM LREM )</p>
<p>-[sorted set](#sorted set)<br>
-<a href="#HyperLoglog">HyperLoglog</a>；<br>
-<a href="#bitmap">bitmap</a><br>
-<a href="#GeoHash">GeoHash</a></p>
</li>
</ul>
<h1 id="redis-2">redis</h1>
<h2 id="目录-2">目录</h2>
<h3 id="redis架构">Redis架构</h3>
<h4 id="redis持久化">Redis持久化</h4>
<p>redis持久化机制对于故障恢复意义</p>
<pre><code>    数据备份和故障恢复，
    如果没有持久化，redis遇到灾难性故障的时候，就会丢失所有的数据，
    如果通过持久化将数据搞一份在磁盘上，然后定期同步到云服务器上，那么就可以保证数据不丢失全部，
    还是可以恢复一部分
</code></pre>
<h5 id="rdb持久化机制">RDB持久化机制</h5>
<p>RDB持久化机制原理介绍：每隔几分钟，生成redis内存数据的一份完整的快照<br>
缺点：redis故障恢复时，数据对丢失的比AOF更多<br>
主进程在fork RDB文件时，如果文件过大，可能导致服务暂停数毫秒，甚至数秒<br>
优点：1.RDB会生成多个数据文件，每个文件都代表了某一时刻中redis的数据，这种多个数据文件的方式，特别适合做冷备。<br>
2.RDB对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。<br>
3.相对于AOF来说，直接基于RDB来重启和恢复redis进程，更加快速<br>
AOF存放的是指令日志，做数据恢复的时候，其实要回放和执行所有指令日志，来恢复出来内存中的所有数据。<br>
RDB，就是一份数据文件，恢复的时候，直接加载到内存中即可</p>
<p>一般不要让redis的RDB间隔时间太长</p>
<h5 id="aof持久化机制">AOF持久化机制</h5>
<p>AOF持久化机制原理介绍：AOF机制对每条写入命令作为日志，以append-only的模式写入os cache 中，fsync 在将os cache数据输入缓存一个日志文件中，在redis重启的时候，<br>
可以通过回放AOF日志中的写入命令来重构整个数据集。<br>
如果我们想要redis仅仅作为纯内存的缓存来使用，那么可以禁止RDB和AOF所有持久化机制<br>
如果想要同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重构数据，因为AOF的数据更加完整<br>
缺点：<br>
优点：1.更好的保证数据不丢失，即使redis进程挂了，最多丢失1m的数据<br>
2.AOF日志文件以append-only模式写入，写入性能非常高<br>
3.AOF日志文件即使过大，出现后台重写操作，也不会影响客户端读写，因为在rewrite log的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来，<br>
在创建新日志文件的时候，老日志文件还是照常写入，当新的merge后日志文件ready的时候，再交换新老日志文件即可</p>
<p>RDB和AOF如何选择：<br>
redis是支持两种模式的持久化</p>
<h4 id="redis主从">Redis主从</h4>
<p>redis replication --&gt;  主从架构---&gt;读写分离---&gt;水平扩容支持高并发<br>
读多写少：</p>
<pre><code>一主多从，主负责写，并且将数据同步复制到其它slave节点，从节点负责读，所有的读请求全部走slave。
进行扩容的
</code></pre>
<p>redis replication的核心机制：</p>
<pre><code>    1.redis采用异步方式复制数据到slave节点，不过从redis 2.8开始，slave节点会周期性的确认自己每次复制数据量
    2.一个master 可以配置多个slave node 
    3.slave node也可以连接其它slave node 
    4.slave node做复制的时候是不会block master node 的正常工作的
    5.slave node在做复制的时候是不会block对自己的查询操作，它会用旧的数据集提供服务，但是复制完成时候，需要删除旧的数据集，加载新的数据集，这个时候会暂停对外的服务。
    6.slave node主要是用来做横向扩容的，增加slave node可以提高吞吐量
</code></pre>
<p>master 持久化对于主从架构安全保障的意义</p>
<pre><code>如果采用了主从架构，那么建议开启master node持久化

master 节点如果没有开启持久化机制，redis宕机之后，恢复时数据就是空的，同步到时候slave node数据也是空的，数据100%丢失。
</code></pre>
<p>redis主从复制的原理、断点续传、无磁盘化复制、过期key处理<br>
1.redis主从复制的原理</p>
<pre><code>    当启动一个slave node的时候，它会发送一个fsync命令给master node ，
    如果是slave node重新连接master node，那么master node仅仅会复制给slave node部分缺少的数据。
    否则，如果是slave node第一次连接master node，那么会触发一次full resynchronized
    
    开始full resynchronized的时候，master会启动一个后台线程，开始生成一份rdb快照，同时还会将客户端的所有写命令缓存到内存中，RDB
    生成完成之后，master 会讲这个rdb发送给slave ，slave先写入到本地磁盘，然后加载到内存，然后master会讲内存中的缓存写命令发送给slave，
    slave node也会同步这些数据
</code></pre>
<p>2.redis的断点续传</p>
<pre><code>    从redis2.0开始就支持断点续传，如果主从复制的过程中，网络连接突然断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头复制一份。
    master node会在内存中保存一个backlog，master和slave都会保存一个replica offset 还有一个master node id，
    offset就是保存在backlog中，如果master和slave node网络突然断掉了，slave node会让master node从上次replica offset开始继续复制
    但是如果没有找到对应的offset，那么会执行一次resynchronized
</code></pre>
<p>3.无磁盘化复制</p>
<pre><code>RDB在内存中直接创建rdb，然后发送给slave，不会在自己本地落磁盘了
</code></pre>
<p>4.过期key处理</p>
<pre><code>slave不会过期key，只会等待master过期key，如果msater过期了一个key或者通过lru淘汰了一个key，那么会模拟一条del 命令发送给slave。
</code></pre>
<h4 id="redis哨兵">Redis哨兵</h4>
<p>sentinal，中文名是哨兵，<br>
哨兵是redis集群架构中的一个非常重要的组建，主要功能如下<br>
(1).集群监控，负责监控redis master node和slave node进程是否正常工作<br>
(2).消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员<br>
(3).故障转移，如果master node挂掉了，那么会自动转移到slave node<br>
(4).配置中心，如果故障转移发生了，通知client客户端新的master上</p>
<p>哨兵本身也是分布式的，作为哨兵集群去运行，互相协同工作<br>
(1).故障转移时，判断一个master node是宕机了，需要大部分哨兵都同意才行，涉及到分布式选举到问题<br>
(2).即使部分哨兵节点挂掉了，哨兵集群还能正常工作，如果一个作为高可用的机制的重要组成部分故障转移系统本身是单点的，那就很坑爹了</p>
<p>目前采用的是sentinal 2版本，sentinal2 相对于sentinel 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加的健壮和简单</p>
<p>2.哨兵的核心知识</p>
<pre><code>(1).哨兵至少需要3个实例，来保证自己的健壮性
(2).哨兵+redis的主从架构，是不会保证数据0丢失的，只能保证redis集群的高可用
(3).对于哨兵+redis这种主从复杂的部署架构，尽量在测试和生产环境，都进行充足的测试和演练
</code></pre>
<p>3.为什么redis哨兵集群只有两个节点时无法正常工作</p>
<pre><code>哨兵集群必须部署2个以上的节点
如果哨兵集群仅仅部署了2个哨兵实例，quorum =1 ：表示有（1）多少个哨兵觉得master宕机了，就可以进行切换了，这个时候会尝试进行故障转移
M1       R1 
S1       S2

master宕机，s1和s2中只要有1个哨兵认为master宕机，就可以进行切换，同时s1  和s2中会选举出一个哨兵
来执行故障转移
同时这个时候，需要majority =2,也就是大多数哨兵是运行的，2个哨兵的majority就是2，2个哨兵都运行着，就可以允许故障转移

但是如果整个m1和s1运行的机器宕机了，那么哨兵只要一个了，此时就没有majority来允许执行故障转移了
虽然还有一台机器r1，但是故障转移不会执行
</code></pre>
<p>经典的3个哨兵集群</p>
<pre><code>M1       R1      R2
S1       S2      S3
quorum =2 表示有（2）多少个哨兵觉得master宕机了，就可以进行切换了，这个时候会尝试进行故障转移
majority =2 2个哨兵的majority就是2，2个哨兵都运行着，就可以允许故障转移 ， 同时s2  和s3中会选举出一个哨兵
来执行故障转移
</code></pre>
<p>哨兵主备切换的数据丢失问题：异步复制，集群脑裂</p>
<p>异步复制导致的数据丢失问题</p>
<pre><code>这个旧的master node内存里的那些数据还没来的及给是slave node 就挂掉了。
slave node就成了master node，那些内存中没来得及复制的数据不就丢失了吗
</code></pre>
<p>集群脑裂导致的数据丢失问题</p>
<pre><code>脑裂，也就是master所在的机器突然脱离了正常的网络，跟其它slave node机器不能连接，但是实际上master node运行着，
此时哨兵可能就会认为master宕机了，然后开启选举，将其它slave node 切换成master 
这个时候，集群中就有两个master，也就是所谓的脑裂。
此时虽然某个slave node被切换成了master ，但是可能client 还没来得及切换到新的master，还继续写向旧的master，
因此旧master再次恢复的时候，会作为slave挂载到存的master上去，自己的数据会清空，重新从新的master复制数据
</code></pre>
<p>解决异步复制和脑裂导致的数据丢失问题</p>
<pre><code>    min-slaves-to-write 1 
    min-slaves-max-lag 10
    要求至少有1个slave node，复制数据和同步的延迟不超过10s
    如果说一旦所有的slave，复制数据和同步数据都超过了10s，那么这个时候master将不在接受任何请求
    以上两个配置可以减少异步复制和脑裂的数据丢失问题

    (1).减少异步复制的数据丢失问题  
    min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就可以拒绝写请求，
    这样就可以把master宕机时由于部分数据未同步到slave node导致的数据丢失降低在可控范围内。
    (2).减少脑裂的数据丢失问题
    如果一个master出现了脑裂，跟其它slave node丢了连接，那么上面的两个配置可以确保的说，如果不能继续给指定数量的slave发送数据，而且slave node
    超过10s没有给自己ack消息，那么就直接拒绝客户端的写请求
    这样脑裂后旧的master就不会接受新的client 的新数据，也就避免了数据丢失
    以上的配置就确保了，如果跟任何一个slave node丢失了连接，在10s之内发现slave没有给自己ack，那么久拒绝新的写请求
</code></pre>
<p>sdown和odown转换机制</p>
<pre><code>sdown是主观宕机，就是一个哨兵就是自己觉得一个master宕机了，那么就是主观宕机
odown是客观宕机，如果quorum数量的哨兵都觉得一个mastar宕机了，那么就是客观宕机
sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-masterHost-down-millisecondssecond
指定的毫秒数之后，就主观认为master宕机了
sdown到odown的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其它哨兵也认为那个master sdown 
那么就任务odown 
</code></pre>
<p>哨兵和slave自动发现机制</p>
<pre><code>    哨兵互相之间的发现是通过redis 的pub/sub系统实现的，每个哨兵都会放_sentinel_:hello这个
    channel里发送一个消息，这个时候其它哨兵就可以消费到这条消息，并感知其它哨兵的存在
    每隔两秒钟，每个哨兵都会往自己监控的某个master+slave对应的 _sentinel_:hello channel 里发送一个消息，
    内容是自己的host  ip 和runid，还有这个对应master的监控配置
    每个哨兵也会监听自己监控的某个master+slave对应的 _sentinel_:hello channel，然后去感知到同样在监听这个master +slave的其它哨兵的存在。
    每个哨兵还会跟其它哨兵交换对master的监控配置，互相进行监控配置的同步
</code></pre>
<p>slave --&gt; master选举算法</p>
<p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举出一个slave来<br>
会考虑slave的一些信息</p>
<pre><code>(1).跟master断开连接的时长
(2).slave node优先级
(3).run id
(4).复制的offset

接下来会对slave进行排序

（1).按照slave的优先级进行排序，slave node priority越低优先级越高
（2).如果slave node priority相同，那么看replica offset ，哪个slave复制了越多的数据，offset越靠后，优先级就越高。
 (3).如果 上面两个条件都相同，那么选择一个run id比较小的那个slave
</code></pre>
<p>slave配置的自动纠正</p>
<pre><code>哨兵会自定纠正slave的一些配置，比如slave node如果要成为潜在的master候选人，哨兵会确保slave node在复制现有master的数据
，如果slave连接到错误的master上，比如故障转移之后，哨兵会确保他们连接到正确的master上
</code></pre>
<p>quorum和majority</p>
<pre><code>每一次一个哨兵要做主备切换，首先要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，
，这个哨兵还的得到majority哨兵的授权，才能正式执行切换，
但是如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵quorum是5，那么必须5个哨兵都同意授权，才能进行切换。
</code></pre>
<p>configuration epoch</p>
<pre><code>哨兵会对一套redis master +slave 进行监控，有相应监控的配置
会执行切换的那个哨兵，会从要切换到新的master（slave -&gt; master）那里会得到一个configuration epoch。这就是一个version号，每次切换的version必须是唯一的。
如果第一个选举出来的哨兵都失败了，那么其它哨兵，会等待failover-timeout时间，然后接替者继续切换此时会从新获取一个新的configuration epoch
作为新的版本号
</code></pre>
<p>configuration 传播</p>
<pre><code>    哨兵切换之后，会在自己本地更新生成最新的master配置，然后同步给其它的哨兵，所以就是通过之前所说的pub/sub消息机制
    这里之前的version号就很重要了，因为各种消息是通过channel发布和监听的，所以一个哨兵完成一次新的切换之后，
    新的master配置是跟着新的version号的，其它哨兵都是根据版本号大小更新自己的master配置
</code></pre>
<h4 id="redis集群">Redis集群</h4>
<p>主从架构的缺点：master节点的数据和slave节点的数据是一摸一样的，<br>
master最大能容纳多大的数据量，那么slave最多能容纳多大数据量</p>
<p>redis Cluster 可以支持多个master ，每个master都会挂载多个slave<br>
也支持读写分离的架构，对于每个master来说，写就写到master，然后读就从master对应的slave上读<br>
高可用，因为每个master都有slave节点，那么如果master挂掉，redis cluster 会自动将slave切换成master</p>
<p>redis cluster （多master+读写分离+高可用）</p>
<p>Redis cluster 主要针对海量数据+高并发+高可用的场景</p>
<p>Redis cluster介绍</p>
<pre><code>(1).自动将数据分片，每个master上放一部分数据
(2).提供内置的高可用支持，部分master不可用时，还可以继续工作
在redis cluster架构下，每个redis要开放两个端口号，一个是6379 另一个是加10000的端口号16379。
16379端口号是用于节点间通信的，也就是cluster bus的东西，集群总线，cluster bus的通信，用于进行故障检验，配置更新
故障转移授权
</code></pre>
<p>redis 数据分布算法<br>
1.hash算法<br>
2.一致性hash算法</p>
<h3 id="redis双写一致性">Redis双写一致性</h3>
<p>1.读的时候，先读缓存，缓存没有，在读数据库，设置缓存<br>
2.更新时候，先删除缓存，然后在更新数据库<br>
如果直接更新缓存，在更新数据库，如果在更新缓存的成功了，更新数据库失败了，下次读取的时候，直接读缓存，那么数据还是旧数据，缓存和数据库不一致</p>
<h3 id="redis缓存雪崩-穿透-击穿">Redis缓存雪崩、穿透、击穿</h3>
<h4 id="缓存雪崩">缓存雪崩，</h4>
<pre><code>是指缓存机器意外发生了全盘宕机，缓存挂了，导致请求全部落在数据库，数据库也支撑不住。
</code></pre>
<p>解决方案如下：<br>
事前：redis高可用，主从+哨兵，redis cluster避免全盘数据崩溃<br>
事中：本地缓存+hystrix限流降级，避免mysql被打死<br>
事后：redis持久化，一旦重启，自动从磁盘中加载数据到缓存，快速恢复缓存数据</p>
<h4 id="缓存穿透">缓存穿透</h4>
<pre><code>很多请求是黑客恶意发送的，缓存中查不到，每次去数据库也查不到
，这种恶意的请求就直接把数据库打死
</code></pre>
<p>解决办法；<br>
只要数据库没查到，就设置一个空值到缓存，返回设置一个过期时间，这样的话，下次有相同的key</p>
<h4 id="缓存击穿">缓存击穿</h4>
<pre><code>    某个key非常热点，访问非常频繁，处于集中式高并发访问的情况
    当这个key在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库
</code></pre>
<p>解决方案如下：</p>
<pre><code>    可以将热点数据设置为永远不过期，或者基于redis or zookeeper实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而
    其它请求也能通过该key访问数据
</code></pre>
<h4 id="redis分布式锁的实现原理">Redis分布式锁的实现原理</h4>
<p>如果说公司里落地生产环境用分布式锁的时候，一般都会使用开源类库，比如redis的分布式锁，一般就是用redisson框架就好了，非常简单易用。</p>
<pre><code class="language-java">
 /**
   * @author ChengJianSheng
   * @date 2019-07-30
   */
    @Slf4j
   @Service
  public class OrderServiceImpl implements OrderService {
     @Autowired
     private StockService stockService;
     @Autowired
     private OrderRepository orderRepository;
     @Autowired
     private RedissonClient redissonClient;
     /**
       * 乐观锁
       */
             @Override
     public String save(Integer userId, Integer productId) {
                 int stock = stockService.getByProduct(productId);
                 log.info(&quot;剩余库存：{}&quot;, stock);
                 if (stock &lt;= 0) {
                         return null;
                 }
                 //  如果不加锁，必然超卖
                 RLock lock = redissonClient.getLock(&quot;stock:&quot; + productId);
                 try {
                         lock.lock(10, TimeUnit.SECONDS);
                         //扣减库存
                        redissonClient.decr();
                         String orderNo = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;).toUpperCase();
                         if (stockService.decrease(productId)) {
                                 OrderModel orderModel = new OrderModel();
                                 orderModel.setUserId(userId);
                                 orderModel.setProductId(productId);
                                 orderModel.setOrderNo(orderNo);
                                 Date now = new Date();
                                 orderModel.setCreateTime(now);
                                 orderModel.setUpdateTime(now);
                                 orderRepository.save(orderModel);
                                 return orderNo;
                             }
            
                     } catch (Exception ex) {
                         log.error(&quot;下单失败&quot;, ex);
                     } finally {
                         lock.unlock();
                     }
        
                 return null;
             }
         }

</code></pre>
<p>⼆、Redisson 实现 Redis 分布式锁的底层原理</p>
<p>（1）加锁机制<br>
首先一个客户端1会hash算法，选择一台机器，紧接着发送一段lua脚本到redis上<br>
<img src="img_1.png" alt="img_1.png" loading="lazy">，<br>
这一段脚本就是保证复杂业务的原子性，</p>
<p>RLock lock = redisson.getLock(&quot;myLock);<br>
先会走一个判断 exists mylock，如果你要加的那个锁的那个key不存在的话你就执行加锁</p>
<pre><code>hset mylock 客户端id：1 1
如果出现了一个这样的数据结构说明加锁成功
</code></pre>
<p>（2）锁互斥机制<br>
同样客户端过来尝试加锁，执行一段同样的lua脚本，会咋样？<br>
先会走一个判断 exists mylock，如果你要加的那个锁的那个key不存在的话你就执行加锁<br>
发现myLock这个锁key已经存在了。</p>
<pre><code>接着走第二个if判断，判断一下myLock锁key的hash数据结构中，是否包含了客户端2 的id 
但是很明显，那里只包含了客户端1的id
所以客户端2 会获取到pttl myLock返回一个数字，这个数字代表了myLock这个锁key的剩余生存是时间，比如还剩15000 毫秒的生存时间
此时客户端2 ，会进入一个while循环，不停的尝试加锁
</code></pre>
<p>（3）watch dog ⾃动延期机制</p>
<pre><code>客户端1加锁的锁key默认生存时间才30s，如果超过了30s，客户端1还想持有这把锁怎么办？
简单，客户端1一旦加锁成功，就会启动一个watch dog 看门狗，它是一个后台线程，会每隔10s检查一下
如果客户端1还持有锁key，那么就会不断延长锁key的生存时间
</code></pre>
<p>（4）可重⼊加锁机制<br>
如果客户端1已经持有了锁，再次加锁，依然执行命令，加锁次数累计加1</p>
<p>（5）锁释放机制<br>
如果执行lock.unLock()，就可以释放分布式锁，此时的业务逻辑也非常简单<br>
其实说白了，就是每次都对myLock数据结构的那个加锁次数减1。<br>
如果发现加锁次数是0了，那么说明客户端不再持有锁了，此时就会用<br>
del mylock 命令，从redis里面删除这个key</p>
<p>（6）此种⽅案 Redis 分布式锁的缺陷</p>
<pre><code>其实上⾯那种⽅案最⼤的问题，就是如果你对某个 redis master 实例，写⼊了 myLock 这种锁 key 的 value，此时会异步复制给对应的 master slave 实例。
但是这个过程中⼀旦发⽣ redis master 宕机，主备切换，redis slave 变为了 redis master。 接着就会导致，客户端 2 来尝试加锁的时候，在新的 redis master 上完成了加锁，⽽客户端 1
也以为⾃⼰成功加了锁。 此时就会导致多个客户端对⼀个分布式锁完成了加锁。 这时系统在业务语义上⼀定会出现问题，导致各种脏数据的产⽣。 
所以这个就是 redis cluster，或者是 redis master-slave 架构的主从异步复制导致的 redis 分布式 锁的最⼤缺陷：在 redis master 实例宕机的时候，可能导致多个客户端同时完成加锁。
</code></pre>
<figure data-type="image" tabindex="1"><img src="img.png" alt="img.png" loading="lazy"></figure>
<h3 id="redis实战">Redis实战</h3>
<h4 id="string">String</h4>
<h5 id="setnxredis分布式锁实现">Setnx(redis分布式锁实现)</h5>
<pre><code>分布式锁
命令：
set mykey newval nx
set mykey newval xx

java：
//加锁
jedis.set(&quot;locks_test&quot;, &quot;value_test&quot;,SetParams.setParams().nx())
//释放锁
jedis.del(&quot;locks_test&quot;);
必须是这个key此时是不存在的，才能设置成功，如果说key要是存在了，此时设置失败
</code></pre>
<h5 id="msetmgetmsetnx">mset,mget,msetnx</h5>
<pre><code>命令
mset a 10 b 20 c 30
mset a 10 b 20 c 30

java 
mset:一下子设置多个key-value对
mget:一下子获取多个key的value 
msetnx:就是多个key都不存在的情况下，一次性设置多个key的value,只要key都不存在才能成功
mset和mgt相当于batch批量设置和查询，比如说加入你要一次性要往redis里塞入
20条数据
//新增或修改
jedis.mset(&quot;key:key&quot;,&quot;value&quot;,&quot;key:key1&quot;,&quot;value2&quot;)
//新增，key不能存在
jedis.msetnx(&quot;key:key&quot;,&quot;value&quot;,&quot;key:key1&quot;,&quot;value2&quot;)
//获取
jedis.mget(&quot;key:key&quot;,&quot;key:key1&quot;)
// 获取value长度
jedis.strlen(&quot;key:key&quot;)
//截取 value的字符
jedis.getrange(&quot;key:key&quot;，0，5)
</code></pre>
<h5 id="append">append</h5>
<pre><code>日志审计
redis append api 就是不停的把数据追加到指定的key里去
jedis.append(key,value);
</code></pre>
<h5 id="incr">incr</h5>
<pre><code>生成唯一id/（点赞）
命令：
set counter 100
incr counter
incrby counter 50

INCR 命令将字符串值解析成整型，将其加一，最后将结果保存为新的字符串值，类似的命令有INCRBY, DECR 和 DECRBY。实际上他们在内部就是同一个命令，只是看上去有点儿不同。
INCR是原子操作意味着什么呢？就是说即使多个客户端对同一个key发出INCR命令，也决不会导致竞争的情况。例如如下情况永远不可能发生：『客户端1和客户端2同时读出“10”，他们俩都对其加到11，然后将新值设置为11』。最终的值一定是12，read-increment-set操作完成时，其他客户端不会在同一时间执行任何命令。
对字符串，另一个的令人感兴趣的操作是GETSET命令，行如其名：他为key设置新值并且返回原值。这有什么用处呢？例如：你的系统每当有新用户访问时就用INCR命令操作一个Redis key。你希望每小时对这个信息收集一次。你就可以GETSET这个key并给其赋值0并读取原值。

java
jedis.incr(&quot;key&quot;);
</code></pre>
<h5 id="decr">decr</h5>
<pre><code>抢购
命令：
set counter 100
自增
incr counter
</code></pre>
<h5 id="exists">exists</h5>
<pre><code>命令
exists mykey
EXISTS命令返回1或0标识给定key的值是否存在
</code></pre>
<h5 id="del">del</h5>
<pre><code>使用DEL命令可以删除key对应的值，DEL命令返回1或0标识值是被删除(值存在)或者没被删除(key对应的值不存在)。
</code></pre>
<h5 id="type">type</h5>
<pre><code>TYPE命令可以返回key对应的值的存储类型：
命令
type mykey
</code></pre>
<h5 id="expire">EXPIRE</h5>
<pre><code>EXPIRE来设置超时时间(也可以再次调用这个命令来改变超时时间，使用PERSIST命令去除超时时间 )。
命令
set key some-value
expire key 5
也可以在创建值的时候设置超时时间:
set key 100 ex 10

TTL命令用来查看key对应的值剩余存活时间。
ttl key
</code></pre>
<h4 id="hash">hash</h4>
<p>Hash 便于表示 objects，实际上，你可以放入一个 hash 的域数量实际上没有限制（除了可用内存以外）。所以，你可以在你的应用中以不同的方式使用 hash</p>
<h5 id="hsethget">hset,hget</h5>
<pre><code>值得注意的是，小的 hash 被用特殊方式编码，非常节约内存。
# 获取
hget user:1000 username
hgetall user:1000
hmget user:1000 username birthyear no-such-field
# 将value +10
hincrby user:1000 birthyear 10

HMSET 指令设置 hash 中的多个域，而 HGET 取回单个域。HMGET 和 HGET 类似，但返回一系列值：



基于token令牌的登陆会话机制：
用户平时在访问我们的系统，在处理任何一个请求之前，必须检查这个请求是否带上了一个令牌，
如果带上了这个令牌，那么此时必须在redis里检查一下，这个令牌是否在redis里合法，有效的session会话。

如果有这个session会话，那么此时可以允许这个请求被处理，说明这个人已经登陆过我们的系统，登陆之后在会在
redis里放一个有效的session会话，
如果说没有这个session会话，此时就会导致用户被迫强制登陆
如果用户登陆之后，就会返回浏览器或者客户端一块令牌，同时在redis里初始化ession会话，后续客户端
就会在指定时间范围内发送请求的时候，带上一块令牌，每次令牌和服务端的session校验通过就可以执行请求
过一段时间过后，服务端的redis里的session会话就会过期，过期之后又回导致你重新登陆。
</code></pre>
<h4 id="list">list</h4>
<p>常用案例</p>
<pre><code>秒杀活动下利用公平队列的抢购机制   待办事项  

秒杀系统有很多实现方式，其中一种技术方案，就是对所有涌入系统的秒杀抢购请求，都放入redis里的一个linhuatest
数据结构中去，进行公平队列排队，然后入队之后等待秒杀结果，专门搞一个消费者从redis 里面按顺序
获取抢购请求，按顺序进行库存扣减，扣减成功了，就让抢购成功。

如果说你要是不要公平队列的话，可能会导致你很多抢购请求进来，大家都在尝试去扣减库存
 此时可能先涌入进来的请求并没有先对redis进行抢购请求，此时可能后进入的请求先执行了抢购请求，此时就是不公平的

公平队列：基于redis里的list数据结构，搞一个队列，抢购请求先进队列，先入先出，先进来的人先抢购，此时就是公平的。

对于抢购队列，就用lpush list 就可以了，然后对出队的队列进行抢购
</code></pre>
<h5 id="lpush">lpush</h5>
<pre><code> LPUSH 命令可向list的左边（头部）添加一个新元素，而RPUSH命令可向list的右边（尾部）添加一个新元素。最后LRANGE 命令可从list中取出一定范围的元素:
//从左边(头部)添加元素
lpush mylist A
//从右边(尾部)添加元素
rpush mylist A
//从尾部开始，指定范围获取元素
lrange mylist 0 -1

注意:LRANGE 带有两个索引，一定范围的第一个和最后一个元素。这两个索引都可以为负来告知Redis从尾部开始计数，因此-1表示最后一个元素，-2表示list中的倒数第二个元素，以此类推。

rpop mylist
lpop mylist
pop,它从list中删除元素并同时返回删除的值。可以在左边或右边操作



List上的阻塞操作
可以使用Redis来实现生产者和消费者模型，如使用LPUSH和RPOP来实现该功能。但会遇到这种情景：list是空，这时候消费者就需要轮询来获取数据，这样就会增加redis的访问压力、增加消费端的cpu时间，而很多访问都是无用的。
 为此redis提供了阻塞式访问 BRPOP 和 BLPOP 命令。 消费者可以在获取数据时指定如果数据不存在阻塞的时间，如果在时限内获得数据则立即返回，如果超时还没有数据则返回null, 0表示一直阻塞。

同时redis还会为所有阻塞的消费者以先后顺序排队。

如需了解详细信息请查看 RPOPLPUSH 和 BRPOPLPUSH。
</code></pre>
<h5 id="brpop-blpop">BRPOP BLPOP</h5>
<pre><code>BRPOP 是一个阻塞的列表弹出原语。 它是 RPOP 的阻塞版本，因为这个命令会在给定list无法弹出任何元素的时候阻塞连接。 该命令会按照给出的 key 顺序查看 list，并在找到的第一个非空 list 的尾部弹出一个元素。

请在 BLPOP 文档 中查看该命令的准确语义，因为 BRPOP 和 BLPOP 基本是完全一样的，除了它们一个是从尾部弹出元素，而另一个是从头部弹出元素。

BRPOP list1 list2 0

返回值
多批量回复(multi-bulk-reply): 具体来说:

当没有元素可以被弹出时返回一个 nil 的多批量值，并且 timeout 过期。
当有元素弹出时会返回一个双元素的多批量值，其中第一个元素是弹出元素的 key，第二个元素是 value。
</code></pre>
<h5 id="rpoplpush-brpoplpush">RPOPLPUSH BRPOPLPUSH</h5>
<h5 id="lindex-lset-linsert-ltrim-lrem">LINDEX LSET LINSERT LTRIM LREM</h5>
<pre><code>LINDEX：返回指定位置的数据
LSET：设置指定位置的数据
LINSERT：往指定位置插入数据
LTRIM：然后保留指定的数据，删掉一些数据
LREM：删掉一些数据
</code></pre>
<h4 id="set">set</h4>
<pre><code>案例 抽奖  公共关注  推荐关注 微博关系 点赞 uv
无序且不重复的数据集合
</code></pre>
<h5 id="sadd">sadd</h5>
<pre><code> 添加元素
 sadd myset 1 2 3

返回所以元素
smembers myset


现在我已经把三个元素加到我的 set 中，并告诉 Redis 返回所有的元素。可以看到，它们没有被排序 —— Redis 在每次调用时可能按照任意顺序返回元素，因为对于元素的顺序并没有规定。

判断元素是否存在
sismember myset 30

返回所以元素
srem myset

取交集
sinter tag:1:news tag:2:news tag:10:news tag:27:news 

对多个集合取并集
sunionstore game:1:deck deck

取差集
sdiffstore new——set  set1 set2

获取随机元素

spop game:1:deck   随机从set里弹出几个元素

srandmember
</code></pre>
<h5 id="scard">scard</h5>
<pre><code> scared 获取key数据总数
</code></pre>
<h4 id="sorted-set">sorted set</h4>
<pre><code>案例  推荐商品  排行榜  自动补全

sorted set不能又重复数据，加入进去的每一个数据都可以带一个分数，它在里面的数据都是按照分数排序的、
有序的set 自动按照分数来排序，相当于你可以定制它的排序规则

添加
zadd hackers 1940 &quot;Alan Kay&quot;

查询   从索引0 到最后一个元素 分数排序
zrange hackers 0 -1

如果我想按相反的顺序，从最小的到最大的顺序，怎么办？使用ZREVRANGE而不是ZRANGE：
zrevrange hackers 0 -1

询问元素在有序元素集中的位置
zrank hackers &quot;Anita Borg&quot;


搜索结果返回分数
zrange hackers 0 -1 withscores
zrevrange hackers 0 -1 withscores

搜索指定分数范围内的数据
zrangebyscore hackers -inf 1950

根据指定分数搜索后删除
zremrangebyscore hackers 1940 1960

ZRANGEBYLEX，我们可以查询字典范围：
zrangebylex hackers [B [P

将分数自增
zincrby
</code></pre>
<h4 id="hyperloglog">HyperLoglog</h4>
<pre><code>案例  日活 网站垃圾数据去重或者过滤

HyperLoglog ，数据结构+概率算法 组合而成的，去重统计 近似数

 如果基于set来计数，太耗费内存，基于HyperLoglog算法来计数，是近似数，有
  0.8%误差，但是误差不会太大，可以给出一个相对准确的近似数，而且就占12KB内存

每次看到新元素时，都要使用PFADD将其添加到计数中。
pfadd hll a b c d 
    
每次要检索迄今为止使用PFADD添加的唯一元素的当前近似值时，都要使用PFCOUNT
pfcount hll


pfmerge  
</code></pre>
<h4 id="bitmap">bitmap</h4>
<pre><code>bitmap位图：二进制里的一位一位的，字符串，int ，long double 都可以用二进制表示
在二进制中都是表示多少位，一个字节是8位的二进制数
int 就是四个字节 就是32位
我可以直接在redis里操作二进制的位数据。

可以把网站里的每一种操作，每天执行过的用户放在一个位图里，
一个用户仅仅代表一位而已

案例 ：基于位图用户行为记录程序
如果说你要记录一下，在系统里执行一些特殊操作，每天执行过某个操作的用户有多少个人
操作日志，审计日志，
记录下来每个用户每天做了哪些操作

 设置位图
 setbit key offset 1
 表示把 这个offset 对应位图的位置设置位1

getbit key value
</code></pre>
<h4 id="geohash">GeoHash</h4>
<pre><code>geoadd key longitude latitude user 
geoadd key longitude latitude shop 
geodist key user shop init ='KM'_ 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/mysql/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/mysql/">
        </link>
        <updated>2022-04-08T13:18:19.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mysql">mysql</h1>
<h2 id="目录">目录</h2>
<ul>
<li>
<p><a href="#Mysql%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84">mysql基础架构</a></p>
<ul>
<li><a href="#Mysql%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1">mysql架构设计</a></li>
<li><a href="#InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1">InnoDB存储引擎的架构设计</a>
<ul>
<li>[buffer pool](#buffer pool)</li>
<li>[redo log](#redo log)</li>
<li>[undo log](#undo log)</li>
</ul>
</li>
<li><a href="#%E4%BA%8B%E5%8A%A1">事务</a>
<ul>
<li><a href="#%E5%A4%9A%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E6%9B%B4%E6%96%B0%E6%88%96%E8%80%85%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98">多事务并发更新或者查询的数据问题</a>
<ul>
<li><a href="#%E8%84%8F%E5%86%99">脏写</a></li>
<li><a href="#%E8%84%8F%E8%AF%BB">脏读</a></li>
<li><a href="#%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB">不可重复读</a></li>
<li><a href="#%E5%B9%BB%E8%AF%BB">幻读</a></li>
</ul>
</li>
<li><a href="#SQL%E6%A0%87%E5%87%86%E4%B8%AD%E5%AF%B9%E4%BA%8B%E5%8A%A1%E7%9A%844%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">SQl对事务的四种隔离级别</a>
<ul>
<li><a href="#%E8%AF%BB%E6%9C%AA%E6%8F%90%E4%BA%A4">read uncommitted</a></li>
<li><a href="#%E8%AF%BB%E5%B7%B2%E6%8F%90%E4%BA%A4">read committed</a></li>
<li><a href="#%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB">repeatable</a></li>
<li><a href="#%E4%B8%B2%E8%A1%8C%E5%8C%96">serializable</a></li>
</ul>
</li>
<li><a href="#%E9%80%8F%E5%BD%BB%E5%89%96%E6%9E%90Mysql%E7%9A%84MVCC%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6">透彻剖析Mysql的MVCC事务隔离机制</a>
<ul>
<li>[undo log版本链](#Undo log版本链)</li>
<li><a href="#ReadView%E6%9C%BA%E5%88%B6">ReadView机制</a></li>
<li>[Read Committed隔离级别是如何基于ReadView机制实现的？](#Read Committed隔离级别是如何基于ReadView机制实现的？)</li>
<li><a href="#MySQL%E6%9C%80%E7%89%9B%E7%9A%84RR%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%EF%BC%8C%E6%98%AF%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8EReadView%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F">MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？</a></li>
</ul>
</li>
<li><a href="#%E5%A4%9A%E4%B8%AA%E4%BA%8B%E5%8A%A1%E6%9B%B4%E6%96%B0%E5%90%8C%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%97%B6%EF%BC%8C%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E9%94%81%E9%81%BF%E5%85%8D%E8%84%8F%E5%86%99%E7%9A%84%EF%BC%9F">多个事务更新同一行数据时，是如何加锁避免脏写的？</a>
<ul>
<li><a href="#%E5%85%B1%E4%BA%AB%E9%94%81">共享锁</a></li>
<li><a href="#%E7%8B%AC%E5%8D%A0%E9%94%81">独占锁</a></li>
</ul>
</li>
<li><a href="#%E7%B4%A2%E5%BC%95">索引</a>
<ul>
<li><a href="#%E7%A3%81%E7%9B%98%E4%B8%8A%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">磁盘上数据页的存储结构</a></li>
<li><a href="#%E9%A1%B5%E5%88%86%E8%A3%82%E7%9A%84%E8%BF%87%E7%A8%8B">页分裂的过程</a></li>
<li><a href="#%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95">主键索引</a></li>
<li><a href="#B+%E6%A0%91%E5%AE%9E%E7%8E%B0%E7%B4%A2%E5%BC%95%E7%9A%84%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84">B+树实现索引的物理结构</a></li>
<li><a href="#%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95">聚簇索引</a></li>
<li><a href="#%E9%92%88%E5%AF%B9%E4%B8%BB%E9%94%AE%E4%B9%8B%E5%A4%96%E7%9A%84%E5%85%B6%E4%BB%96%E5%AD%97%E6%AE%B5%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8E%9F%E7%90%86">针对主键之外的其他字段建立索引的原理</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">索引的优缺点</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E8%A7%84%E5%88%99">索引的使用规则</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99">索引的设计规则</a></li>
<li><a href="#%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92">执行计划</a></li>
<li><a href="#sql%E8%B0%83%E4%BC%98">sql调优</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#mysql%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B">mysql数据模型</a>
<ul>
<li><a href="#VARCHAR%E8%BF%99%E7%A7%8D%E5%8F%98%E9%95%BF%E5%AD%97%E6%AE%B5%EF%BC%8C%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E5%88%B0%E5%BA%95%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84">VARCHAR这种变长字段，在磁盘上到底是如何存储的</a></li>
<li><a href="#%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E5%A4%9A%E4%B8%AANULL%E5%AD%97%E6%AE%B5%E5%80%BC%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%EF%BC%9F">一行数据中的多个NULL字段值在磁盘上怎么存储？</a></li>
<li><a href="#%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%E4%B8%AD40%E4%B8%AAbit%E4%BD%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%B4%E4%BB%A5%E5%8F%8A%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84%EF%BC%9F">磁盘文件中40个bit位的数据头以及真实数据是如何存储的？</a></li>
<li><a href="#%E8%A1%8C%E6%BA%A2%E5%87%BA">行溢出</a></li>
<li><a href="#%E8%A1%A8%E7%A9%BA%E9%97%B4">表空间</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5">生产实践</a></p>
<ul>
<li><a href="#%E7%9C%9F%E5%AE%9E%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%BA%E5%99%A8%E9%85%8D%E7%BD%AE%E5%A6%82%E4%BD%95%E8%A7%84%E5%88%92%EF%BC%9F">真实生产环境下的数据库机器配置如何规划？</a></li>
<li><a href="#%E4%BA%92%E8%81%94%E7%BD%91%E5%85%AC%E5%8F%B8%E7%9A%84%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%9A%84%EF%BC%9F%EF%BC%9F">互联网公司的生产环境数据库是如何进行性能测试的？</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E5%AF%B9%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C360%E5%BA%A6%E6%97%A0%E6%AD%BB%E8%A7%92%E5%8E%8B%E6%B5%8B%EF%BC%9F">如何对生产环境中的数据库进行360度无死角压测？</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%B8%BA%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E9%83%A8%E7%BD%B2%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%EF%BC%9F">如何为生产环境中的数据库部署监控系统？</a></li>
<li>[如何通过多个Buffer Pool来优化数据库的并发性能？](#如何通过多个Buffer Pool来优化数据库的并发性能？)</li>
<li>[如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？](#如何通过chunk来支持数据库运行期间的Buffer Pool动态调整？)</li>
<li>[在生产环境中，如何基于机器配置来合理设置Buffer Pool？](#在生产环境中，如何基于机器配置来合理设置Buffer Pool)</li>
<li><a href="#Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%B1%82%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E4%BB%A5%E5%8F%8AIO%E8%B0%83%E5%BA%A6%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86">Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E7%9A%84RAID%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E5%88%9D%E6%AD%A5%E4%BB%8B%E7%BB%8D">数据库服务器使用的RAID存储架构初步介绍</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84RAID%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E7%94%B5%E6%B1%A0%E5%85%85%E6%94%BE%E7%94%B5%E5%8E%9F%E7%90%86">数据库服务器上的RAID存储架构的电池充放电原理</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E6%95%85%E9%9A%9C%E7%9A%84%E5%AE%9A%E4%BD%8DToomanyconnections">数据库无法连接故障的定位，Too many connections</a></li>
<li><a href="#%E7%BA%BF%E4%B8%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%80%A7%E8%83%BD%E6%8A%96%E5%8A%A8%E4%BC%98%E5%8C%96">线上数据库不确定性的性能抖动优化</a></li>
</ul>
</li>
<li>
<p><a href="#mysql%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84">mysql主从架构</a></p>
<ul>
<li><a href="#%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8E%9F%E7%90%86">主从架构的原理</a></li>
<li><a href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%E7%9A%84%E6%90%AD%E5%BB%BA">主从复制架构的搭建</a></li>
<li><a href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%95%B0%E6%8D%AE%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98">主从复制数据延迟问题</a></li>
<li><a href="#%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84">高可用架构</a></li>
<li><a href="#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8">分库分表</a></li>
</ul>
</li>
</ul>
<h1 id="目录-2">目录</h1>
<h2 id="mysql基础架构">Mysql基础架构</h2>
<h3 id="mysql架构设计">Mysql架构设计</h3>
<p>一个不变的原则：网络连接必须让线程处理 mysql架构的整体设计原理<br>
<img src="image/mysqlshejiyuanli.png" alt="img_1.png" loading="lazy"></p>
<h3 id="innodb存储引擎的架构设计">InnoDB存储引擎的架构设计</h3>
<figure data-type="image" tabindex="1"><img src="image/InnoDByuanlli.png" alt="img.png" loading="lazy"></figure>
<p>实际上，执行器是非常核心的一个组件，负责跟存储引擎配合完成一个sql语句在磁盘与内存层面的全部数据更新操作。</p>
<p>拆分成两个阶段：</p>
<p>上图的1，2，3，4是执行更新语句的时候干的事， 5，6是从你提交事务开始的，属于提交事务阶段</p>
<pre><code>redo log 是一种偏向物理性值的重做日志，本身属于InnoDB存储引擎特有的一个东西。

redo log 主要记录下你对数据做了哪些修改，这个此时还在内存缓存区

bin log 叫做归档日志，它里面记录的时偏向逻辑性的日志，类似  对users 表中的id =10的一行数据，进行了更新操作，操作以后的值是什么   

bin log 日志不是InnoDB 存储引擎特意的日志文件，是属于 mysql server 自己的日志文件
</code></pre>
<p>提交事务时，redo log日志的刷盘策略：</p>
<pre><code>  这个策略通过innodb_flush_log_at_trx_commit 来配置
  0：提交事务的时候，不会把redo log buffer 里的数据刷入磁盘文件，此时你可能提交事务了，结果mysql宕机了，此时内存中的数据全部丢失。
  1：提交事务的时候，就必须把redo log 从内存中刷入到磁盘文件里去，只要事务提交成功，那么redo log 就必然在磁盘里。
  2：提交事务的时候，把redo日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件，可能1s之后才会把os cache里的数据写入到磁盘文件
</code></pre>
<p>对于数据库这种严格的系统而言，一般建议redo 日志刷盘策略设置为1，保证事务提交之后，数据绝对不能丢失</p>
<p>提交事务时，bin log日志的刷盘策略：</p>
<pre><code>  这个策略通过sync_binlog参数来控制binlog的刷盘策略，它的默认值是0
  0:提交事务的时候，新进入 os cache 内存缓存，后刷回到磁盘（bin log会丢失）
  1:提交事务的时候，强制把binlog直接写入磁盘文件里去（bin log不会丢失）
</code></pre>
<h4 id="buffer-pool">buffer pool</h4>
<figure data-type="image" tabindex="2"><img src="image/bufferpool.png" alt="img_1.png" loading="lazy"></figure>
<p>数据库buffer pool 里面会包含很很多个缓存页，同时每个缓存页还有一个数据描述，也可以叫做数据控制</p>
<p>初始化buffer pool</p>
<pre><code>数据库只要已启动，就会按照你设置的buffer pool 的大小稍微再加大一点去找操作系统申请一块内存区域，作为buffer pool的内存区域

然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16kb的大小以及对应800个字节左右的描述数据的大小，在buffer pool 中划分出来一个个缓存页和一个个对应的数据描述

只不过这个时候，buffer pool中一个个缓存页的都是空的，里面什么都没有，要等数据库运行起来，我们对数据进行增删改查的操作的时候，才会把数据对应的磁盘文件读取出来，放入buffer pool 的缓存页
</code></pre>
<p>哪些缓存页是空闲的？ free链表</p>
<p>从磁盘上的数据页放入到buffer pool的缓存页，必然涉及到一个问题，那就是哪些缓存页是空闲的？</p>
<pre><code>所以数据库会为buffer pool 设计一个**free链表**，它是一个双向链表的数据结构，这个free链表里，每个节点就是一个空闲的
缓存页的描述数据块的地址，也就是说，只要你的一个缓存页是空闲的，那么它的描述数据块地址就会被放入free链表中。
</code></pre>
<p>磁盘上的数据页是如何读到缓存页中？</p>
<pre><code> 其实有了free链表之后，这个问题就很简单了，首先需要重free链表中获取描述数据块，然后就可以获取这个描述数据块对应的空闲缓存页
 写缓存页，添加描述信息
</code></pre>
<p>那怎么知道一个数据是否加载到缓存页？</p>
<pre><code>数据库会维护一个**哈希表数据结构**，他会用表空间+数据页号作为key，然后缓存的地址作为value

也就是说每次你读取一个数据页缓存之后，都会在这个哈希表中写入一个key-value，下次在使用数据页只需要从哈希表中读取数据即可 
</code></pre>
<p>哪些缓存页是脏页</p>
<pre><code>内存中更新的脏页数据，都是要被刷回磁盘文件的。
但是不肯呢个所有的缓存页都刷回磁盘，因为有的缓存页可能是因为查询的时候，而被读到buffer pool 里面去的，可能根本没有修改过

所以数据库这里引入了另外一个跟free链表类似的**flush 链表**，**这个flush链表的本质也是通过缓存页的描述数据块的两个指针，让被修改过的缓存页描述数据块组成一个双向链表**
</code></pre>
<p>引入LRU算法来判断哪些缓存页是不常用的（缓存命中率）</p>
<pre><code>怎么判断哪些缓存页不是经常使用，哪些缓存页是脏页？
引入LRU链表

LRU：least recently used 最近最少使用的意思

工作原理：

假如我们从磁盘加载一个数据页到缓存页的时候，就会把这个缓存页描述数据放到LRU的头部，
那么只要有数据缓存页的时候，他就会在LRU链表里，而且最近被在加载的缓存页，都会放到
LRU的头部去。

然后假定某个缓存页的描述数据块本来是放在LRU尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这个缓存页挪动到HttpServletRequest
尾部，也就是说最近被访问过的缓存页，一定在LRU的头部。
</code></pre>
<p>LRU算法带来的问题</p>
<pre><code>预读带来的巨大问题

预读会导致，一直没被访问的数据放在LRU链表的头部，在空闲缓存页全部使用完时，会将链表尾部的数据刷入磁盘，清空缓存页。但是有可能这个数据时经常被使用的
</code></pre>
<p>哪些情况会触发Mysql的预读机制</p>
<pre><code>1.innodb_read_ahead_threshold他的默认值是56，意思是就是如果顺序的访问一个区里的多个数据页，访问的数据页的数量可能超过这个阈值
此时就会触发预读机制，把下一个相邻区中所有额数据页都加载到缓存中去。

2.如果Buffer Pool里缓存了12个联系的数据页，而且这些数据都是比较频繁被访问的，此时就会出发预读机制，把这个区里的其他数据页都加载到缓存里区。
这个机制是通过参数innodb_random_read_ahead来控制的，默认时OFF，也就是这个规则是关闭的
</code></pre>
<p>另外一种可能导致频繁访问的缓存页被淘汰的场景体验一下</p>
<p>那就是<strong>全表扫描</strong></p>
<pre><code>  类似  SELECT * FROM USERS 他一下子吧这个表里的所有数据页，都加载到Buffer Pool里去
</code></pre>
<p>Mysql基于冷热数据分离方案优化LRU算法</p>
<pre><code>真正的LRU链表，会被拆分成两个部分,一个部分是热数据，一个部分是冷数据，这个冷数据比例是由

innodb_old_blocks_pct参数来控制的，它默认的是37，也就是说冷数据的占比37%。

实际上这个时候，第一次加载时，缓存页会被放到冷数据链表的头部。
</code></pre>
<p>冷数据区域的缓存页何时被加载到热数据区域</p>
<pre><code>innodb_old_blocks_time 默认设置为1000，也就是1000毫秒

也就是数据加载到冷数据区域，过了1s后，你再访问这个缓存页，他就会被放到热数据区域的链表头部
</code></pre>
<figure data-type="image" tabindex="3"><img src="image/LRU.png" alt="img.png" loading="lazy"></figure>
<p>LRU链表的热数据区域是如何进行优化的？</p>
<pre><code>经常被访问的数据时热数据，不经常被访问的数据是冷数据，所以在设计缓存的时候，经常会考虑 **热数据的缓存预加载**
也就是说，每天统计出来哪些商品被访问次数最多，然后晚上的时候，系统启动一个定时作业，把热门商品的数据，预加载到redis里。
那么第二页是不是对热门访问的商品自然就优先走redis

 LRU链表的热数据区域的访问规则被优化了一下，即你只要在热数据区域的后3/4部分缓存页被访问了，才会给你移动到链表头部

如果你是热数据区域的前面的1/4的缓存页被访问，他是不会移动到链表头部的。

这样可以尽可能减少链表中的节点移动了。
</code></pre>
<p>定时LRU尾部的部分缓存页刷入磁盘</p>
<pre><code>第一个时机：有一个后台线程，他会运行一个定时任务，这个定时任务每个一段时间，就会把LRU链表的冷数据区域的尾部一些缓存页刷入到磁盘里去，清空几个缓存页，把他们加入到free链表中。

只要缓存页被刷盘，那么这个缓存页必然会加搭配free链表中，从flush链表中一处，从LRU链表中移除。

因为LRU链表中的热数据可能是被频繁修改的，难道他们永远都不刷入到磁盘了吗？

第二个时机，这个后台线程同时也会在Mysql不怎么繁忙的时候，找个时间把flush链表中的缓存页刷入磁盘，这样被你修改过的数据迟早都会刷入磁盘。
</code></pre>
<h4 id="redo-log">redo log</h4>
<p>redo log:在事务提交成功之后，保存一条日志记录，防止机器宕机导致数据丢失。顺序写，性能高。</p>
<p>redo log长什么样？</p>
<pre><code>redo log里面记录的就是：**表空间号+数据页号+偏移量+修改了几个字节的值+具体的值**

修改了几个字节的值，redo log就划分了不同的类型，MLOG_1BYTE:就是修改了一个字节的值，以此类推
但是如果你修改了一大串的值，类型就是MLOG_WRITE_STRING,就是代表你一下子在那个数据页的某个偏移量位置插入或者修改了一大串的值

日志类型(就是类似MLOG_1BYTE)，表空间号，数据页号，数据页中的偏移量。具体修改的数据
</code></pre>
<p>redo log写磁盘的过程</p>
<pre><code>其实mysql内有另外一个数据结构，叫做 redo log block
一个 redo log block是512字节，这个redo log block字节分为三个部分
一个是12字节的header块头，一个是496字节的body块体，一个是4字节trailer块尾
在这里面，12个字节的header投又分为4个部分：
    1.包括4个字节的block no，就是块唯一编码
    2.2个字节的data length，就是block里写入了多个字节数据；
    3.2个字节的first record group ，这个是说每个事务都会有多个redo log ，一个是redo log group，另一组redo log。那么在这个block里的第一组redo log的偏移量，就是这两个字节存储的；
    4.4个字节的checkpoint on
</code></pre>
<figure data-type="image" tabindex="4"><img src="image/redolog.png" alt="img.png" loading="lazy"></figure>
<p>redo log block 与磁盘文件的关系</p>
<figure data-type="image" tabindex="5"><img src="image/redo_log_block2.png" alt="img.png" loading="lazy"></figure>
<p>平时我们执行完增删改之后，要写入磁盘的redo log，其实应该是先进入到redo log block这个数据结构里，然后再进入磁盘文件</p>
<p>redo log buffer 类似申请出一块连续的空间，然后里面划分出N多个空的redo log block</p>
<p>通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认也就是16MB</p>
<figure data-type="image" tabindex="6"><img src="image/redo_log_block3.png" alt="img_1.png" loading="lazy"></figure>
<p>redo log buffer中的缓冲日志，到底是什么时候写入磁盘的？</p>
<pre><code>（1）如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在
缓冲里了，此时就会把他们刷入到磁盘文件里去
（2）一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事
务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改
（PS：当然，之前最早最早的时候，我们讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的
文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数，我们之前都讲过的 ，大家回过
头去看看 ）
（3）后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去
（4）MySQL关闭的时候，redo log block都会刷入到磁盘里去
</code></pre>
<p>redo log占用磁盘越来越大怎么办？</p>
<p>实际上默认情况下，redo log都会写入到一个目录中文件按里，这个目录可以通过</p>
<pre><code>show variables like 'datadir'
</code></pre>
<p>可以通过修改</p>
<pre><code>innodb_log_group_home_dir
</code></pre>
<p>参数来设置redo log这个目录</p>
<p>指定每个redo log文件的大小，默认是48M</p>
<pre><code>innodb_log_file_size
</code></pre>
<p>指定日志文件的数量</p>
<pre><code>innodb_log_file_in_group
</code></pre>
<figure data-type="image" tabindex="7"><img src="image/redologsetting.png" alt="img.png" loading="lazy"></figure>
<h4 id="undo-log">undo log</h4>
<p>INSERT 语句的undo log 类型是TRX_UNDO_INSERT_REC ，这个undo log里包含了一下的东西：</p>
<pre><code>    1.这条日志的开始位置
    2.主键的各列长度和值
    3.表idx
    4.undo log 日志编号
    5.undo log 日志类型
    6.这条日志的结束位置
</code></pre>
<figure data-type="image" tabindex="8"><img src="image/undolog.png" alt="img.png" loading="lazy"></figure>
<p>现在事务要是回滚，直接从undo log 日志中拿出这个id，找到对应的数据删掉</p>
<h3 id="事务">事务</h3>
<h4 id="多事务并发更新或者查询的数据问题">多事务并发更新或者查询的数据问题</h4>
<p>多个事务要是对缓存页里的同一条数据同时进行更新或者查询，此时会产生哪些问题？</p>
<pre><code>  实际上会设计到脏读，脏写，不可重复读，幻读
</code></pre>
<h5 id="脏写">脏写</h5>
<pre><code>事务B修改了事务A修改过的值，此时事务A还没提交，所以事务A随时会回滚，导致事务B修改过的值也没了
</code></pre>
<figure data-type="image" tabindex="9"><img src="image/zangxie.png" alt="img.png" loading="lazy"></figure>
<h5 id="脏读">脏读</h5>
<pre><code>事务B查询了事务A修改过的数据，但是此时事务A还没有提交，所以事务A随时回滚，导致事务B再次查询就读不到事务A修改的数据了
</code></pre>
<figure data-type="image" tabindex="10"><img src="image/zangdu.png" alt="img.png" loading="lazy"></figure>
<p>其實一句话总结：</p>
<pre><code>无论是脏写还是脏读，都是因为一个事务去更新或者查询了另外一个还没有提交的事务更新过的数据
    
因为另外一个事务还没提交，所以他随时可能反悔回滚，那么必然导致你更新的数据没了，或者你之前查询到的数据就没了，这种就是脏读和脏写。
</code></pre>
<h5 id="不可重复读">不可重复读</h5>
<pre><code>   针对已经提交的事务修改的值，被你的事务给读到了，你的事务多次查询，多次读到的是别人已经提交事务
   修改过的值，导致每次查询的值不一样
</code></pre>
<figure data-type="image" tabindex="11"><img src="image/bukechongfudu.png" alt="img_1.png" loading="lazy"></figure>
<h5 id="幻读">幻读</h5>
<h4 id="sql标准中对事务的4个隔离级别">SQL标准中对事务的4个隔离级别</h4>
<p>SQL标准中滚定了4种事务隔离级别，并不是Mysql的事务隔离级别，mysql的事务隔离级别有点差别。</p>
<p>在SQL标准中，规定的4种事务隔离级别，就是说多个事务并发运行的同时，互相是如何隔离的，从而避免事务并发问题</p>
<p>这四种级别包括：</p>
<h5 id="read-uncommitted-读未提交是不允许脏写的">read uncommitted 读未提交：是不允许脏写的</h5>
<pre><code>也就是说，不可能两个事务在没有提交的情况下去更新同一行数据的值，
但是这种隔离级别下，可能发生脏读，不可重复度，幻读。
</code></pre>
<h5 id="read-committed-rc-读已提交不可能发生脏写和脏读">read committed  RC 读已提交：不可能发生脏写和脏读</h5>
<pre><code>也就是说人家事务没有提交修改的值，你是绝对读不到的
这种隔离级别下不会发生脏读和脏写，但是可以发生不可重复读和幻读
</code></pre>
<h5 id="repeatable-read-rr-可重复读不可能发生脏读脏写不可重复读">repeatable read RR 可重复读：不可能发生脏读脏写，不可重复读</h5>
<pre><code>你的事务多次查询一个数据的值，哪怕别的事务修改这个值还提交了，没有，你不会读到人家事务提交事务修改过的值
你的事务一旦开始，多次查询一个值，会一直读到同一个值。
</code></pre>
<h5 id="serializable-串行化">serializable 串行化</h5>
<pre><code> 这种隔离级别，根本不允许你多个事务并发执行，只能串起来执行
</code></pre>
<h4 id="spring对事务的支持">spring对事务的支持</h4>
<p>在@Transaction(isolation =isolation.DEFAULT),默认是default，表示数据库是什么就是什么 isolation.READ_UNCOMMITTED isolation.READ_COMMITTED<br>
isolation.REPEATABLE_READ isolation.SERIALIZABLE</p>
<h4 id="透彻剖析mysql的mvcc事务隔离机制">透彻剖析Mysql的MVCC事务隔离机制</h4>
<h5 id="undo-log版本链">Undo log版本链</h5>
<pre><code>我们每条数据其实都有两个隐藏字段，一个是trx_id,一个是roll_pointer ，
這個trx_id就是最近一次更新过这条数据的事务id，
roll_pointer 就是指向你了你更新这个事务之前生成的undo log。
所以不管多个事务并发执行时如何执行的，
起码先搞清楚一点，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段trx_id和roll_pointer，
同时之前多个数据快照对应的undo log，会通过roll_pointer指针串联起来，形成一个很重要的版本链
</code></pre>
<h5 id="readview机制">ReadView机制</h5>
<p><a href="https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e86040203a20_GmWrGMJe/1?from=p_5e0c2a35dbbc9_MNDGDYba&amp;type=6">ReadView机制</a></p>
<p>你在在执行事务的时候，就会生成一个ReadView，里面比较重要的东西有四个</p>
<pre><code>1.一个是m_ids，这个就是说此时有哪些事务在mysql里执行还没有提交的
2.一个是min_trx_id，就是m_ids里最小的值；
3.一个是max_trx_id,这是说mysql下一个要生成的事务id，就是最大的事务id
4.一个是create_trx_id，就是你这个事务的id
</code></pre>
<p>现在两个事务并发执行过来，一个是事务A（id = 45），一个是事务B（id = 59），事务B要更新这行数据<br>
事务A是要去读取这行数据的值</p>
<p>现在事务A直接开启ReadView，这个ReadView里的m_ids就包含事务A和事务B的两个id，45和59，<br>
然后min_trx_id就是45，max_trx_id 就是60 create_trx_id 就是45 是事务A自己</p>
<p>这个时候事务A第一次查询这行数据，会走一个判断，就是判断这行数据的trx_id，是否小于 ReadView<br>
中的min_trx_id，此时发现trx_id =32是小于 ReadView中的min_trx_id 就是45的<br>
说明你在事务开启之前，修改这行数据的事务早就提交了，所以此时你就可以看到这行数据</p>
<p>接着事务B开始动手了，他把这行数据的值改为了B，然后这行数据trx_id设置为自己的id，也就是59，<br>
同时roll_pointer指向了修改之前生成的undo log，接着这个事务B就提交了。</p>
<p>接着事务A再次查询，此时查询的时候发现一个问题，就是此时数据行里的trx_id = 59 ，那么这个trx_id是大于ReadView里的<br>
min_trx_id（45），同时又小于ReadView里的max_trx_id（60）的，说明更新这条数据的事务很有可能跟自己差不多同时开启的，<br>
于是会看一下m_ids列表中有45 和 59 两个事务id，直接证实了，这条修改数据的事务是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的。</p>
<p>既然这行数据不能查询，那查什么？<br>
简单，顺着这条数据的roll_pointer顺着undo log日志链往下找，就会找到最近一条undo log，trx_id =32，<br>
此时发现trx_id =32 是小于ReadView里的min_trx_id =45 的 说明这个undo log版本必然是在事务A开启之前就执行且提交了。<br>
好了，那么就查询最近的那个undo log里的值好了，这就是undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值。</p>
<p>如果事务A ，更新值A,trx_id修改为45，同时保存之前事务B修改值的快照。<br>
那么此时A来查询这条数据，会发现trx_id =45 居然和自己的ReadView里的create_trx_id = 45 的值是一样的。<br>
说明这行数据就是自己修改的，自己修改的值当然可以i看到</p>
<p>如果在事务A执行的过程中，突然开启了是一个事务C，这个事务C的id =78，然后它更新了那行的值为值C，还提交了<br>
这个时候，事务A再去查询，会发现当前数据的trx_id = 78，大于了自己的ReadView中的max_trx_id（60）此时说明了什么，<br>
说明是这个事务A开启之后，然后有一个事务更新了数据，自己当然是看不到的。<br>
此时就会顺着undo log多版本链条往下找，自然先找到值A之前修改过的那个版本，因为那个trx_id = 45 跟自己的<br>
ReadView里的create_trx_id是一样的，所以此时直接读取自己修改的那个版本</p>
<figure data-type="image" tabindex="12"><img src="image/ReadViewjizhi.png" alt="img.png" loading="lazy"></figure>
<pre><code>通过undo log多版本链条，加上你开启事务时候生产的一个ReadView，然后再有一个查询的时候，根据ReadView进
行判断的机制，你就知道你应该读取哪个版本的数据。
而且他可以保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。假如说是你事务
开启之前，就有别的事务正在运行，然后你事务开启之后 ，别的事务更新了值，你是绝对读不到的！或者是你事务开
启之后，比你晚开启的事务更新了值，你也是读不到的！
</code></pre>
<h5 id="read-committed隔离级别是如何基于readview机制实现的">Read Committed隔离级别是如何基于ReadView机制实现的？</h5>
<pre><code>每次查询都生成新的ReadView，那么如果 在你这次查询之前，有事务修改了数据还提交了，你这次查询生成的ReadView里，那个m_ids列表当然不包含这个已
经提交的事务了，既然不包含已经提交的事务了，那么当然可以读到人家修改过的值了。
这就是基于ReadView实现RC隔离级别的原理，实际上，基于undo log多版本链条以及
ReadView机制实现的多事务并发执行的RC隔离级别、RR隔离级别，就是数据库的MVCC多版本并发控制机制。
</code></pre>
<h5 id="mysql最牛的rr隔离级别是如何基于readview机制实现的">MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？</h5>
<p>默认的ReadView 就是这个机制</p>
<pre><code>默认情况下，有人在更新数据的时候，你去读取这一行数据,直接默认就是开启mvcc机制的。
也就是说，此时一行数据的读和写两个操作默认是不会加锁互斥的，因为mysql的mvcc机制就是为了解决这个问题，避免频繁加锁互斥。
此时你读取数据，完全可以根据你的ReadView，去在undo log版本链条里找一个你能读取的版本，完全不用顾虑别人在不在更新。
就算你真的等他更新完毕了还提交了，基于mvcc机制，你也读取不到他更新的值啊！因为ReadView机制是不允许的，所以你默认情况下的读
，完全不需要加锁，不需要care其他食物的更新加锁问题，直接介于mvcc机制读某个快照就可以了

如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥
    
查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法
select * from table for update

当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h4 id="多个事务更新同一行数据时是如何加锁避免脏写的">多个事务更新同一行数据时，是如何加锁避免脏写的？</h4>
<p>多个事务同时更新一行数据，此时都会加锁（X 锁，也就是Exclude独占锁），然后都会等待排队，必须一个事务执行完毕了，提交了，释放了锁，才能唤醒别的事务继续执行。</p>
<p>加锁</p>
<figure data-type="image" tabindex="13"><img src="image/jiasuo.png" alt="img.png" loading="lazy"></figure>
<p>释放锁-加锁<img src="image/shifangsuojiasuo.png" alt="img.png" loading="lazy"></p>
<h5 id="共享锁">共享锁</h5>
<pre><code>如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥


默认情况下，有人在更新数据的时候，你去读取这一行数据,直接默认就是开启mvcc机制的。
也就是说，此时一行数据的读和写两个操作默认是不会加锁互斥的，因为mysql的mvcc机制就是为了解决这个问题，避免频繁加锁互斥。

如果要再执行查询的时候想要加锁，mysql支持一种共享锁 就是 s锁，这种共享锁的语法
select * from table lock in mode
共享锁和独占锁互斥，独占锁之间互斥，共享锁与共享锁不互斥
    
查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法
select * from table for update

当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h5 id="独占锁">独占锁</h5>
<pre><code>当有一个事务加了独占锁之后，其他事务再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。

查询的时候还能加互斥锁，也就是 X 锁（Exclude独占锁），这种独占锁的语法

select * from table for update

一旦你查询的时候加了独占锁，此时在你的事务提交之前，任何人都不能更新数据，只能你在本事务里更新数据，等你提交了别人在更新数据
</code></pre>
<h4 id="在表级别加锁">在表级别加锁</h4>
<p>多个事务并发更新数据的时候，都要在行级别加独占锁，独占锁是互斥的，所以不可能发生脏写问题，一个事务提交了才会释放自己的独占锁，唤醒下一个事务的执行。<br>
如果你此时去读取别的事务在更新的数据，有两种可能：<br>
1.第一种可能就是基于MVCC机制进行事务隔离，读取快照版本，这个是比较常见的；<br>
2.第二种可能是查询的同时基于特殊语法去加独占锁或者共享锁。</p>
<p>一般而言，不太建议在数据卷粒度去通过行锁实现复杂的业务锁机制，而更加建议通过redis，zookeeper来用分布式锁来实现复杂业务下的锁机制</p>
<p>比较正常的情况而言，其实还是多个事务并发运行更新一行数据，默认加独占锁互斥，同时其他事物基于mvcc机制进行快照版本读实现事务隔离<br>
、表锁其实是InnoDB存储引擎的概念</p>
<h4 id="索引">索引</h4>
<h5 id="磁盘上数据页的存储结构">磁盘上数据页的存储结构</h5>
<figure data-type="image" tabindex="14"><img src="image/shujuyedecunchu.png" alt="img.png" loading="lazy"></figure>
<pre><code>大量的数据页按照顺序一页一页的存放的，然后相邻的两个数据页会采用采用双向列表的格式互相引用

然后一个数据页内部会存储一行行的数据，也就是我们平时在表里插入的一行行数据就会存储在数据页里

然后数据页里的每一行数据都会按照主键大小进行排序村粗，同时每一行数据都有一个指针指向下一行数据

的位置，组成一个单向链表。

然后每个数据页都会有一个页目录，里面根据数据行的主键存放一个目录，同时数据行是被分割存储在不同槽位里去的

如果是主键查找，在数据页的页目录里,根据主键值直接定位到槽位，遍历槽位数据行，就可以找到数据
如果是非主键查找，只能进入数据页根据单向链表查找数据
</code></pre>
<p>在没有索引的情况下查找数据</p>
<pre><code>第一个数据页遍历所有数据页查找，将数据页加载到缓存页中
如果是主键查找，在数据页的页目录里,根据主键值直接定位到槽位，遍历槽位数据行，就可以找到数据
如果非主键查找，再单向遍历查找那条数据，如果没有那条数据，再加载下一个数据页到缓存页里来
以此类推，循环往复， 其实就是一个全表扫描
</code></pre>
<h4 id="页分裂的过程">页分裂的过程</h4>
<pre><code>假如我们不停的再表里插入数据，接着数据越来越多，此时就要在搞一个数据页了
但是此时就会遇到一个问题，索引运作的一个核心基础就是要求你后一个数据页的主键值大于前面一个数据页的主键值
但是如果你的主键是自增的，还可以保证这一点，因为你新插入的后一个数据页的主键值一定都大于前一个数据页的主键值。
但是如果你的主键不是自增的，所以可能会出现你的后一个数据页的主键值里，有点小于前一个数据页的主键值。
所以此时就会出现一个过程叫做也分裂
就是万一你的主键值都是你自己设置的，那么在增加一个新的数据页的时候，实际上会把前一个数据页主键值较大，挪到新的数据页里来
然后把你新插入的主键值较小的数据挪动到上一个数据页里去。保证了新数据页里的主键值一定都比上一个数据页里的主键值大。
</code></pre>
<h4 id="主键索引">主键索引</h4>
<pre><code>我们先拿最基础的主键索引来分析，把索引原理和查询原理搞清楚

mysql针对主键设计了一个索引，针对主键的索引实际上就是主键目录这个目录呢
把每个数据页的页号，还有数据页里最小主键的值放在一起，组成一个索引目录
</code></pre>
<figure data-type="image" tabindex="15"><img src="image/zhujiansuoyin.png" alt="img.png" loading="lazy"></figure>
<pre><code>通过主键查找时，通过二分查找，对比之后，确定id到底在那个数据页，
通过页目录直接定位到数据对应的槽位，遍历槽位数据行，就可以找到数据
</code></pre>
<h4 id="b树实现索引的物理结构">B+树实现索引的物理结构</h4>
<pre><code>很多索引数据不可能一直放在索引页里，会进行分裂

在更高索引层级里，保存每个索引页里最小的主键值，如果最顶层的索引页里存放下层索引页的也好太多了怎么办？
继续分裂，加一层索引页，这就形成了B+树，
这是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是由很多个数据页组成的一颗B+树
</code></pre>
<h4 id="聚簇索引">聚簇索引</h4>
<p>更新数据时，自动维护的聚簇索引</p>
<pre><code>当我们要查找某个主键id 的值时，通过二分查找很容易找到对应的索引页，通过索引页就能快读定位到数据页
实际上索引页和数据页之间是有指针连接起来的
另外呢,对于同一层级的索引页互相之间都是基于指针组成双向链表的
</code></pre>
<figure data-type="image" tabindex="16"><img src="image/index1.png" alt="img.png" loading="lazy"></figure>
<pre><code>加入把索引页和数据页综合起来看,他们连接在一起,看起来就如同一颗完整的大B+树一样

在B+树里最底层的一层就是数据页,数据页也就是B+树里的叶子节点了

也就是说,上图所有的索引页+数据页组成的B+树就是**聚簇索引**

这个聚簇索引默认时按照主键来组织的,所以你在增删改的时候,一方面会更新数据页,另一方面其实会给你自动维护
B+树结构的聚簇索引,给新增和更新索引页,这个聚簇索引是默认给你建立的.
</code></pre>
<h4 id="针对主键之外的其他字段建立索引的原理">针对主键之外的其他字段建立索引的原理</h4>
<pre><code>根据主键搜索数据的原理其实很清晰了,其实就是从聚簇索引的根节点进行二分查找,一路找到对应的数据页里,
基于页目录直接定位到主键对应的数据就可以了
</code></pre>
<p>主键之外的其他字段建立索引的原理</p>
<pre><code>其实原理是一样的,简单来说,你插入数据的时候,一方面会把完整的数据插入到聚簇索引的叶子节点的数据页里面去,
同时维护好聚簇索引,另一方面会为其他字段建立索引,重新建立一颗B+树.

比如你基于name建立一个索引,那么此时你插入数据的时候,就会重新搞一个B+树(这是独立与聚簇索引的另一个索引的B+树),
B+树的叶子节点也是数据页,但是这个数据页里仅仅存放主键字段和name字段.
</code></pre>
<figure data-type="image" tabindex="17"><img src="image/qitasuoyin.png" alt="img.png" loading="lazy"></figure>
<pre><code>搜索的时候过程和主键字段一模一样,不就是从name字段的索引B+树里根节点开始一层一层往下找,一直找到
叶子节点的数据页里,定位到name字段对应的主键值.
此时还需要进行回表操作,这个回表就是根据主键值,再到聚簇索引里面从根节点开始,一路找到叶子接待你的数据页,
定位到主键对应的完整数据行.
一般吧普通字段的索引称为二级索引,一级索引就是聚簇索引
</code></pre>
<p>多个字段联合起来,建立联合索引,比如:age+name</p>
<pre><code>联合索引的运行原理也是一样的,只不过是建立了一颗独立的B+树,叶子节点里面存放了id+name+age的数据,
然后默认按照name排序,name一样就按照age排序
查询的时候和普通索引一样的原理
</code></pre>
<p>联合索引的查询原理，以及使用索引的全职匹配规则</p>
<pre><code>假如莫得sql语句的where 条件里的几个字段的名称和顺序，都是跟你的索引里的字段一样，同时你还用等号值做匹配，那就是全职匹配
通过第一个字段值，二分查找找到对应的数据页，再在数据页里面二分查找找到对应的其他值找到id之后，进行查找聚簇索引回表操作，查询出剩下的其他字段
</code></pre>
<p>这就是InnoDB存储引擎的索引的完整实现原理了.</p>
<h4 id="索引的优缺点">索引的优缺点</h4>
<p>优点：不需要全表扫描，性能提升很快<br>
缺点消耗磁盘空间，增删改的速度很比较差（因为要维护B+树结构）</p>
<h4 id="索引的使用规则">索引的使用规则</h4>
<p>设计原则：</p>
<pre><code>设计系统时，索引的设计

1.一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，才能发挥出B+树快速二分查找的优势来

2.尽量使用那些字段值比较小的列来设计索引

3.设计索引别太多，建议两三个联合索引就应该覆盖掉你这个表的全部查询了。

否则索引太多，必然导致你增删改的时候性能很差，因为要很多个索引树。

4.另外很关键一点，建议大家主键一定是自增的，别用UUID之类的
因为主键自增，那么你的聚簇索引不会频繁的分裂，主键都是有序的，就会自然新增一个列而已，如果你用得视UUID，那么会
导致聚簇索引频繁的页分裂
</code></pre>
<p>where 使用原则：</p>
<pre><code>1.联合索引的等值匹配规则
    where语句中的几个字段名称和联合索引的条件里的几个字段的名称和顺序，都是跟你的索引里的字段一样，同时你还用等号值做匹配，那就是全职匹配

2.最左侧列匹配
   这个意思是我们的联合索引是KEY(index_key1,index_key2,index_key3)
   那么不一定必须要在where语句里查询三个字段来查，其实只需要根据最左侧的部分字段来查也是可以的
   where index_key1 = '' and index_key2 = '' 是没有问题的
   但是 你要用 where index_key3 那就不行了，因为在联合索引B+树里，是必须先按index_key1，再按index_key2，
   不能跳过前面两个字段直接按照最后一个index_key3 来查
   另外 where index_key1 = '' and index_key3 = '' ,那么饿只要index_key1在索引里能搜到，剩下的index_key3
    没办法在索引中找到
   所以，在建立所以的过程中，你必须建立好联合索引的字段，以及平时你写sql的时候要按照哪几个字段来查

3.最左前缀匹配规则
  即如果你要用like语法来查  like '1%'，是可以用到索引的  ，但是 like '%1'，没法用索引

4.范围查找规则
    同最左侧匹配

5.等值匹配+范围匹配规则
 同最左侧匹配
</code></pre>
<p>order 在sql进行排序，如何使用索引</p>
<pre><code>通常情况下，我们建立INDEX(xxx1,xxx2,xxx3)这样的联合索引，
这个时候默认情况下索引树里本身就是依次按照xxx1,xxx2,xxx3三个字段的值进行排序的
这个时候 用order by xxx1 ,xxx2,xxx3，在联合索引的索引树里都排好了，直接取出数据，
再去聚簇索引里面回表查询所有字段
但是这里有一个限定规则，因为联合索引里的字段值在索引树里都是从小到大一次排序的，
所以order by 要么都降序，要么都升序
不能有的字段降序，有的字段升序，那是不能用索引的
</code></pre>
<p>group by 在在sql中进行分组，如何使用索引<br>
通常而言 group by 后的字段，最好也是按照联合索引最左侧的字段开始，按顺序排列开来，这样的话就可以完美的<br>
运用上索引直接提取一组一组数据，然后对每组数据进行聚合就可以了。</p>
<p>覆盖索引</p>
<pre><code>覆盖索引是不是一种索引，他就是一种基于索引的查询方式罢了。
仅仅需要联合索引里面的几个字段的值，那么其实只要扫描联合索引的索引树就可以了
这种查询的方式就是覆盖索引，这样就不需要回表
</code></pre>
<p>最好使用覆盖索引<br>
即使真的要回表到聚簇索引，那你尽可能的用limit 和where 之类的语句<br>
限定一下回表到聚簇索引的次数，这样性能也要好一些</p>
<h4 id="索引的设计规则">索引的设计规则</h4>
<p>1.一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，才能发挥出B+树快速二分查找的优势来</p>
<p>2.尽量使用那些字段值比较小的列来设计索引</p>
<p>3.设计索引别太多，建议两三个联合索引就应该覆盖掉你这个表的全部查询了。</p>
<p>否则索引太多，必然导致你增删改的时候性能很差，因为要很多个索引树。</p>
<p>4.另外很关键一点，建议大家主键一定是自增的，别用UUID之类的<br>
因为主键自增，那么你的聚簇索引不会频繁的分裂，主键都是有序的，就会自然新增一个列而已，如果你用得视UUID，那么会<br>
导致聚簇索引频繁的页分裂</p>
<h4 id="执行计划">执行计划</h4>
<p>每一次提交sql给mysql，他内核的查询优化器，都会针对这个sql语句的语义去生成一个执行计划，<br>
这个执行计划就代表了，如何筛选过滤如何使用函数，如何进行排序，如何进行分组。</p>
<p>执行计划里包含哪些内容：<br>
1.数据的访问方式：</p>
<p>const - ref -range - index -- all</p>
<pre><code>const:肯定是通过了主键或者唯一索引，速度超高
ref:普通索引  或者主键唯一索引 搞了is null 或者 is not null
range:利用索引来进行范围筛选，一旦索引做了范围筛选，那么这种方式就是range
index:只要遍历组合索引就可以，不需要回表到聚簇索引中去，针对这种只需要遍历二级索引就能拿到你想要的数据，而不需要回源到聚簇索引的访问方式
all:直接全表扫描
</code></pre>
<p>const ，ref ，range :本质上都是居于索引树的二分查找和多层跳转来查询的，所以性能都是很高的<br>
接着接下来就是index 速度上比上面三种压迫差一些，因为他是走遍历二级索引树的叶子节点的方式来执行的<br>
那肯定比基于索引树的二分查找要慢多了，但是还是比全表扫描好一些。</p>
<p>多表关联的sql是如何执行的？</p>
<p>select * from tabel1 t1, table2 t2 where t1.xx = xxx,t2.xxx= xxx and t1.xxx2 = t2.xxx2</p>
<p>sql关联语法的实现原理（嵌套循环关联）：</p>
<pre><code>1.首先根据t1.xxx 表里查询出来一批数据，此时可能是const， ref ,index 或者all，具体看你的索引怎么建立的，他会挑一种执行计划的访问方式。
2.筛选出t1表的数据后，比如说找到两条数据，根据每条数据xxx2的值，以及t2.xxx2这个条件去t2表里找x2字段值和xxx 都匹配的字段值
这时就把两个表的数据关联起来了，另一条数据也是如法炮制。
</code></pre>
<p>记住，他可能是先从表里查一波数据，这个表叫做”驱动表“，再根据这波数据去另一个表查一波数据进行关联，另一个表叫做”被驱动表“</p>
<p>内连接：inner join 意思是两个表的数据必须完全关联上，才能返回回来<br>
外连接：outer join 可分为左外连接（左连接），右外连接（有连接）<br>
如果你是之前的那种内连接，那么连接条件可以放在where语句里，但是外连接一般是把连接条件放在ON字句里的</p>
<p>其实一般写多表关联，主要就是内连接和外连接，连接的语义和实现过程</p>
<p>mysql是如何根据成本优化执行计划的？</p>
<p>全表扫描的成本计算：</p>
<pre><code>show like status like '表名';
rows:表里的记录数
data_length:代表表的聚簇索引的字节数大小 默认是byte

全表扫描的 IO成本：数据页的数量* 1.0 +微调值
         CPU成本：行记录数 * 0.2 + 微调值
总成本= IO成本+CPU成本
</code></pre>
<p>索引的成本计算：</p>
<p>1.基于IN查询的子查询方式的优化：</p>
<p>sql物化表：存储引擎通过内存来存放，如果结果集太大，则可能采用普通B+树聚簇索引的方式存放在磁盘里<br>
但是无论如何，这个物化表都会建立索引。</p>
<p>2.对子查询的另一种优化方式：半连接</p>
<p>在互联网公司，比较崇尚的是尽量写简单的sql，复杂的逻辑用java系统来实现就可以了<br>
sql能单表就不要多表关联，能多表关联就尽量别写子查询，多考虑用java代码在内存里实现<br>
一些数据的复杂计算逻辑，而不是都放在sql里做。</p>
<p>执行计划落实到底层无非就是先访问哪张表，用哪个索引还是全表扫描，拿到数据之后如何去聚簇索引中回表<br>
是否要基于临时磁盘文件做分组聚合或者排序</p>
<p>查看执行计划的内容</p>
<p>id：每个select 都会对应一个id<br>
select_type:说的就是这一条执行计划对应查询的是个什么查询类型<br>
table：就是表名，意思是要查询哪张表<br>
partitions:是表分区的概念<br>
type:当前这个表的访问方式，比如说 const ref range index all<br>
possible_keys:可能选择的索引<br>
key：实际上选择的索引<br>
key_len:就是索引的长度<br>
ref:就是使用某个字段的索引进行等值匹配搜索的时候，跟索引列等值匹配的那个目表值得一些信息<br>
rows:是预估通过索引或者别的方式访问这个表的时候，大概可能取多少条数据，<br>
filtered:就是通过搜索条件过滤后得剩下数据得百分比<br>
extra：一些额外得信息</p>
<p>select_type:</p>
<pre><code>一般单表或者多表连接查询，他们得select_type都是SIMPLE，就是简单得查询
如果是union 语句，第一条执行计划针对表1，select_type 就是 PRIMARY
                第二条执行计划针对表2，select_type 就是 UNION
                第三条执行计划就是针对两个查询结果依托 一个临时表去重
                第三条执行计划 select_type 就是 union_result
如果是子查询，第一条执行计划 select_type 就是 PRIMARY
            第二条执行计划 select_type 就是SUBQUERY  
            select_type 是DERIVED 针对子查询得结果集会物化一个内部临时表
</code></pre>
<h4 id="sql调优">Sql调优</h4>
<pre><code>在sql调优的时候，核心就是分析执行计划里哪些出现了全表扫描，或者扫描的数据过大，尽可能的通过合理
优化索引保证执行计划每个步骤都是基于索引执行，避免扫描过多的数据
</code></pre>
<p>如果mysql使用了错误得执行计划应该怎么办？<br>
使用 force index 语法就可以了</p>
<p>select * from table fore index (index) where  index = &quot;&quot;</p>
<p>为什么mysql 默认会选对主键得聚簇索引进行扫描？</p>
<h3 id="mysql物理存储">mysql物理存储</h3>
<h4 id="varchar这种变长字段在磁盘上到底是如何存储的">VARCHAR这种变长字段，在磁盘上到底是如何存储的</h4>
<p><strong>引⼊变长字段的长度列表，解决⼀⾏数据的读取问题：</strong></p>
<pre><code>将数据的长度转成16进制表示，放在数据存储的前面
</code></pre>
<p><strong>多个变长字段是如何存储的？</strong></p>
<pre><code>此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储⼏个变长字段的长度，⼀定要注意⼀点，他这⾥是逆
序存储的！
</code></pre>
<p>0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a</p>
<p><strong>mysql的一行行数据紧凑存储有什么好处？</strong></p>
<pre><code>多行紧凑的原因有： 序列化反序列时的开销小；不易有内存碎片；定位数据时比较快速
</code></pre>
<h4 id="一行数据中的多个null字段值在磁盘上怎么存储">一行数据中的多个NULL字段值在磁盘上怎么存储</h4>
<p><strong>为什么一行数据的NULL值不能直接存储？</strong></p>
<pre><code>肯定不是按照字符串的方式存储，会浪费空间。
</code></pre>
<p><strong>NULL值是以二进制Bit来存储的？</strong></p>
<pre><code>bit值是1 说明是NULL，如果是0 说明不是NULL
</code></pre>
<p><strong>磁盘上的⼀⾏数据到底如何读取出来的？</strong></p>
<pre><code>我们结合上⾯的磁盘上的数据存储格式来思考⼀下，⼀⾏数据到底是如何读取出来的呢？
再看上⾯的磁盘数据存储格式：
0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN

⾸先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析⼀下，就知道有⼏个变长字段，哪⼏个变长
字段是NULL，因为NULL值列表⾥谁是NULL谁不是NULL都⼀清⼆楚。
此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪⼏个字段是NULL的，此时
根据这些信息，就可以从实际的列值存储区域⾥，把你每个字段的值读取出来了。
如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字
段，就按照定长长度来读取，这样就可以完美的把你⼀⾏数据的值都读取出来了！
</code></pre>
<h4 id="磁盘文件中40个bit位的数据头以及真实数据是如何存储的">磁盘文件中40个bit位的数据头以及真实数据是如何存储的</h4>
<pre><code>每一行数据在磁盘上存储的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，  
然后会有NULL值列表，对于允许NULL值得字段都会有一个bit位标识那个字段是否为NULL，也是逆序排序得
</code></pre>
<p>每一行数据存储得时候，还得有一个bit位得数据头，这个数据头是用来描述这行数据的。</p>
<pre><code>第一位bit和第二位bit都是预留位，是没有任何含义的。
接下来的bit位是delete_mask：他标识这行数据是否被删除了
下一个bit位是min_rec_mask：在B+树里每一层的非页字节点里最小值都有这个标记
接下来是4个bit位是n_owned：记录了一个记录数
接下来13个bit位是heap_no，他代表是当前这行数据在数据堆里的位置
然后是3个bit位record_type：也就是这行数据的类型
   0:代表普通类型
   1：代表是B+树非叶子节点
   2：代表是最小值的数据 
   3：代表最大值的数据
最后16位bit是next_record:这个是他下一条数据的指针
</code></pre>
<h4 id="一行数据实际在磁盘上的存储">一行数据实际在磁盘上的存储</h4>
<p><img src="image/mysqlcipancunchu.png" alt="img.png" loading="lazy">变长字段列表 NULL值列表 数据头 真实数据</p>
<p>在实际存储一行数据的时候，会在他真实数据部分，添加一些隐藏字段</p>
<pre><code>DB_ROW_ID 字段：这是一个行的唯一标识，是数据库内部的一个标识，不是你的主键ID字段，入股我们没有指定主键和
unique key 唯一索引的时候，他的内部就会自动加一个DB_ROW_ID

DB_TRX_ID字段，这个跟事务相关，他是说这是哪个事务更新的数据，这是事务ID。

DB_ROLL_PTR，这是回滚指针，用来进行事务回滚的
</code></pre>
<h4 id="行溢出">行溢出</h4>
<p>行溢出：就是一行的数据存储太多的内容，一个数据页都放不下，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页。</p>
<h4 id="表空间">表空间</h4>
<pre><code>表空间：我们平时创建的那些表，其实就是都有一个表空间的概念，在磁盘上对会对应'表明.ibd'，这样的一个磁盘数据文件。’

‘一个表空间磁盘文件里，其实会有很多很多的数据页，为了便于管理，表空间又引入了**数据区（extent）**
一个数据区对应64个连续的数据页，每个数据页的大小是16kb，所以一个数据区就是1mb，然后256个数据区被划分为一组。

当我们需要执行CRUD操作的时候，说白，就是从磁盘上表空间的数据文件里，去加载一些数据页出来到buffer pool的缓存页里区使用
</code></pre>
<figure data-type="image" tabindex="18"><img src="image/shujuqu.png" alt="img.png" loading="lazy"></figure>
<h3 id="生产实践">生产实践</h3>
<h4 id="真实生产环境下的数据库机器配置如何规划">真实生产环境下的数据库机器配置如何规划</h4>
<p>普通应用的机器选择？</p>
<pre><code>就经验而言，普通的系统 4核8G ，每秒抗几百的请求没问题，
数据库通常是在8核16G以上正常的是16核32G
</code></pre>
<p>高并发场景数据库应该选择什么样的机器？</p>
<pre><code>磁盘，io，网络压力会比较大，最好采用ssd固态硬盘
</code></pre>
<h4 id="互联网公司的生产环境数据库是如何进行性能测试的">互联网公司的生产环境数据库是如何进行性能测试的？</h4>
<p>请求测试指标：QPS、TPS</p>
<pre><code>QPS：Query Per Second，每秒可以处理多少个请求，也就是说这个数据库每秒可以处理多少个sql

TPS：Transaction Per Second 。其实就是每秒可处理的事物
</code></pre>
<p>IO相关压测性指标</p>
<pre><code>IOPS：这个是机器随机IO并发处理能力
这个指标很关键，你在内存中更新的脏数据，最后都会由后台IO在不确定时间，刷回到磁盘里去。这个是随机IO的过程，
如果说IOPS指标太低了，那么会导致脏数据刷回磁盘的效率不高。


吞吐量：这个指机器的磁盘存储每秒可以读写多少个字节的数据
这个指标也很关键，因为大家通过学习都知道，我们在平时执行各种sql的时候，提交事物的时候，其实都会有大量会写redo log日志之类的，这些日志都会直接写磁盘

latency：这个指标说的往磁盘里写入一条数据的延迟。
这个指标同样很重要，因为我们执行sql语句和提交事物的时候，都需要顺序写redo log 次哦盘文件，所以此时
你写一条日志到磁盘文件里去，到底延迟是1ms还是100us，这就是对你的数据库sql语句执行性能是有影响的
</code></pre>
<p>其它指标</p>
<pre><code>CPU负载：PU负载是⼀个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标
都还正常，但是此时CPU负载特别⾼，那么也说明你的数据库不能继续往下压测更⾼的QPS了，否则CPU是吃不消的。

网络负载：这个主要是要看看你的机器带宽情况下，在压测到⼀定的QPS和TPS的时候，每秒钟机器的⽹卡会输⼊多少
MB数据，会输出多少MB数据，因为有可能你的⽹络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，⽹
卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了

内存负载：：这个就是看看在压测到⼀定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过⾼了，说明也
不能继续压测下去了
</code></pre>
<h4 id="如何对生产环境中的数据库进行360度无死角压测httpsapppukyptrl1086pcxiaoe-techcomdetaili_5e383c5357307_mjhluwmb1fromp_5e0c2a35dbbc9_mndgdybatype6">如何对生产环境中的数据库进行360度无死角压测？（https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e383c5357307_MjhluwMb/1?from=p_5e0c2a35dbbc9_MNDGDYba&amp;type=6）</h4>
<p>在linux 安装sysbench</p>
<pre><code>curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash
sudo yum -y install sysbench
sysbench --version
如果上⾯可以看到sysbench的版本号，就说明安装成功了

QPS：Query Per Second，每秒可以处理多少个请求，也就是说这个数据库每秒可以处理多少个sql

TPS：Transaction Per Second 。其实就是每秒可处理的事物
</code></pre>
<p>如何为生产环境中的数据库部署监控系统</p>
<pre><code>Prometheus：其实就是一个监控数据采集和存储系统，它可以利用采用缉拿空数据采集组件从你指定的Mysql数据库中采集他需要的监控数据
然后他自己由一个时序数据库，他会把采集道德监控数据放到自己的时序数据库中，本质就是存储在磁盘文件里。

Grafana：就是一个可视化的监控数据展示系统，他可以Prometheus采集到的大量mysql监控数据展示成各种精美报告，可以让我们直接看到mysql的监控情况。
</code></pre>
<h4 id="如何通过多个buffer-pool来优化数据库的并发性能">如何通过多个Buffer Pool来优化数据库的并发性能</h4>
<p>多线程并发访问一个Buffer Pool的时候必然会加锁，然后很多线程可能要串行着排队，一个个的依次执行操作。</p>
<p>一般来说，Mysql默认的规则是，如果你给Buffer Pool分配的内存大小小于1GB，那么最多就会给你一个Buffer Pool</p>
<p>但是如果你的机器内存就很大，那么此时你是可以同时设置多个Buffer Pool</p>
<pre><code>  innodb_buffer_pool_size = 8589934592
  innodb_buffer_pool_instance = 4
</code></pre>
<p>我们给Buffer Pool 设置了8GB的总内存，然后设置了4个Buffer Pool，也就是说每个Buffer Pool的大小是2GB</p>
<p>所以在生产实践中设置多个Buffer Pool 来优化高并发访问的性能，是mysql一个很重要的优化技巧。</p>
<h4 id="如何通过chunk来支持数据库运行期间的buffer-pool动态调整">如何通过chunk来支持数据库运行期间的Buffer Pool动态调整</h4>
<p>实际上Buffer Pool是由很多个chuck组成的，他的大小是innodb_buffer_pool_chunk_size 来控制的默认值是128M</p>
<pre><code>所以实际上我们可以做一个假设，比如现在我们给Buffer Pool 设置一个总大小是8GB，然后4个Buffer Pool ，那么每个Buffer Pool 就是2GB
 此时每个Buffer Pool 是由一系列的128M chuck组成的，也就是说每个Buffer Pool 会有16个chuck，然后每个Buffer Pool里的每个chuck里就是一系列
数据描述和缓存页，每个Buffer Pool里的多个chuck共享一套 free flush lru 链表 
</code></pre>
<h4 id="在生产环境中如何基于机器配置来合理设置buffer-pool">在生产环境中，如何基于机器配置来合理设置Buffer Pool</h4>
<p>Buffer Pool 的大小一般设置为机器大小的50-60%</p>
<p>确定了Buffer pool 的总大小之后，就得考虑设置多少个buffer pool以及chuck</p>
<p>一般来说： buffer pool总大小 = （chuck大小 * buffer pool数量）的倍数</p>
<h4 id="linux操作系统的存储系统软件层原理剖析以及io调度优化原理">Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理</h4>
<p>Linux的存储系统分为VFS层、⽂件系统层、Page Cache缓存层、通⽤Block层、IO调度层、Block设备驱动 层、Block设备层，</p>
<figure data-type="image" tabindex="19"><img src="image/linuxcunchujiegou.png" alt="img.png" loading="lazy"></figure>
<p>当mysql发起随机读写或者一次顺序写redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给linux操作系统的VFS层</p>
<p>VFS层：根据你是对哪个目录中的文件执执行磁盘IO操作，把IO请求交给具体的文件系统。</p>
<pre><code>举个例⼦，在linux中，有的⽬录⽐如/xx1/xx2⾥的⽂件其实是由NFS⽂件系统管理的，有的⽬录⽐如/xx3/xx4⾥的⽂件
其实是由Ext3⽂件系统管理的，那么这个时候VFS层需要根据你是对哪个⽬录下的⽂件发起的读写IO请求，把请求转
交给对应的⽂件系统，如下图所⽰

接着⽂件系统会先在Page Cache这个基于内存的缓存⾥找你要的数据在不在⾥⾯，如果有就基于内存缓存来执⾏读
写，如果没有就继续往下⼀层⾛，此时这个请求会交给通⽤Block层，在这⼀层会把你对⽂件的IO请求转换为Block IO
请求，如下图所⽰

接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这⼀层⾥默认是⽤CFQ公平调度算法的
也就是说，可能假设此时你数据库发起了多个SQL语句同时在执⾏IO操作。
有⼀个SQL语句可能⾮常简单，⽐如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的⼀个block
⾥的数据就可以了
但是有的SQL语句，⽐如说select * from xx where xx1 like &quot;%xx%&quot;可能需要IO读取磁盘上的⼤量数据。
那么此时如果基于公平调度算法，就会导致他先执⾏第⼆个SQL语句的读取⼤量数据的IO操作，耗时很久，然后第⼀
个仅仅更新少量数据的SQL语句的IO操作，就⼀直在等待他，得不到执⾏的机会。
所以在这⾥，其实⼀般建议MySQL的⽣产环境，需要调整为deadline IO调度算法，他的核⼼思想就是，任何⼀个IO操
作都不能⼀直不停的等待，在指定时间范围内，都必须让他去执⾏。
所以基于deadline算法，上⾯第⼀个SQL语句的更新少量数据的IO操作可能在等待⼀会⼉之后，就会得到执⾏的机会，
这也是⼀个⽣产环境的IO调度优化经验。
我们看下图，此时IO请求被转交给了IO调度层


最后IO完成调度之后，就会决定哪个IO请求先执⾏，哪个IO请求后执⾏，此时可以执⾏的IO请求就会交给Block设备驱
动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，如下图所⽰。

然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上⾯的层级反向依次返回，最终
MySQL可以得到本次IO读写操作的结果
</code></pre>
<figure data-type="image" tabindex="20"><img src="image/RAIDchongfangdian.png" alt="img.png" loading="lazy"></figure>
<h4 id="数据库服务器使用的raid存储架构初步介绍">数据库服务器使用的RAID存储架构初步介绍</h4>
<pre><code>所以MySQL数据库软件都是安装在一台linux服务器上的，然后启动MySQL的进程，就是启动了一个MySQL数据库

MySQL运行过程中，他需要使用CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供的接口，依托于操作系统来使用和运行的，然后linux操作系统负责操作底层的硬件。
</code></pre>
<figure data-type="image" tabindex="21"><img src="image/mysql_1.png" alt="img.png" loading="lazy"></figure>
<pre><code>数据库部署在机器上的时候，存储都是搭建的RAID存储架构

RAID就是一个磁盘冗余阵列

RAID这个技术，大致理解为用来管理机器里的多块磁盘的一种磁盘阵列技术！

有了他以后，你在往磁盘里读写数据的时候，他会告诉你应该在哪块磁盘上读写数据，
</code></pre>
<figure data-type="image" tabindex="22"><img src="image/img_1.png" alt="img_1.png" loading="lazy"></figure>
<pre><code>有了RAID这种多磁盘阵列技术之后，我们是不是就可以在一台服务器里加多块磁盘，扩大我们的磁盘存储空间了？

当我们往磁盘里写数据的时候，通过RAID技术可以帮助我们选择一块磁盘写入，在读取数据的时候，我们也知道从哪块磁盘去读取。
</code></pre>
<p>除此之外，RAID技术很重要的一个作用，就是他还可以<strong>实现数据冗余机制</strong></p>
<pre><code>所谓的数据冗余机制，就是如果你现在写入了一批数据在RAID中的一块磁盘上，然后这块磁盘现在坏了，无法读取了，那么岂不是你就丢失了一波数据？如下图所示

![img.png](image/mysql_3.png)
</code></pre>
<p>所以其实有的RAID磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的.<br>
这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的，不需要你操心， 如下图。</p>
<figure data-type="image" tabindex="23"><img src="image/mysql_4.png" alt="img.png" loading="lazy"></figure>
<p>所以RAID技术实际上就是管理多块磁盘的一种磁盘阵列技术，他有软件层面的东西，也有硬件层买的东西，比如有RAID卡这种硬件设备。</p>
<p>具体来说，RAID还可以分成不同的技术方案，比如RAID 0、RAID 1、RAID 0+1、RAID2，等等，一直到RAID 10，很多种不同的多磁盘管理技术方案</p>
<h4 id="数据库服务器上的raid存储架构的电池充放电原理">数据库服务器上的RAID存储架构的电池充放电原理</h4>
<p>RAID緩存模式設置為write back，意思是先寫緩存再寫磁盤整列<br>
<img src="image/RAIDchongfangdian.png" alt="img.png" loading="lazy"></p>
<p>鋰電池會性能减弱，所以需要对锂电池的配置订定时充放电。</p>
<p>充电的过程中 RAID缓存级别会从write back 变成write through，这个时候IO直接些磁盘。性能会下降，导致数据库抖动出现性能抖动。</p>
<h4 id="raid锂电池充放电导致的mysql数据库性能抖动的优化">RAID锂电池充放电导致的MySQL数据库性能抖动的优化</h4>
<p>RAID 0：同时些很多快磁盘，读写并发能力强，容易丢失数据 RAID 1：两块磁盘为镜像关系，所写的数据在另一块磁盘上都有，形成数据冗余，防止数据丢失，分摊读写的压力。</p>
<p>RAID 10 = RAID 0 + RAID 1：写的时候使用RAID 0 的思路，备份使用RAID 1 的思路。</p>
<p>对于RAID 锂电池充放电问题导致的存储性能抖动，一般有三种解决方案：</p>
<pre><code>1.给RAID卡把锂电池换成电容，电容是不用频繁充放电的，不会导致充放电的性能抖动，还有就是电容可以支持透明充放电，就是自动检查电量，自动进行充电，不会说在充放电的时候让写IO直接走磁盘，但是更换电容很麻烦，而且电容比较容易老化，这个其实一般不常用

2.手动充放电，这个比较常用，包括一些大家知道的顶尖互联网大厂的数据库服务器的RAID就是用了这个方案避免性能抖动，就是关闭RAID自动充放电，然后写一个脚本，脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本手动触发充放电，这样可以避免业务高峰期的时候RAID自动充放电引起性能抖动

3.充放电的时候不要关闭write back，就是设置一下，锂电池充放电的时候不要把缓存级别从write back修改为write through，这个也是可以做到的，可以和第二个策略配合起来使用
</code></pre>
<h4 id="数据库无法连接故障的定位toomanyconnections">数据库无法连接故障的定位TooManyConnections</h4>
<p>TooManyConnections 说明数据库连接池已经满了，你的业务系统不能与他建立更多的连接了。</p>
<p>检查mysql的配置文件 my.conf，里面有个关键的参数max_connections就是mysql建立的最大连接数。</p>
<p>查看mysql实际最大连接数</p>
<pre><code>show variables like 'max_connections'
</code></pre>
<p>mysql无法设置max_connections期望值，只能强行限制为214？为什么？</p>
<pre><code>    简单来说，就是因为底层linux操作系统把进程可以打开的文件句柄数限制为1024了导致mysql最大连接数时214
    为什么linux的最大文件句柄限制为1024的时候，MySQL的最大连接数是214呢？ 
    原因其实是mysql内部源码写死的，它在源码中就是有一个公式，算下来如此罢了
</code></pre>
<p>如何解决经典的Too Many Connections故障，背后的原理是什么？</p>
<pre><code>    ulimit -HSn 65535
    然后就可以用如下命令检查最大文件句柄数是否被修改了
    cat /etc/security/limits.conf
    cat /etc/rc.local
    如果都修改好了之后，可以在mysql的my.cnf里确保max_connections参数也调整好了，然后就可以重启服务器，重启mysql，
    这样的话，linux的最大文件句柄就会生效了，mysql最大连接数也会生效了
</code></pre>
<h4 id="线上数据库不确定性的性能抖动优化">线上数据库不确定性的性能抖动优化</h4>
<p>sql语句性能会出现不正常的莫名其妙的抖动，平时可能即使毫秒，现在居然要几秒钟，根本原因有两种：</p>
<p>1.第一个可能buffer pool缓存页都满了，此时你的sql查询了很多数据，一下把很多缓存页flush到磁盘上去，刷磁盘太慢了，就会导致你的查询语句执行的很慢。</p>
<p>2.第二种可能是你执行更新语句的时候，redo log在磁盘上的所有文件都写满了，此时需要回到第一个redo log文件覆盖写，覆盖写可能就涉及到第一个redo log文件里有很多<br>
redo log日志对应的更新操作改动了缓存页，那写缓存页还没有flush到磁盘，此时就必须把哪些缓存页的flush到磁盘，才能执行后续的更新语句，那么这一等待<br>
必然会导致更新执行很慢</p>
<p>如何尽可能的优化Mysql的一些参数，减少这种缓存页flush到磁盘带来的性能抖动的问题？</p>
<pre><code>1.对于不是数据库的机器一定要采用ssd的磁盘，
2.innodb_io_capacity 这个参数是告诉数据库采用多大的io速率把缓存页flush到磁盘里去的
    可以使用fio工具测试磁盘最大随机io速率之后，就知道他每秒可以执行多少次随机io
3.innodb_flush_neighbors,意思是在flush缓存页到磁盘德时候，可能会把缓存页临近的其他缓存页也刷到磁盘
但是这样有时候会导致flush缓存也太多了，实际上如果你使用的是SSD固态硬盘，并没必要让他同时刷进临近的缓存页，
可以把innodb_flush_neighbors设置为0，禁止刷进缓存页
</code></pre>
<h2 id="mysql主从架构">mysql主从架构</h2>
<h3 id="主从架构的原理">主从架构的原理</h3>
<p>大致来说：就是主库接受增删改的操作，把增删改操作binlog写入本地文件，然后从库发送请求来拉取binlog,接着从库上重复执行一遍binlog的操作，就可以还原出一样的数据。</p>
<h3 id="主从复制架构的搭建最基础架构">主从复制架构的搭建(最基础架构)</h3>
<p>事前准备：</p>
<pre><code>1.首先确保主库和从库的server_id是不同的，这个是必然的
2.主库必须打开binlog功能，你必须打开binlog功能，主库才会写binlog到本地磁盘，接着按照如下步骤
</code></pre>
<p>1.在主库上创建一个主从复制的账号</p>
<pre><code>create user 'backup_user'@'192.168.31.%' identified by 'backup_123';
grant replication slave on *.* to 'backup_user'@'192.168.31.%';
flush privileges;
</code></pre>
<p>2.如果主库跑了一段时间，现在要挂一个从库，应该在凌晨时，对主库和从库做一个数据备份和导入</p>
<pre><code>可以使用mysqldump工具把主库在这个时刻的数据全量备份，但是此时一定是不允许操作主库的，主库的数据时不能有变动的
/usr/local/mysql/bin/mysqldump --single-transaction -uroot -proot --master-data=2 -A &gt; backup.sql

注意，mysqldump工具就是在你的Mysql安装目录的bin目录下，然后用上述命令对你的主库所有的数据都做一个备份，
备份会以sql语句的方式进入指定的backup.sql 文件，只要执行backup.sql 就可以恢复出来跟主库一样的数据了

--master-data=2，是说备份的sql文件里，要记录一下此时主库的binlog文件和position号这是为了主从复制做准备的

接着从库执行下面的命令取执行主库进行复制

CHANGE MASTER TO MASTER_HOST='192.168.31.229',
MASTER_USER='backup_user',MASTER_PASSWORD='backup_123',MASTER_LOG_FILE='mysqlbin.000015',MASTER_LOG_POS=1689;

可能有人会疑惑，上面的master机器的ip地址我们是知道的，master上用于执行复制的用户名和密码是我们自己创建
的，也没问题，但是master的binlog文件和position是怎么知道的？这不就是之前我们mysqldump导出的
backup.sql里就有，大家在执行上述命令前，打开那个backup.sql就可以看到如下内容：
MASTER_LOG_FILE='mysql-bin.000015',MASTER_LOG_POS=1689
然后你就把上述内容写入到主从复制的命令里去了。
接着执行一个开始进行主从复制的命令：start slave，再用show slave status查看一下主从复制的状态，主要看到
Slave_IO_Running和Slave_SQL_Running都是Yes就说明一切正常了，主从开始复制了。
接着就可以在主库插入一条数据，然后在从库查询这条数据，只要能够在从库查到这条数据，就说明主从复制已经成
功了。
这仅仅是最简单的一种主从复制，就是异步复制，就是之前讲过的那种原理，从库是异步拉取binlog来同步的，所以
肯定会出现短暂的主从不一致的问题的，比如你在主库刚插入数据，结果在从库立马查询，可能是查不到的。
</code></pre>
<p>只要你搭建出来主从复制架构，就可以实现读写分离了<br>
可以用mycat 或者sharding-sphere之类的中间件，就可以实现你的系统写入主库，从库去读取</p>
<p>主从架构默认是异步的复制方式，意思是说主库把日志写入到binlog文件，接着自己提交事务返回了，他不管从库是否受到日志</p>
<p>如果主库宕机，从库切换为主库，可能发生数据丢失。</p>
<h5 id="主从半复制生产实践">主从半复制（生产实践）</h5>
<p>因此一般来说，搭建主从复制都是采用半同步的方式复制的，这个半同步的意思是，你主库写入数据，日志进入binlog之后，起码确保binlog<br>
日志复制到从库，才提交事务。</p>
<p>这个半同步复制的方式有两种</p>
<pre><code>    1.第一种叫做AFTER_COMMIT方式，他不是默认的，他的意思是说，主库写入日志到binlog，等待binlog日志复制到从库
    主库就提交自己的本地事务，接着就等待从库返回给自己一个成功的响应，然后主库就返回提交事务成功的响应给客户端。
</code></pre>
<p>（传统的搭建方式）<br>
搭建半复制也很简单，在搭建好异步复制的基础上，安装好版复制的插件就可以了，先在主库上安装半复制插件同时还得开启半复制功能</p>
<pre><code>install plugin rpl_semi_sync_master soname 'semisync_master.so';
set global rpl_semi_sync_master_enabled=on;
show plugins;
</code></pre>
<p>可以看到你安装了这个插件那就ok了</p>
<p>接着从库上页安装这个插件以及开启半复制功能：</p>
<pre><code>install plugin rpl_semi_sync_master soname 'semisync_master.so';
set global rpl_semi_sync_master_enabled=on;
show plugins;
</code></pre>
<p>接着要重启从库的IO线程：stop slave io_thread; start slave io_thread;</p>
<p>然后在主库上检查一下半同步复制是否正常运行：show global status like '%semi%';，如果看到了<br>
Rpl_semi_sync_master_status的状态是ON，那么就可以了。</p>
<p>到此半同步复制就开启成功了，其实一般来说主从复制都建议做成半同步复制，因为这样配合高可用切换机制，就可以保证数<br>
据库有一个在线的从库热备份主库的数据了，而且主要主库宕机，从库立马切换为主库，数据不丢失，数据库还高可用。</p>
<p>（GTID）搭建方式</p>
<p>首先在主库进行配置;</p>
<pre><code> gtid_mode=on
 enforce_gtid_consistency=on
 log_bin=on
 server_id=单独设置一个
 binlog_format=row
 接着在从库进行配置：
 gtid_mode=on
 enforce_gtid_consistency=on
 log_slave_updates=1
 server_id=单独设置一个

 接着按照之前讲解的步骤在主库创建好用于复制的账号之后，就可以跟之前一样进行操作了，比如在主库dump出来一
 份数据，在从库里导入这份数据，利用mysqldump备份工具做的导出，备份文件里会有SET
 @@GLOBAL.GTID_PURGED=***一类的字样，可以照着执行一下就可以了。
 接着其余步骤都是跟之前类似的，最后执行一下show master status，可以看到executed_gtid_set，里面记录的是执行
 过的GTID，接着执行一下SQL：select * from gtid_executed，可以查询到，对比一下，就会发现对应上了。
 那么此时就说明开始GTID复制了

其实大家会发现无论是GTID复制，还是传统复制，都不难，很简单，往往这就是比较典型的MySQL主从复制的搭建方
式了，然后大家可以自行搜索一下MyCat中间件或者是Sharding-Sphere的官方文档，其实也都不难，大家照着文档
做，整合到Java代码里去，就可以做出来基于主从复制的读写分离的效果了。
那些中间件都是支持读写分离模式的，可以仅仅往主库去写，从从库去读，这都没问题的。
如果落地到项目里，那么就完成了一个主从架构以及读写分离的架构了，此时按照我们之前所说的，如果说你的数据
库之前对一个库的读写请求每秒总共是2000，此时读写分离后，也许就对主库每秒写TPS才几百，从库的读QPS是
1000多。
那么万一你要是从库的读QPS越来越大，达到了每秒几千，此时你是不是会压力很大？没关系，这个时候你可以给主
库做更多的从库，搭建从库，给他挂到主库上去，每次都在凌晨搞，先让系统停机，对外不使用，数据不更新。
接着对主库做个dump，导出数据，到从库导入数据，做一堆配置，然后让从库开始接着某个时间点开始继续从主库复
制就可以了，一旦搭建完毕，就等于给主库挂了一个新的从库上去，此时继续放开系统的对外限制，继续使用就可以
了，整个过程基本在1小时以内。
如果在凌晨比如2点停机1小时，基本对业务是没有影响的。
</code></pre>
<h4 id="主从复制数据延迟问题">主从复制数据延迟问题</h4>
<p>为什么会产生主从延迟问题？</p>
<pre><code>其实很简单，其实你主库是多线程写入的，速度很快，从库是单个线程缓慢拉去数据，所以才会导致从库的复制数据的速度是比较慢的
</code></pre>
<p>主从复制的延迟实践监控</p>
<pre><code>这个可以用一个工具进行监控，比较推荐的是percona-toolkit工具集里的pt-hearbeat工具，他会在主库创建一个hearbeat表，
然后会有一个线程定时更新这个表里的时间戳字段，从库上就会有一个monitor线程会负责检查从库同步过来的hearbeat表里的时间戳。
把时间戳和当前时间对比一下就知道
</code></pre>
<p>如何缩小主从同步的延迟时间？</p>
<pre><code>其实就是让从库也用多线程并行复制数据就可以了，这样从库复制的速度很快，延迟就会很低了。
mysql5.7就已经支持并行复制了，可以在从库里设置slave_parallel_workers &gt;0,
然后把slave_parallel_type设为LOGICAL——CLOCK。
</code></pre>
<h4 id="高可用架构">高可用架构</h4>
<p>主从复制说白了就是允许主库把数据复制到从库上，然后允许我们的系统往主库里写数据，从库里读数据，实现一个读写分离的模式。</p>
<p>那么读写分离的模式确定了，接着就可以考虑一下数据库的高可用架构了，所谓的高可用架就是说数据库突然宕机，比如说主库或者从库宕机了，那么数据库还能正常使用吗？</p>
<p>如果主库真的宕机了，那就真的麻烦了，因为主库一旦宕机，你就没法写入数据，从库毕竟是不允许写入数据的，只允许读取。</p>
<p>所以数据库的高可用架构，可以实现主库宕机的同时，把从库切换为主库，然后所有的请求都基于现在的这台服务器去经行去读和写入。，</p>
<p>一般生产环境用于数据库高可用架构额管理工具MHA，是日本人写的，用peer脚本写一个工具，这个工具就是战门用于监控主库的状态，如果</p>
<p>感觉不对，就可以把从库切换为从库。</p>
<p>这个MHA也是需要单独部署的，分为两种节点，一个是Manager节点，一个是Node节点，Manager节点一般都是单独部署一台机器的<br>
Node节点一般都是部署在每天Mysql机器上的，因为Node节点通过通过解析各个Mysql的日志来进行一些操作</p>
<p>Manager节点会通过探测集群里的Node节点去判断各个Node所在机器上的MySQL运行是否正常，如果发现某个Master故障，就直接把Slave提升为Master，然后让<br>
其他Slave都挂到新的Master上去，完全透明。</p>
<h4 id="分库分表">分库分表</h4>
<p>要实现分库分表需要数据库中间件支持的，业内常用的一般有Sharding-Sphere以及Mycat两种，都是国内开源的。</p>
<p>一般建议Mysql单表数据量不超过1000万，最好在500万以内，如果内控制在100万以内，那是最佳的选择了，单表控制在100万以内，性能上不会有太大的问题，<br>
前提是你要建立好所有就行，其实保证Mysql高性能通常没有什么高深的技巧，就是控制数据量不要太大，另外只要保证你的查询用上了索引，所以一般就不会有问题。</p>
<p>一般分库分表时往往要考虑三个维度：<br>
1.一个是必然要按照主键id为粒度去分库分表，也就是把主键id进行hash后，对表数量进行取模，然后把数据均匀的分布到这些表中，<br>
再把这些表分散到多台数据库里。<br>
2.另外两个维度是用户端和运营端<br>
用户端：用户可能要查询自己的订单<br>
运营端：公司可能要查询所有的订单<br>
如何解决，针对用户端，你就需要按照(userids，主键id)这个表结构去做一个索引映射表，</p>
<p>userid和主键id的一一对应映射关系要放到这个表里，然后针对userid为粒度取进行分表分库</p>
<p>也就是对userid进行hash后取模，然后把数据均匀分散到很多索引映射表，再把表放到很多数据库里。</p>
<p>然后每次用户端拿出app查询自己的订单，直接根据userid取hash后取模路由到一个索引映射表，找到用户的userid</p>
<p>这里当然可以做一个分页了，先拿到所有的主键id，再根据主键id取对应的数据库里，去分库分表的表里提取完整数据。</p>
<p>至于运营端，一般都是根据N多个条件对数据经行搜索，此时跟上次将的一样，可以把数据的搜索条件放到es里面</p>
<p>然后用es来进行复杂搜索，找出一波主键id，再根据主键id去分库分表里找到完整数据。</p>
<p>分库分表的玩法基本都是这套思路，按业务id分库分表，建立索引映射表的同时进行分库分表，数据同步到es做复杂搜索，</p>
<p>基本这套玩法就可以保证你的分库分表的场景下，各种业务都可以执行</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[idea 找不到符号]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/idea-zhao-bu-dao-fu-hao/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/idea-zhao-bu-dao-fu-hao/">
        </link>
        <updated>2022-04-07T13:12:32.000Z</updated>
        <content type="html"><![CDATA[<p>在使用IDEA的时候，经常出现过找不到包或者找不到符号的情况，可以尝试以下几种方式来解决</p>
<p>1.如果项目使用的是Maven可以使用Maven-Reimport<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337559961.png" alt="" loading="lazy"><br>
2.还可以 Invalidate and Restart （无效并重新启动）<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337602794.png" alt="" loading="lazy"><br>
3.重新编译<br>
1.打开Project Structure --&gt;Modules 找到项目编译输出目录<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337677309.png" alt="" loading="lazy"><br>
2.将target目录下文件清空<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337720835.png" alt="" loading="lazy"><br>
3.右键项目重新build<br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1649337751258.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[函数式编程]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/han-shu-shi-bian-cheng/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/han-shu-shi-bian-cheng/">
        </link>
        <updated>2022-04-05T13:58:04.000Z</updated>
        <content type="html"><![CDATA[<pre><code>行为参数化就是让一个方法接受多种不同的行为作为参数，并且在内部使用他们，完成不同行为的能力。
行为参数化可以让代码更好的适应不断变化的要求，减轻未来的工作量。
</code></pre>
<pre><code class="language-java">

</code></pre>
<p>-传递代码就是将新行为作为参数传递给方法。<br>
但是在Java8之前实现起来很啰嗦，在java8之前可以适应匿名内部类来减少，1.8可以使用lambda表达式来</p>
<p>关于stream的使用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[随笔]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/sui-bi/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/sui-bi/">
        </link>
        <updated>2022-04-05T07:58:50.000Z</updated>
        <content type="html"><![CDATA[<p>有些人并不是你的花 ，你只是途径了它的绽放。<br>
2022.04.04</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Cloud Alibaba底层原理]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/spring-cloud-alibaba-di-ceng-yuan-li/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/spring-cloud-alibaba-di-ceng-yuan-li/">
        </link>
        <updated>2022-03-27T12:30:32.000Z</updated>
        <content type="html"><![CDATA[<p>Spring Cloud Alibaba底层原理</p>
<p>组件</p>
<p>nacos：服务注册中心 配置中心</p>
<p>dubbo：RPC调用框架  负载均衡  远程调用</p>
<p>sentinel:限流</p>
<p>seata：分布式事务管理</p>
<figure data-type="image" tabindex="1"><img src="/Users/develop/code/java-stack/docs/framework/images/springcloudAlibaba.png" alt="img_1.png" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[UML]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/uml/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/uml/">
        </link>
        <updated>2022-03-27T11:32:04.000Z</updated>
        <content type="html"><![CDATA[<p>统一建模语言(Unified Modeling Language，UML)是一种为面向对象系统的产品进行说明、可视化和编制文档的一种标准语言，是非专利的第三代建模和规约语言。UML是面向对象设计的建模工具，独立于任何具体程序设计语言。</p>
<p>UML系统开发中有三个主要的模型： [3]<br>
功能模型：从用户的角度展示系统的功能，包括用例图。 [3]<br>
对象模型：采用对象，属性，操作，关联等概念展示系统的结构和基础，包括类别图、对象图。 [3]<br>
动态模型：展现系统的内部行为。包括序列图，活动图，状态图。 [3]</p>
<p>序列图（也叫左时序图，顺序图）</p>
<p>为什么要绘制时序图？<br>
我们编码的时候，知道有的用例的业务逻辑按照比较确定的时间先后顺序进行展开。这时候，我们就需要知道我们设计的系统中的不同类之间传递消息（可以认为是不同对象函数间的调用）要按照怎么样的顺序、传递什么消息、返回什么消息。这时候用时序图是最好不过的了</p>
<p>时序图的定义：</p>
<p>时序图是描述消息时间顺序的交互图。在图形上，时序图是一张表，其中显示的对象沿横轴排列，从左到右分布在图的顶部；而消息则沿纵轴按时间顺序排序。创建时序图时，以能够使图尽量简洁为依据布局。</p>
<p>时序图创建步骤</p>
<p>1、确定交互过程的上下文；</p>
<p>2、识别参与过程的交互对象；</p>
<p>3、为每个对象设置生命线；</p>
<p>4、从初始消息开始，依次画出随后消息；</p>
<p>5、考虑消息的嵌套，标示消息发生时的时间点，则采用FOC（focus of control）；</p>
<p>6、说明时间约束的地点。</p>
<p>时序图的元素<br>
我们在画时序图时会涉及7种元素：角色(Actor)、对象(Object)、生命线(LifeLine)、控制焦点(Activation)、消息(Message)、自关联消息、组合片段。其中前6种是比较常用和重要的元素，剩余的一种组合片段元素不是很常用，但是比较复杂。我们先介绍前6种元素，在单独介绍组合片段元素。</p>
<p>角色(Actor)<br>
系统角色，可以是人或者其他系统，子系统。以一个小人图标表示。<br>
对象(Object)<br>
对象位于时序图的顶部,以一个矩形表示。对象的命名方式一般有三种：<br>
1 对象名和类名。例如：华为手机:手机、loginServiceObject:LoginService。<br>
2 只显示类名，不显示对象，即为一个匿名类。例如：:手机、:LoginSservice。<br>
3 只显示对象名，不显示类名。例如：华为手机:、loginServiceObject:。<br>
生命线(LifeLine)<br>
时序图中每个对象和底部中心都有一条垂直的虚线，这就是对象的生命线(对象的时间线)。以一条垂直的虚线表。<br>
控制焦点(Activation)<br>
控制焦点代表时序图中在对象时间线上某段时期执行的操作。以一个很窄的矩形表示。<br>
消息(Message)<br>
表现代表对象之间发送的信息。消息分为三种类型。<br>
同步消息(Synchronous Message)<br>
消息的发送者把控制传递给消息的接收者，然后停止活动，等待消息的接收者放弃或者返回控制。用来表示同步的意义。以一条实线+实心箭头表示。<br>
异步消息(Asynchronous Message)<br>
消息发送者通过消息把信号传递给消息的接收者，然后继续自己的活动，不等待接受者返回消息或者控制。异步消息的接收者和发送者是并发工作的。以一条实线+大于号表示。<br>
返回消息(Return Message)<br>
返回消息表示从过程调用返回。以小于号+虚线表示。<br>
自关联消息<br>
表示方法的自身调用或者一个对象内的一个方法调用另外一个方法。以一个半闭合的长方形+下方实心剪头表示。</p>
<p>组合片段<br>
组合片段用来解决交互执行的条件和方式，它允许在序列图中直接表示逻辑组件，用于通过指定条件或子进程的应用区域，为任何生命线的任何部分定义特殊条件和子进程。组合片段共有13种，名称及含义如下：</p>
<p><img src="https://zuolinlin.github.io/zuo.github.io//post-images/1648381778972.png" alt="" loading="lazy"><br>
<img src="https://zuolinlin.github.io/zuo.github.io//post-images/1648381787741.png" alt="" loading="lazy"></p>
<p>常用组合片段举例</p>
<p>抉择（Alt）<br>
抉择在任何场合下只发生一个序列。 可以在每个片段中设置一个临界来指示该片段可以运行的条件。else 的临界指示其他任何临界都不为 True 时应运行的片段。如果所有临界都为 False 并且没有 else，则不执行任何片段。Alt片段组合可以理解为if..else if...else条件语句</p>
<p>选项（Opt）<br>
包含一个可能发生或不发生的序列。Opt相当于if..语句。</p>
<p>循环（Loop）<br>
片段重复一定次数，可以在临界中指示片段重复的条件。Loop相当于for语句。</p>
<p>并行（Par）<br>
并行处理，片段中的事件可以并行交错。Par相当于多线程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[navicat]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/navicat/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/navicat/">
        </link>
        <updated>2022-03-23T14:23:02.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>使用navicat生成逆向模型</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[git]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/git/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/git/">
        </link>
        <updated>2022-03-23T14:22:17.000Z</updated>
        <content type="html"><![CDATA[<p>Git高速下载地址：https://npm.taobao.org/mirrors/git-for-windows/</p>
<p><a href="hhttps://blog.csdn.net/unique_perfect/article/details/104833391">Git以及Github的使用</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[idea]]></title>
        <id>https://zuolinlin.github.io/zuo.github.io/post/wo-er-ti-yu/</id>
        <link href="https://zuolinlin.github.io/zuo.github.io/post/wo-er-ti-yu/">
        </link>
        <updated>2022-03-22T15:14:10.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>snoarline</li>
<li>lombok</li>
<li>restfultool</li>
<li>translation</li>
<li>codata</li>
<li>FindBugs</li>
<li>Alibaba Java Coding Guidelines</li>
<li>CodeGlance</li>
<li>MyBatisCodeHelperPro</li>
<li>Free-idea-mybatis</li>
<li>github copilot</li>
</ul>
<p>JetBrains</p>
<pre><code>账号: linlinzuo    Kupcu4-davqiq-hosdaf  邮箱：zuoxiyue@outlook.com
账号：qiaosiye     xiyuezuo1993@         邮箱：878522146@qq.com
账号：yuezuo     Kupcu4-davqiq-hosdaf         邮箱：zuoxiyue2022@163.com
账号：xizuo      Kupcu4-davqiq-hosdaf   邮箱：zuoxiyue202204@163.com Ymqctx2022
</code></pre>
]]></content>
    </entry>
</feed>