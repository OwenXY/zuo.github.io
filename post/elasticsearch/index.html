<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Elasticsearch | zuolinlin</title>
<link rel="shortcut icon" href="https://zuolinlin.github.io/zuo.github.io//favicon.ico?v=1654385389620">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://zuolinlin.github.io/zuo.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Elasticsearch | zuolinlin - Atom Feed" href="https://zuolinlin.github.io/zuo.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Elasticsearch
目录

Elasticsearch核心知识入门篇

Elasticsearch快速入门

Elasticsearch功能适用场景特点
Elasticsearch核心概念
Elasticsearch安装部署
Ela..." />
    <meta name="keywords" content="数据库,框架" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://zuolinlin.github.io/zuo.github.io/">
  <img class="avatar" src="https://zuolinlin.github.io/zuo.github.io//images/avatar.png?v=1654385389620" alt="">
  </a>
  <h1 class="site-title">
    zuolinlin
  </h1>
  <p class="site-description">
    你要问我如何去二仙桥，我会告诉你走成华大道。可你要问人生，我也说不清。
  </p>
  <div class="menu-container">
    
      
        <a href="https://zuolinlin.github.io/zuo.github.io/" class="menu">
          首页
        </a>
      
    
      
        <a href="https://zuolinlin.github.io/zuo.github.io/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="https://zuolinlin.github.io/zuo.github.io/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="https://zuolinlin.github.io/zuo.github.io/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Elasticsearch
            </h2>
            <div class="post-info">
              <span>
                2022-04-08
              </span>
              <span>
                72 min read
              </span>
              
                <a href="https://zuolinlin.github.io/zuo.github.io/tag/bw-eCiZ9Q/" class="post-tag">
                  # 数据库
                </a>
              
                <a href="https://zuolinlin.github.io/zuo.github.io/tag/DTrX5zKuV/" class="post-tag">
                  # 框架
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-e98bc940f96206a85e67dc08bed593d2_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1652016918&amp;t=b58b8af13804906de89c01298554ea7b" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="elasticsearch">Elasticsearch</h1>
<h2 id="目录">目录</h2>
<ul>
<li><a href="#Elasticsearch%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8%E7%AF%87">Elasticsearch核心知识入门篇</a>
<ul>
<li><a href="#Elasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8">Elasticsearch快速入门</a>
<ul>
<li><a href="#Elasticsearch%E5%8A%9F%E8%83%BD%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%E7%89%B9%E7%82%B9">Elasticsearch功能适用场景特点</a></li>
<li><a href="#Elasticsearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5">Elasticsearch核心概念</a></li>
<li><a href="#Elasticsearch%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2">Elasticsearch安装部署</a></li>
<li><a href="#Elasticsearch%E6%96%87%E6%A1%A3%E7%9A%84CRUD">Elasticsearch文档的CRUD</a></li>
<li><a href="#Elasticsearch%E5%A4%9A%E7%A7%8D%E6%90%9C%E7%B4%A2%E6%96%B9%E5%BC%8F">Elasticsearch多种搜索方式</a></li>
<li><a href="#Elasticsearch%E8%81%9A%E5%90%88%E6%90%9C%E7%B4%A2">Elasticsearch聚合搜索</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch分布式架构</a>
<ul>
<li><a href="#Elasticsearch%E5%9F%BA%E7%A1%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch基础分布式架构</a>
<ul>
<li><a href="#Elasticsearch%E5%AF%B9%E5%A4%8D%E6%9D%82%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%8F%E6%98%8E%E9%9A%90%E8%97%8F%E7%89%B9%E6%80%A7">Elasticsearch对复杂分布式机制的透明隐藏特性</a></li>
<li><a href="#Elasticsearch%E7%9A%84%E5%9E%82%E7%9B%B4%E6%89%A9%E5%AE%B9%E4%B8%8E%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9">Elasticsearch的垂直扩容与水平扩容</a></li>
<li><a href="#Elasticsearch%E5%A2%9E%E5%87%8F%E8%8A%82%E7%82%B9%E6%97%B6rebalance">Elasticsearch增减节点时rebalance</a></li>
<li><a href="#Elasticsearch%E7%9A%84master%E8%8A%82%E7%82%B9">Elasticsearch的master节点</a></li>
<li><a href="#Elasticsearch%E8%8A%82%E7%82%B9%E5%B9%B3%E7%AD%89%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch节点平等的分布式架构</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86">index分片原理</a>
<ul>
<li><a href="#Shard&amp;replica%E6%9C%BA%E5%88%B6%E6%A2%B3%E7%90%86">shard&amp;replica机制梳理</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E5%8E%9F%E7%90%86">Elasticsearch横向扩容原理</a>
<ul>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%9F%E7%90%86_%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%EF%BC%8C%E5%A6%82%E4%BD%95%E8%B6%85%E5%87%BA%E6%89%A9%E5%AE%B9%E6%9E%81%E9%99%90%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%AE%B9%E9%94%99%E6%80%A7">Elasticsearch分布式原理_横向扩容，如何超出扩容极限以及如何提升容错性</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%EF%BC%9Amaster%E9%80%89%E4%B8%BE%EF%BC%8Creplace%E5%AE%B9%E9%94%99%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D">Elasticsearch容错机制：master选举，replace容错，数据恢复</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8Fdocument">Elasticsearch分布式document</a>
<ul>
<li><a href="#Index%E5%85%83%E6%95%B0%E6%8D%AE">_index元数据</a></li>
<li><a href="#Type%E5%85%83%E6%95%B0%E6%8D%AE">_type元数据</a></li>
<li><a href="#Id%E5%85%83%E6%95%B0%E6%8D%AE">_id元数据</a></li>
<li><a href="#Source%E5%85%83%E6%95%B0%E6%8D%AE">_source元数据</a></li>
<li><a href="#Document%E7%9A%84%E5%85%A8%E9%87%8F%E6%9B%BF%E6%8D%A2">document的全量替换</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Eexterna1lVersion%E8%BF%9B%E8%A1%8C%E4%B9%90%E8%A7%82%E9%94%81%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6">_基于externa1lVersion进行乐观锁并发控制</a></li>
<li><a href="#PartialUpdate">partial update</a></li>
<li><a href="#%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C">批量操作</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">Elasticsearch分布式系统</a>
<ul>
<li><a href="#Document%E6%95%B0%E6%8D%AE%E8%B7%AF%E7%94%B1%E5%8E%9F%E7%90%86">document数据路由原理</a></li>
<li><a href="#Document%E5%A2%9E%E5%88%A0%E6%94%B9%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86">Document增删改内部原理</a></li>
<li><a href="#%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8Aquorum%E6%9C%BA%E5%88%B6%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">写一致性原理以及quorum机制的深入解析</a></li>
<li><a href="#Document%E5%86%85%E9%83%A8%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86">Document内部查询原理</a></li>
<li><a href="#BuilApi%E7%9A%84%E5%A5%87%E7%89%B9json%E6%A0%BC%E5%BC%8F%E4%B8%8E%E5%BA%95%E5%B1%82%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%85%B3%E7%B3%BB">BuilApi的奇特json格式与底层性能优化关系</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E">Elasticsearch搜索引擎</a>
<ul>
<li><a href="#Search%E7%BB%93%E6%9E%9C%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">search结果的深入解析</a></li>
<li><a href="#Multi-index&amp;multi-type%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86">Multi-index&amp;multi-type搜索模式解析以及搜索原理</a></li>
<li>[分页搜索以及deep paging性能问题深度图解](#分页搜索以及deep paging性能问题深度图解)</li>
<li>[快速掌握query stringserach语法以及_all metadata原理揭秘](#快速掌握query stringserach语法以及_all metadata原理揭秘)</li>
<li><a href="#mapping">mapping</a></li>
<li><a href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%BF%AB%E9%80%9F%E8%A7%A3%E5%AF%86">倒排索引的核心原理快速解密</a></li>
<li><a href="#%E5%88%86%E8%AF%8D%E5%99%A8">分词器</a></li>
<li><a href="#QueryDSL">queryDSL</a></li>
<li><a href="#%E5%AF%B9StringField%E6%8E%92%E5%BA%8F">对stringfield排序</a></li>
<li><a href="#%E7%9B%B8%E5%85%B3%E5%BA%A6%E8%AF%84%E5%88%86TF&amp;IDF%E7%AE%97%E6%B3%95">相关度评分TF&amp;IDF算法</a></li>
<li><a href="#DocValues%E6%AD%A3%E6%8E%92%E7%B4%A2%E5%BC%95">doc Values</a></li>
<li><a href="#QueryPhase">query phase</a></li>
<li><a href="#FetchPhase">fetch phase</a></li>
<li><a href="#%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0%E6%A2%B3%E7%90%86%E4%BB%A5%E5%8F%8Abouncingresults%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">搜索相关参数梳理以及bouncing results问题的解决方案</a></li>
<li><a href="#Scoll%E6%8A%80%E6%9C%AF%E6%BB%9A%E5%8A%A8%E6%90%9C%E7%B4%A2%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE">scoll技术滚动搜索大量数据</a></li>
</ul>
</li>
<li><a href="#Elasticsearch%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86">Elasticsearch索引管理</a>
<ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5">索引的增删改查</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E5%88%86%E8%AF%8D%E8%B5%B7%E4%BB%A5%E5%8F%8A%E5%AE%9A%E5%88%B6%E5%88%86%E8%AF%8D%E5%99%A8">修改分词起以及定制分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2type%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">深入探索type底层数据结构</a></li>
<li><a href="#MappingRootObject%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">mapping root object深入解析</a></li>
<li><a href="#%E5%AE%9A%E5%88%B6%E5%8C%96%E8%87%AA%E5%B7%B1%E7%9A%84dynamicMapping%E7%AD%96%E7%95%A5">定制化自己的dynamic mapping策略</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Elasticsearch%E9%AB%98%E6%89%8B%E8%BF%9B%E9%98%B6%E7%AF%87">Elasticsearch高手进阶篇</a>
<ul>
<li><a href="#%E6%B7%B1%E5%BA%A6%E6%8F%AD%E7%A7%98%E6%90%9C%E7%B4%A2%E6%8A%80%E6%9C%AF">深度揭秘搜索技术</a></li>
<li><a href="#IK%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8">IK中文分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E8%81%9A%E5%90%88%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">深入聚合数据分析</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E5%AE%9E%E6%88%98">数据建模实战</a></li>
<li><a href="#%E5%AE%8C%E6%88%90%E5%BB%BA%E8%AE%AE">完成建议</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E9%9B%86%E7%BE%A4">生产实践-集群</a></li>
<li><a href="#Elasticsearch%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98">Elasticsearch性能调优</a></li>
</ul>
</li>
</ul>
<h1 id="elasticsearch-2">Elasticsearch</h1>
<h2 id="elasticsearch核心知识入门篇">Elasticsearch核心知识入门篇</h2>
<h3 id="elasticsearch快速入门">Elasticsearch快速入门</h3>
<h4 id="elasticsearch功能适用场景特点">Elasticsearch功能适用场景特点</h4>
<p>1.Elasticsearch的功能、适用场景、以及特点介绍</p>
<pre><code>1.分布式搜索引擎和数据分析引擎
2.全文检索、结构化检索、数据分析
3.对海量数据进行近实时处理
</code></pre>
<p>2.Elasticsearch适用场景</p>
<pre><code>1.维基百科、全文检索、高亮、搜索推荐
2.用户日志、社交网络数据、分析新闻文章公众反馈
3.日志数据分析、logstash采集日志、复杂的数据分析
4.分布式搜索引擎和数据分析引擎
5.全文检索、结构化检索、数据分析
6.对海量数据进行近实时处理
</code></pre>
<p>3.Elasticsearch特点介绍</p>
<pre><code>1.可以作为大型分布式集群技术，处理PB级数据服务大公司，也可以在单机上服务小公司
2.全文检索、数据分析、分布式技术结合在一起。
3.开箱即用、非常简单
4.Elasticsearch提供了全文检索、同义词处理、相关度排序、复杂数据分析、海量数据近实时的功能
</code></pre>
<h4 id="elasticsearch核心概念">Elasticsearch核心概念</h4>
<pre><code>1.Near Realtime(NRT)：近实时,意思是：从查询数据库到数据可以被es搜索到有一个延迟(大概1S);基于es执行搜索和分析可以达到秒级
2.cluster:集群,包含多个节点,每个节点属于哪个 集群是通过一个配置(集群名称,默认是elasticsearch)来决定的。
3.node：节点，几圈中的一个节点，节点也有名称（默认是随机分配的）,节点名称很重要(在运维管理进行操作的时候),默认节点会去加入一个名称为&quot;elasticsearch&quot;的集群中，如果直接启动一堆节点,那么他们会自动组成elasticsearch集群，当然一个节点可以组成elasticsearch集群
4.document:文档,es中最小的数据单元,一个document可以是一条订单数据或者是一个商品数据，通常用JSON数据结构表示,每个index下type中都可以存储多个document,一个document里面有多个field，每个field就是一个数据字段
5.index:索引，包含一堆相似的文档数据,比如订单索引，索引有一个名称。一个index包含多个document，一个index就代表一类类似的document.比如说建立一个product index，商品索引,里面可能就存放了所有的商品数据，所有的商品document.
6.type:类型,每个索引都可以有一个活多个type，type是index中的一个逻辑数据分类,一个type下的document都有相同的field
7.shard：单台机器无法存储大量数据,es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储.有了shard就可以横向扩展，存储更多数据,让搜索和分析等操作分布到多台机器上，执行速度快,提升吞吐量和性能.
8.replica:粉盒一个服务器随机可能出现故障或者宕机.因此可以为每个shard创建多个replica副本,replica可以在shard故障时候提供备用，保证数据不丢失。多个replica哈可以提升搜索作用的吞吐量和性能。
primary shard(建立索引时候一次设置,不能修改,默认5个),replica shard（随时修改数量,默认1个）,默认每个索引10个shard.5个primary shard。5个replica shard。最小高可用配置，是两台server.
</code></pre>
<h4 id="elasticsearch安装部署">Elasticsearch安装部署</h4>
<p>Elasticsearch安装</p>
<pre><code>docker pull elasticsearch:7.6.2

vim /etc/sysctl.conf #文件最后添加一行 vm.max_map_count=262144

mkdir -p /data/elasticsearch/config
mkdir -p /data/elasticsearch/data

进入config目录下 创建 elasticsearch.yml文件 粘贴下面配置

http.host: 0.0.0.0
http.port : 9200
transport.tcp.port : 9300
http.cors.enabled : true
http.cors.allow-origin : &quot;*&quot;
network.bind_host: 0.0.0.0
xpack.security.enabled: true
xpack.security.audit.enabled: true

#启动

docker run -d --restart=always -p 9200:9200 -p 9300:9300 --name elasticsearch -e &quot;discovery.type=single-node&quot; -e &quot;cluster.name=elasticsearch&quot; -v /data/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data/elasticsearch/data:/usr/share/elasticsearch/data -v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins elasticsearch:7.6.2

#启动完毕后设置密码 参考文档: https://www.cnblogs.com/woshimrf/p/docker-es7.html
#进入容器
docker exec -it elasticsearch /bin/bash
执行: ./bin/elasticsearch-setup-passwords auto
输出以下信息:
Changed password for user apm_system
PASSWORD apm_system = l5CWYr67Q6CJUzpKyvZb

Changed password for user kibana
PASSWORD kibana = HOauyvrBjHKxwQ1R2Idt

Changed password for user logstash_system
PASSWORD logstash_system = sHvJEh4kxu0inCAlk8Uc

Changed password for user beats_system
PASSWORD beats_system = 8YmZ4TAAlaSzuVMgBSDi

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = X48M4DRRnWBTgG8y9dWb

Changed password for user elastic
PASSWORD elastic = e4R0G5bbwWTT7IuTdR63

审核服务器:
Changed password for user apm_system
PASSWORD apm_system = E1OeyBsIoY1f4Hk8p3gM

Changed password for user kibana
PASSWORD kibana = 2qlVVaovTSguYNhw4YRf

Changed password for user logstash_system
PASSWORD logstash_system = m0Z9JdoGcPLLuLtjqrNv

Changed password for user beats_system
PASSWORD beats_system = LgNP0AhqfkEBKyg7E006

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = MpiGnxDhy36DtSviy7Bj

Changed password for user elastic
PASSWORD elastic = YWUVdA9MQPhUcFAt9JdH

生产密码:
Changed password for user apm_system
PASSWORD apm_system = rx7WKzaqc1jZMLISiodA

Changed password for user kibana
PASSWORD kibana = lXGbcUu5wFH27XLeOUfL

Changed password for user logstash_system
PASSWORD logstash_system = 9S2Mg1vkUjeqQUdDmCik

Changed password for user beats_system
PASSWORD beats_system = k0pxVqpDQtJnK6z6sjok

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = gN9dIqHHHRMyVmzifIVU

Changed password for user elastic
PASSWORD elastic = n4rI5IOzxqC0Db1HJKzc
</code></pre>
<p>查看Elasticsearch是否启动成功</p>
<p>http://ip:port/?pretty</p>
<pre><code>{
&quot;name&quot; : &quot;66405ae2daed&quot;,    //Node名称
&quot;cluster_name&quot; : &quot;docker-cluster&quot;,  //集群名称  在Elasticsearch.yml 文件里修改
&quot;cluster_uuid&quot; : &quot;5_7wD3BtSKSuIYrBas5w0A&quot;,
&quot;version&quot; : {
&quot;number&quot; : &quot;7.13.1&quot;,         //版本号
&quot;build_flavor&quot; : &quot;default&quot;,
&quot;build_type&quot; : &quot;docker&quot;,
&quot;build_hash&quot; : &quot;9a7758028e4ea59bcab41c12004603c5a7dd84a9&quot;,
&quot;build_date&quot; : &quot;2021-05-28T17:40:59.346932922Z&quot;,
&quot;build_snapshot&quot; : false,
&quot;lucene_version&quot; : &quot;8.8.2&quot;,
&quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,
&quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;
},
&quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre>
<p>查看Elasticsearch集群状态<br>
GET ip:port/_cat/health?v</p>
<p>green：每个索引的primary shard和replica shard 都是activity<br>
yellow：每个索引的primary shard 都是activity ，部分replica shard 不是activity状态，是不可用的状态<br>
red：不是所有的primary shard都是activity，部分索引有数据丢失</p>
<p>kibana安装</p>
<pre><code>mkdir -p /data/kibana/config
docker pull kibana:7.6.2

vim /data/kibana/config/kibana.yml # 填入下面配置

i18n.locale: 'zh-CN'
server.host: '0.0.0.0'
elasticsearch.hosts: ['http://172.18.14.12:9200','http://172.18.14.15:9200','http://172.18.14.10:9200']
elasticsearch.username: 'elastic'
elasticsearch.password: 'n4rI5IOzxqC0Db1HJKzc'
xpack:
  apm.ui.enabled: false
  graph.enabled: false
  ml.enabled: false
  monitoring.enabled: false
  reporting.enabled: false
  security.enabled: false
  grokdebugger.enabled: false
  searchprofiler.enabled: false


# 运行
docker run -d -it --restart=always --privileged=true --name=kibana -p 15601:5601 -v /data/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.6.2
</code></pre>
<h4 id="elasticsearch文档的crud">Elasticsearch文档的CRUD</h4>
<p>快速查看集群中有哪些索引</p>
<pre><code>    GET /_cat/indecs?v
</code></pre>
<p>创建索引</p>
<pre><code>   PUT /test?pretty
</code></pre>
<p>删除索引</p>
<pre><code>DELETE /test?pretty
</code></pre>
<p><strong>document CRUD</strong></p>
<pre><code>新增document文档
    put /index/type/id
    {
        &quot;key1&quot;:&quot;value1&quot;,
        &quot;key2&quot;:&quot;value2&quot;,
    }
更新document文档
POST /index/type/id/_update
   &quot;doc&quot; {
        &quot;key1&quot;:&quot;value1&quot;,
        &quot;key2&quot;:&quot;value2&quot;,
}

删除document文档
DELETE /index/type/id?pretty
</code></pre>
<h4 id="elasticsearch多种搜索方式">Elasticsearch多种搜索方式</h4>
<p>（1）、query string search（因为search都是http请求query string来附带的）</p>
<pre><code>语法：GET /index/type/_search

例：GET /index/type/_search?q=&quot;search&quot;&amp;sort=filed:desc

结果
    {
    &quot;took&quot; : 0, h耗费了几秒
    &quot;timed_out&quot; : false, 是否超时
    &quot;_shards&quot; : { // 请求了几个shard
    &quot;total&quot; : 3,
    &quot;successful&quot; : 3,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
    },
    &quot;hits&quot; : {
    &quot;total&quot; : {  查询的数量
    &quot;value&quot; : 174,
    &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 1.0, 相关度匹配分数，越相关就越匹配，分数越高
    &quot;hits&quot; : [  匹配的document的相关数据
    ]
</code></pre>
<p>在生产环境很少用</p>
<p>（2）、query DSL（Domain Specified Language 特定领域的语言） 基于Http request body请求体，可以用json格式构建语法，可以构建各种复杂的语法</p>
<pre><code>    例如：  
    {
        &quot;query&quot;:{ //查询
        “match_all”:{ //
        },
        &quot;filter&quot; :{ // 过滤
            &quot;range&quot;{
                &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
            }
        }
    }
        &quot;sort&quot;:[ 排序
        {
        &quot;price&quot;:&quot;desc&quot;
        }
        ]
        &quot;from&quot;:1, 查询游标
        &quot;size&quot;:2 查询数量
        }
        &quot;_source&quot;:[&quot;&quot;,&quot;&quot;] :指定要查询出来的field
     }
</code></pre>
<p>match_all:全部查询<br>
match:全文检索，将搜素词拆分为一个个词之后去倒排索引中进行匹配<br>
match_phrase(短语搜索) :要求输入的搜索串，必须在指定字段文本中，完全一模一样的，才能算匹配<br>
sort:排序<br>
highlight:高亮<br>
from:查询游标<br>
size：查询数量<br>
_source:指定要查询出来的field</p>
<h4 id="elasticsearch聚合搜索">Elasticsearch聚合搜索</h4>
<pre><code>GET /index/type/_search
{
    &quot;size&quot;:0,         // 去掉返回值里的hits 具体的document
    &quot;query&quot;：&quot;&quot;  // 查询条件之后在分组
    &quot;aggs&quot;:{
        &quot;group_by_tags&quot;:{       //聚合的别名
            //分组下的操作
            &quot;terms&quot;:{
                &quot;field&quot;:&quot;vaue&quot; //根据field的分组
                &quot;order&quot;:{&quot;group_by_tag1&quot;:desc/asc}  //按照内层聚合的结果降序排序
            },
            // 组内分组计算
            &quot;aggs&quot;:{
                &quot;group_by_tag1&quot;:{
                  }
                }
        }
    }
}
</code></pre>
<p>为需要聚合的filed添加正排索引</p>
<pre><code>PUT /index/_mapping/type
{
    &quot;properties&quot;:{
        &quot;field&quot;:{ //根据filed的设置
            &quot;type&quot;:&quot;string&quot;,
            &quot;fielddata&quot;:&quot;true&quot;,
        }
    }
    
}
</code></pre>
<h3 id="elasticsearch分布式架构">Elasticsearch分布式架构</h3>
<h4 id="elasticsearch基础分布式架构">Elasticsearch基础分布式架构</h4>
<h5 id="elasticsearch对复杂分布式机制的透明隐藏特性">Elasticsearch对复杂分布式机制的透明隐藏特性</h5>
<pre><code>分片机制:我们将document插入到es集群中去，不用关心数据是怎么进行分片的，数据到哪个shard中
cluster discovery：新加入的node自动发现集群，并且加入进去还接受了部分数据
Shared 负载均衡:es会自动进行负载均衡（让每个node上具备差不多的shard数量），以保持每个节点均衡读写负载请求
share副本:rep1ica shard是primary. shard的副本
集群扩容:水平扩容
请求路由:节点对等
share重分配:集群rebalance
</code></pre>
<h5 id="elasticsearch的垂直扩容与水平扩容">Elasticsearch的垂直扩容与水平扩容</h5>
<pre><code>(1).垂直扩容：采购更强大的服务器。成本高，有瓶颈
(2).水平扩容：增加服务器的数量
</code></pre>
<h5 id="elasticsearch增减节点时rebalance">Elasticsearch增减节点时rebalance</h5>
<pre><code>总有一些服务器负载重一些，承载的数据和请求会大一些，当增加或者减少节点时，数据分片会重新rebalance，实现shard的负载均衡（让每个节点的数据量差不多）
</code></pre>
<h5 id="elasticsearch的master节点">Elasticsearch的master节点</h5>
<p>（主要管理es的元数据）</p>
<pre><code>(1)、创建或者删除索引
(2)、增加或者删除节点
</code></pre>
<h5 id="elasticsearch节点平等的分布式架构">Elasticsearch节点平等的分布式架构</h5>
<pre><code>(1)、节点对等，每个节点都能接受所有请求
(2)、自动请求路由
(3)、响应收集
</code></pre>
<h4 id="分片原理">分片原理</h4>
<h5 id="shardreplica机制梳理">Shard&amp;replica机制梳理</h5>
<pre><code>(1) index包含 多个shard，将多个shard分配到各个节点上去，每个shard存储一部分数据
(2)每个shard都是一个最小工作单元， 承载部分数据，1ucene实例， 完整的建立索引和处理请求的能力
(3)增减节点时，shard会自动在nodes中负载均衡
(4) primary shard和replica shard; ，每个document肯定只存在于某一个primary      shard以及其对应的rep1ica shard中， 不可能存在于多个primary shard
(5) rep1ica shard是primary. shard的副本， 负责容错，以及承担读请求负载
(6).primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改
(7).primary shard的默认数量是5，rep1ica默认是1:默认直10个shard; 5 primary shard, 5个replica, shard
(8) primary shard不能和自己的replica shard放在同一个节点上(否则节点宕机，primary shard和副本都丢失，起不到容错的作用)，但是可以和其他primary shard的 ep1ica shard放在同一一个节点上
</code></pre>
<h4 id="elasticsearch横向扩容原理">Elasticsearch横向扩容原理</h4>
<h6 id="elasticsearch分布式原理_横向扩容如何超出扩容极限以及如何提升容错性">Elasticsearch分布式原理_横向扩容，如何超出扩容极限以及如何提升容错性</h6>
<pre><code>1、图解横向扩容过程，如何超出扩容极限，以及如何提升容错性
(1) primary&amp;rep1ica 自动负载均衡，6个shard， 3 primary，3 replica
(2)每个node有更少的shard, I0/CPU/Memory资 源给每个shard分配更多，每个shard性能更好
(3) 扩容的极限， 6个shard (3 primary, 3 replica) ，最多扩 容到6台机案，每个shard可以占用单 台服务器的所有资源，性能最好
(4)超出扩容极限，动态修改rep1ica数量，9个shard (3primary， 6 rep1ica)，扩容到9台机器，比3台机器时，拥有3倍的读吞吐量
(5) 3台机器下，9个shard (3 primary, 6 replica) ，资源更少，但是容错性更好，最多容纳2台机器宕机，6个shard只能容纳1台机器宕
</code></pre>
<h4 id="elasticsearch容错机制master选举replace容错数据恢复">Elasticsearch容错机制：master选举，replace容错，数据恢复</h4>
<pre><code>(1).容错第-步: master选举，自动选举另外一个node成为新的master ,承担起master的责任来
(2).容错第二步:新master ,将丢失掉的primary shard的某个replica shard提升为primary shard.此时cluster status会变为yellow ,因为primaryshard全都变成active了.但是,少了一个replica shard ,所以不是所有的replica shard都是active了.
(3).容错第三步:重启故障的node ,new master ,会将缺失的副本都是copy-份到该node上去。而且该node会使用之前已有的shard数据，只是同步- -下宕机之后发生过的修改。cluster status变为green,因为primary shard和replica shard都齐全了
</code></pre>
<h3 id="elasticsearch分布式document">Elasticsearch分布式document</h3>
<h4 id="index元数据">Index元数据</h4>
<pre><code>(1)代表一个document存放在哪个index中
(2)类似的数据放在一一个素引，非类似的数据放不同索引
(3) index中包含了很多类似的document
(4)索引名称必须是小写的，不能用下划线开头，不能包含逗号
</code></pre>
<h4 id="type元数据">Type元数据</h4>
<pre><code>(1)代表document属于index中的哪个类别(type)
(2)一个索引通常会划分为多个type,谭辑上对index中有些许不同的几类数据进行分类
(3) type名称可以是大写或者小写，但是同时不能用下划线开头，不能包含逗号
</code></pre>
<h4 id="id元数据">Id元数据</h4>
<pre><code>(1)代表document的唯-标识， 与index和type一起， 可以唯-标识和定位一-个document
(2)我们可以手动指定document的id,也可以不指定，由es自动为我们创建一-个id
</code></pre>
<p>根据应用情况来说，是否满足手动指定document id的前提:</p>
<pre><code>-般来说，是从某些其他的系统中，导入一些数据到es时，会采取这种方式，就是使用系统中已有数据的唯一标识，作为es中document的id。 举个例子，比如说，我们现在在开发
- 一个电商网站，做搜索功能:或者是0A系统，做员工检索功能。这个时候，数据首先会在网站系统或者IT系统内部的数据库中，会先有一 份，此时就肯定会有- 一个数据库的primary
  key (自增长，UID,或者是业务编号)。如果将数据导入到es中，此时就比较适合采用数据在数据库中已有的primary key。
  如果说，我们是在做一个系统，这个系统主要的数据存储就是es- -种，也就是说，数据产生出来以后，可能就没有id, 直接就放es- -个存储，那么这个时候，可能就不太适合说手
  动指定document id的形式了，因为你也不知道i d应该是什么，此时可以采取下面要讲解的让es自动生成i d的方式。
  (2) put /index/ type/id
  (3.2)、自动生成document id
  (1) post ./index/ type.
  (2)自动生成的id,长度为20个字符，URL安全，base64编码， GUID, 分布式系统并行生成时不可能会发生冲突
</code></pre>
<h4 id="source元数据">Source元数据</h4>
<pre><code>_source元数据:就是说，我们在创建一个document的时候， 使用的那个放在request body中的json串， 默认情况下，在get的时候，会原封不动的给我们返回回来。定制返回的结果，指定_source中，返回哪些field
</code></pre>
<h4 id="document的全量替换">Document的全量替换</h4>
<p>(1)语法与创建文档是一样的。如果document id不存在，那么就是创建:如果document. ig已经存在，那么就是舍量替换操作,替换document的json串内容<br>
(2) document是不可变的，如果要修改document的内容，第-种方式就是全量替换，直接对document重新建立索引，替换里面所有的内容。<br>
PUT /index/type/id?<br>
(3) es会将老的document标记为deleted,然后新增我们给定的一个document, 当我们创建越来越多的document的时候，es会 在适当的时机在后台自动删除标记为deleted的<br>
document<br>
2、document的强制创建<br>
(1)创建文档与全量替换的语法是一样的， 有时我们只是想新建文档，不想替换文档，如果强制进行创建呢?<br>
(2) PUT /index/ type/id?op__type=create,<br>
PUT /index/type/id/_create<br>
3、document的删除<br>
(1) DELETE  index/type/id<br>
(2)不会理解物理删除，只会将其标记为deleted，当数据越来越多的时候，在后台自动删除</p>
<p>1.Elasticsearch内部如何基于_version如何进行乐观锁并发控制</p>
<p>1.第一次创建一个document的时候，它的_version内部版本号就是1;<br>
2.以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1;哪怕是删除，也会对这条数据的版本号加1<br>
3.多线程并发更新数据时,先获取document数据和最新版本号， 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错或执行retry策略（retry_ on_ conf1ict）;<br>
3.别的线程更新失败后，执行retry策略<br>
retry策略<br>
1、再次获取document数据和最新版本号<br>
2、基于最新版本号再次去更新，如果成功那么就ok了<br>
3、如果失败,重复1和2两个步骤,最多,重复几次呢?可以通过retry那个参数的值指定,比如5次</p>
<h4 id="基于externa1lversion进行乐观锁并发控制">基于externa1lVersion进行乐观锁并发控制</h4>
<pre><code>es提供了一个feature, 就是说，你可以不用它提供的内部_version版本号来进行并发控制，可以基于你自己维护的一一个版本号来进行并发控制。
举个列子，加入你的数据在mysq1
里也有一份，然后你的应用系统本身就维护了-一个版本号，无论是什么自己生成的，程序控制的。
这个时候，你进行乐观锁并发控制的时候，可能并不是想要用es内部的_version来进行控制，而是用你自己维护的那个version来进行控制。
?version=1
?version=1&amp;version_type=externa1

version_type=externa1,唯一-的区别在于， version, 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错;

当version_type=externa1的时候， 只有当你提供的versi on比es中的_versi on大的时候，才能完成修改
es，_version=1?version=1， 才能更新成功
es，_version=1?version&gt; 1&amp;version_type=externa1, 才能成功，比如说?versi on=2&amp;version_type=externa1
</code></pre>
<h4 id="partialupdate">PartialUpdate</h4>
<p>全量替换语法：</p>
<pre><code>PUT /index/type/id,创建文档&amp;替换文档，就是-样的语法
</code></pre>
<p>partial update语法：</p>
<pre><code>post /index/ type/id/_ update
{
'要修改的少数几个fie1d即可，不需要全量的数据”：&quot;&quot;，
&quot;retry_ on_ conf1ict&quot;:&quot;5&quot;  //retry策略
}
</code></pre>
<p>般对应到应用程序中，每次的执行流程基本是这样的（和全量替换的原理一样）:</p>
<pre><code>(1)应用程序发起一个get请求，获取到document， 展示到前台界面，供用户查看和修改
(2)用户在前台界面修改数据，发送到后台
(3)后台代码，会将用户修改的数据在内存中进行执行，然后封装好修改后的全量数据
(4)然后发送PUT请求，到es中， 进行全量替换
(5) es将老的document标记为de1eted，然后重新创建一个 新的document
</code></pre>
<p>看起来，好像就比较方便了，每次就传递少数几个发生修改的fie1d即可，不需要将全量的document数据发送过去</p>
<p>2、图解partial update实现原理以及其优点</p>
<pre><code>partial update, 看起来很方便的操作，实际内部的原理是什么样子的，然后它的优点是什么|

其实es内部对partial update的实际执行,跟传统的全量替换方式，是几乎-样的

1、内部先获取document
2、将传过来的field更新到document的json中
3、将老的document标记为deleted
4、将修改后的新的document创建出来
</code></pre>
<p>partial update相较于全量替换的优点</p>
<pre><code>1、所有的查询、修改和写回操作,都发生在es中的一 个shard内部,避免了所有的网络数据传输的开销(减少2次网络请求) , 大大提升了性能
2、减少了查询和修改中的时间间隔,可以有效减少并发冲突的情况
</code></pre>
<p>基于groovy脚本，如何执行partial update</p>
<pre><code>es， 其实是有个内置的脚本支持的， 可以基于groovy脚本实现各种各样的复杂操作
基于groovy脚本，如何执行partia1 update.
es scripting module, 我们会在高手进阶篇去讲解，这里就只是初步讲解一-下
</code></pre>
<p>partial update乐观锁并发控制原理</p>
<p>1.第一次创建一个document的时候，它的_version内部版本号就是1;<br>
2.以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1;哪怕是删除，也会对这条数据的版本号加1<br>
3.多线程并发更新数据时,先获取document数据和最新版本号， 只有当你提供的version与es中的，version-模一样的时候，才可以进行修改，只要不一样，就报错或执行retry策略（retry_ on_ conf1ict）;<br>
3.别的线程更新失败后，执行retry策略<br>
retry策略<br>
1、再次获取document数据和最新版本号<br>
2、基于最新版本号再次去更新，如果成功那么就ok了<br>
3、如果失败,重复1和2两个步骤,最多,重复几次呢?可以通过retry那个参数的值指定,比如5次</p>
<h4 id="批量操作">批量操作</h4>
<p>mget批量查询API(很重要，性能优化的一种方式)</p>
<pre><code>就是一条一条的查询，比如说要查询100条数据，那么就要发送100次网络请求，这个开销还是很大的
如果进行批量查询的话，查询100条数据，就只要发送1次网络请求，网络请求的性能开销缩减100倍
</code></pre>
<p>语法一：查询不同一个index不同type的Document</p>
<pre><code>GET /index/_mget
    {
    &quot;docs&quot;:[
        {
        &quot;_index&quot;：&quot;index&quot;，
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        },
        {
        &quot;_index&quot;：&quot;index&quot;，
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        }
}
</code></pre>
<p>语法二：查询同一个index不同type的Document</p>
<pre><code>GET /index/_mget
{
    &quot;docs&quot;:[
        {
            &quot;_type&quot;: &quot;type&quot;,
            &quot;_id&quot;:&quot;id&quot;
        },
        {
        &quot;_type&quot;: &quot;type&quot;,
        &quot;_id&quot;:&quot;id&quot;
        }
}
</code></pre>
<p>mget的重要性</p>
<p>可以说mget是很重要的，一 般来说，在进行查询的时候，如果一 次性要查询多条数据的话，那么一定要用batch批量操作的api<br>
尽可能减少网络开销次数，可能可以将性能提升数倍，其至数十倍，非常非常之重要</p>
<p>bulk批量增删改</p>
<p>1、bulk语法</p>
<pre><code>POST /_bulk 或则POST index/type/_bulk
delete&quot;: {” index&quot;:&quot; test_ index,，” type&quot; :“ test_ type'“?”J
create&quot; :index&quot; :” test_ index，”_ type' :” test_ type&quot;，”_ id&quot; :“ 12”} }test_ fie1d&quot;: &quot; test12”}
index&quot;: {_index&quot;:&quot; test_ index' '，”_type&quot; : &quot;test_ _type” }}，test_ field&quot; :auto-generate id test
index&quot; :_index&quot; :” test_ index”_type”: &quot;test_ type&quot;， ”id&quot;:“2”}}'test_ fie1d”:&quot; replaced test2”
update&quot; : {”_ index :“ test_ index'，“type”: &quot;test_ _type”，”id&quot;: &quot;1”， ”retry_ on_ conf1ict&quot; :3} }
{“doc&quot; : {&quot;test_ fie1d2” : &quot;bulk test1&quot;} }
</code></pre>
<p>每一-个操作要两个json串， 语法如下:</p>
<pre><code>'action&quot;: { 'metadata&quot;}}&quot;data&quot;}
举例，比如你现在要创建一 个文档，放bulk里面，看起来会是这样子的:

{&quot; index&quot;: {&quot;_ _index&quot;: &quot;test_ index&quot;，”type&quot;，&quot;test_ type&quot;， &quot; id&quot;:“1&quot;}}
{&quot; test_ fie1d1&quot;:“ test1&quot;，&quot;test_ fie1d2&quot;: &quot;test2&quot;}
</code></pre>
<p>一个操作的语法不能换行，不同操作的语法要换行</p>
<p>有哪些类型的操作可以执行呢?</p>
<pre><code>(1) delete: 删除一个文档
(2) create: PUT /index/type/id/ create， 强制创建
(3) index: 普通的put操作，可以是创建文档，也可以是全量替换文档
( 4) update: 执行的partial update操作
</code></pre>
<p>bulk size最佳大小</p>
<pre><code>bulk, reguest会加载到内存里， 如果太大的话，性能反而会下降，因此需要反复尝试一 个最佳的bulk size。 - -般从1000 5000条数据开始，尝试逐渐增加。另外，如果看大小的话
最好是在5^ 15MB之间。
</code></pre>
<p>document 总结</p>
<pre><code>到目前为止，你觉得你在学什么东西，给大家个真观的感觉，好像已经知道了es是分布式的， 包括一些基本的原理，然后化了不少时间在学习document本身相关的操作，增删改
查。一句话点出来，给大家归纳总结一 下，其实我们应该思考一 下，es的一个最最核心的功能，已经被我们相对完整的讲完了。
Blastigsearch件电智
来以
其实起到的第一个最核心的功能。就是、个分布式的文档数据存储系统。ES是 分布式的。文档数据存储系统。文档据，存储系统。
文档数据: es可以存储和操作json文档类型的数据， 而且这也是es的核心数据结构。
存储系统: es可以对json文档类型的数据进行存储，查询，创建，更新，删除，等等操作。其实已经起到了一个什么样的效果呢?其实ES满足了这些功能，就可以说已经是一个
NoSQL的存储系统了。
围绕着document在操作，其实就是把es当成了一个NoSQL存储引擎，一个 可以存储文档类型数据的存储系统，在操作里面的document。
s可以作为一个分布式的文档存储系统，所以说，我们的应用系统，是不是就可以基于这个概念，去进行相关的应用程序的开发了。
什么类型的应用程序呢?
I (①)数据量较大: es的分布式本质，可以帮助你快速进行护
有的
承载大量数据
(2)
教据精构家适备著随时可能会奔化计雪且教据替格之间的美系常基森出 如果聚们用传统数摄居奇那号不是很玩，因为要面临太量的表
(3)
对数据的
作较为简单，比
就是一些间
改查，用我们之前讲解的那些document操作就可以搞定
(4) NoSQL数据库，适用的也是类似于，上面的这种场景
举个例子，比如说像一些网站系统，或者是普通的电商系统，博客系统，面向对象概念比较复杂，但是作为终端网站来说，没什么太复杂的功能，就是一些简单的CRUD操作， 而且
数据量可能还比较大。这个时候选用ES这种NoSQL型的数据存储，比传统的复杂的功能务必强大的支持SOL的关系型数据库，更加合适一些。无论是性能，还是
春吐量，可能都会更|
好。
</code></pre>
<h3 id="elasticsearch分布式系统">Elasticsearch分布式系统</h3>
<h4 id="document数据路由原理">Document数据路由原理</h4>
<p>document路由到shard是什么意思？</p>
<p>我们知道一个index数据会被分为多片，每片都在一个shard中<br>
所以一个document，只能存放在一个shard中（primary shard）</p>
<p>后面primary shard 会同步到replica shard上</p>
<p>当客户端创建document的时候，此时需要决定，这个document<br>
要放在这个index哪个shard上。<br>
<img src="images/document_route.png" alt="document_route.png" loading="lazy"></p>
<p>(2)路由算法: shard = hash(routing) % number_of_primary_shards举个例子，一个index有3个primary shard, PO, P1, P2</p>
<pre><code>每次增册改查一 个document的时候， 都会带过来一 个routing number,
默认就是这个document的_id (可能是手动指定，也可能是自动生成)routing =. id, 假设. id=1

会将这个routing值， 传入一个hash函数中，产出- -个routing值的hash值， hash(routing) = 21

然后将hash函数产出的值对这个index的primary shard的数量求余数，21%3= 0就决定了，这个document就放在P0上。
</code></pre>
<p>决定一个document在哪个shard上， 最重要的一一个值就是routing值，默认是id,也可以手动指定，相同的routing值，</p>
<p>每次过来，从hash函数中， 产出的hash值-定是相同的无论hash值是几，无论是什么数字，对number_ _of. primary. shards求余数，结果-定是在0 *number_of_primary_shards-1之间这个范围内的。0,1, 2。</p>
<p>(3)_ id or custom routing value默认的routing就是id.</p>
<pre><code>也可以在发送请求的时候，手动指定一 个routing value, 比如说put /index/type/id?routing =useid

手动指定routing value是很有用的， 可以保证说，某- -类document- -定被路由到一-个shard上去， 那么在后续进行应用级别的负载均衡，以及提升批量读取的性能的时候，是很有
</code></pre>
<p>(4) primary shard数量不可变的谜底（路由算法只和primary. shards的数量有关）</p>
<pre><code>因为shard = hash(routing) % number_of_primary_shards决定了document 在哪个shard上，
如果改变，导致数据不在之前的shard上，导致查询的时候，无法找到，就会间接导致数据丢失。
private shard 一旦index建立，是不允许修改的，replica shard 是可以改变的
</code></pre>
<h4 id="document增删改内部原理">Document增删改内部原理</h4>
<figure data-type="image" tabindex="1"><img src="images/document_rud.png" alt="document_rud.png" loading="lazy"></figure>
<pre><code>(1)客户端任意选择-个node发送请求过去，，这个node就会变成coordinating. node (协调节点)
(2) coordinating, node,对document进行路由，,将请求转发给对应的node (有primary shard,因为是增删改操作，请求只能路由到primary shard上去)
(3)实际的node.上的pri mary shard处理请求，然后将数据同步到replica node
(4) coordinating node, 如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端
</code></pre>
<h4 id="写一致性原理以及quorum机制的深入解析">写一致性原理以及quorum机制的深入解析</h4>
<p>(1)我们在发送任何一一个增删改操作的时候，比如说put /index/type/id?consistency=one, 都可以带上一个consistency参数，指明我们想要的写-致性是什么 ?put /index/ type/id?consistency-quorum</p>
<p>consistency= one (primary shard)或者a11 (a11 shard)或者quorum (default)</p>
<p>one:要求我们这个写操作，只要有一个primary shard量active活跃可用的、 就可以执行<br>
all: 要求我们作，必须所有的primary shard和replica shard都是活跃的，才可以执行这个写操作，<br>
quorum: 默认的值，要求所有的shard中， 必须是大部分的shard都是活跃的，可用的，才可以执行这个写操作</p>
<p>(2) quorum机制， 写之前必须确保大多数shard都可用，</p>
<p>quorum = int( (primary+number_of_replicas) / 2 ) + 1， 当number_of_replicas&gt;1 quorum机制才生效<br>
quorum= int( (primary_number_of_replicas) / 2 )1、<br>
举个例子，3个primary, shard, number_of_replicas=1, 总共有3 + 3 * 1 = 6个shard<br>
quorum= int( (3+1)/2)<br>
所以，要求6个shard中至少有3个shard是active状态的， 才可以执行这个写操作</p>
<p>(3)如果节点数少于quorum数量，可能导致quorum不齐全， 进而导致无法执行任何写操作<br>
3个primary, shard, rep1ica=1, 要求至少3个shard号active;<br>
3个shard按照之前学习的shard&amp;replica机制，必须在不同的节点上，如果说只有1台机器的话，是不是有可能出现说3个shard都没法分配齐全，<br>
此时就可能会出现写操作无法执行的情况</p>
<p>1个primary_ shard, replica=3, quorum=((1+3) / 2) + 1=3，要求1个primary shard + 3个rep1ica shard = 4个shard,<br>
其中必须有3个shard是要处于active状态的。如果这个时候只有2台机器的话，会出现什么情祝呢?<br>
es提供了一 种特殊的处理场景，就是说当number_of_replicas&gt; 1时才生效，因为假如说，你就一 个primary shard, replica=1, 此时就2个shard.<br>
(1+1/2)+1=2，要求必须有2个shard是活跃的，但是可能就1个node, 此时就1个shard是活跃的，如果你不特殊处理的话，导致我们的单节点集群就无法工作</p>
<p>(4) quorum不齐全时，wait， 默认1分钟，timeout, 100， 30s<br>
等待期间，期望活跃的shard数量可以增加，最后实在不行，就会timeout<br>
我们其实可以在写操作的时候，加一个timeout参数，<br>
比如说put /index/type/id?timeout-30， 这个就是说自己去设定quorum不齐全的时候， es的timeout时长， 可以缩短，也可以增长</p>
<h4 id="document内部查询原理">Document内部查询原理</h4>
<figure data-type="image" tabindex="2"><img src="images/document_query.png" alt="img.png" loading="lazy"></figure>
<pre><code>1、客户端发送请求到任意一个node, 成为coordinate. node, coordinate node对document进行路由 ，将请 求转发到对应的node,
2、此时会使用round-robin随机轮询算法，在primary shard以及其所有rep1ica中随机选择一个，让读请求负载
3、接收请求的node返回document给coordinate node
4、coordinate node返回
</code></pre>
<p>和写不一样的是，写是找primary shard，读的时候primary shard和replica shard</p>
<p>5、特殊情况: document如果还在建立索引过程中，可能只有primary shard有, 任何一个repl1ica shard都没有， 此时可能会导致无法读取到document, 但是document完成引建立z后，primary shard和replica shard就都有了</p>
<h4 id="builapi的奇特json格式与底层性能优化关系">BuilApi的奇特json格式与底层性能优化关系</h4>
<p>1、bulk中的每个操作都可能要转发到不同的node的shard去执行<br>
2、如果采用比较良好的json数组格式<br>
允许任意的换行，整个可读性非常棒，读起来很爽，es拿到那种标准格式的ison串以后，要按照下述流程去进行处理<br>
(1)将json数组解析为ISONArray对象，这个时候，整个数据，就会在内存中出现一份-模一样的拷贝，-份数据是jison文本，一份数据是JSONArray对象2)解析json落组里的每个对每个请求中的document进行路由<br>
为路由到同一个shardE的多个请求，创建一个请求数组(4)将这个<br>
(5)将序列化后的请求数组发送到对应的节点上去</p>
<p>3、耗费更多内存，更多的jvm gc开销<br>
我们之前提到过bulk size最佳大小的那个问题，--般建议说在几千条那样，然后大小在10MB左右，所以说，可怕的事情来了。假设说现在100个bulk请求发送到了一个节点上去，然后每个请求是10MB，100个请求，就是1000MB = 1GB， 然后每个请求的json都copy 份为jsonarray对象， 此时内存中的占用就会翻倍，就会占用2GB的内存， 甚至还不止。因为弄成jsonarrayZ后，还可能会多搞一些其他的数据结构，2GB+的内存占用。</p>
<p>占用更多的内存可能就会积压其他请求的内存使用量，比如说最重要的搜索请求，分析请求，等等，此时就可能会导致其他请求的性能急速下降，<br>
另外的话，占用内存更多，就会导致java虚拟机的垃圾回收次数更多，跟频繁，每次要回收的垃圾对象更多，耗费的时间更多，导致es的java虚拟机停止工作线程的时间更</p>
<p>现在的奇持格式<br>
(action:{meta&quot;]}\n&quot;data&quot;}}n<br>
&quot;action&quot;:(meta&quot;}n'data&quot;'}\r</p>
<p>(1)不用将其转换为json对象，不会出现内存中的相同数据的拷见，直接按照换行往ison<br>
(2)对每两个组的json，读取meta,进行document路由<br>
(3)直接将对应的json发送到node上去</p>
<p>5、最大的优势在于，不需要将ison数组解析为一个TSONArray对象， 形成一份大数据的拷贝，很费内存空间，尽可能地保证性的</p>
<h3 id="elasticsearch搜索引擎">Elasticsearch搜索引擎</h3>
<h4 id="search结果的深入解析">Search结果的深入解析</h4>
<pre><code>took:整个搜索请求花费了多少毫秒
hits. total:本次搜索返回了几条结果
hits. max_score:本次搜索的所有结果中，最大的相关度分数是多少，每一条document对于search的相关度，越相关，score分数越大， 排位越靠前
hits. hits:默认查询前10条数据，完整数据，score降序排序
shards; shards. fa1的条件(pri mary和replica全部挂掉)，不影响其他shard。默认情况下来说，一个搜索请求，会打到一个index的所有primary shard上去，当然了，每个primary shard都可能会有一个或多 个rep1ic shard, 所以请求也可以到primary shard的其中一个rep1ica shard上去。
timeout:默认无timeout, 1atency平衡icompleteness, 手动指定tineout，
timeout 查询执行机制:指定每个shard就在指定的timed out时间范围内，将搜索到的部分数据直接返回给client，而不是等到所有的数据都搜索出来了在返回
确保说一次搜索，可以在用户指定的time out时间内完成，为时间敏感的搜索应用提供良好的支持
</code></pre>
<h4 id="multi-indexmulti-type搜索模式解析以及搜索原理">Multi-index&amp;multi-type搜索模式解析以及搜索原理</h4>
<figure data-type="image" tabindex="3"><img src="images/Multi-index.png" alt="img.png" loading="lazy"></figure>
<h4 id="分页搜索以及deep-paging性能问题深度图解">分页搜索以及deep paging性能问题深度图解</h4>
<figure data-type="image" tabindex="4"><img src="images/deep_paging.png" alt="img.png" loading="lazy"></figure>
<p>deep paging:搜索特别深，总共6w数据，每个shard分了2w，每页10条数据，<br>
这个时候你要搜索到1000页，每个shard都要返回10010条数据，那么会返回30030条数据，排序，<br>
汇总之后，取第1000页的数据，会出现性能问题</p>
<h4 id="速掌握query-string-search语法以及_all-metadata原理揭秘">速掌握query string search语法以及_all metadata原理揭秘</h4>
<p>基础语法：<br>
GET /index/type/_search?q=filed:value<br>
_all metadata原理：<br>
es中的_all元数据，在建立索引的时候，我们插入一条document，它里面包含了多个field,此时es会将多个field值串联起来<br>
作为_all field的值，同时建立索引<br>
后面如果在搜索的时候，没有对某个filed指定搜索，就默认搜_all field的,其中是包含了所有field的值</p>
<h4 id="mapping">mapping</h4>
<p>mapping:自动或者手动对index建立数据结构和相关配置。mapping里包含了每个field对应的数据类型以及如何分词和搜索的行为。<br>
dynamic mapping:自动为我们建立index，type，以及对应的mapping。mapping里包含了每个field对应的数据类型以及如何分词。</p>
<pre><code>(1)往es里面直接插入数据:会自动建立索引。同时建立type以及对应的mapping
(2) mapping中就自动定义每个filed的数据类型
(3)不同的数据类型(正如说text和date)，可能有的是exact value, full text
(4)exact value在建立倒排索引的时候，分词的时候，是将整个值-起作-一个关键词建立到倒排索引中的: full text, 会经历各种各样的处理，分词，normaliztion (时态转换，同义词转换，天小弓转换)，才会建立到倒排索引中
(5)同时呢，exact value和fu11 text类型的filed就决定了，在一个搜索过来的时候，对exact value fie1d或者是full text. filed进行搜索的行为也是不一样的，会跟建立倒排索引的行为保持一致;比如说exact value搜索的时候，  直接按照整索引行为，包括分词器，等等
(6)可以用dynamic mapping让其自动建立mapping,包括自动设置数据类型，也可以手动index和type的mapping, 自己对各filed进存设置，包括数据类型，包括数据类型，包括分词等等
</code></pre>
<p>总结：mapping决定了field数据类型，倒排索引的行为，还有搜索的行为。</p>
<p>mapping数据类型：</p>
<pre><code>text，byte，short,integer,long float ,double ,boolean ,date
</code></pre>
<p>查询 mapping</p>
<pre><code>GET index/_mapping/type
</code></pre>
<p>只能创建index时手动指定mapping或者添加field mapping，不能修改field mapping</p>
<p>string默认是分词的，也可以手动指定分词行为<br>
analyzed：分词<br>
no_analyzed:不分词<br>
no：不分词不被搜索</p>
<p>创建索引指定filed mapping</p>
<figure data-type="image" tabindex="5"><img src="images/mapping.png" alt="img.png" loading="lazy"></figure>
<p>添加field mapping</p>
<figure data-type="image" tabindex="6"><img src="images/add_field_mapping.png" alt="img.png" loading="lazy"></figure>
<p>查看分词效果</p>
<figure data-type="image" tabindex="7"><img src="images/sehngchanzhexierushuju.png" alt="img.png" loading="lazy"></figure>
<p>es支持两种模式的搜索：<br>
full_text:全文检索<br>
exact_value:精确搜索<br>
不同的filed 有点可能是full_text 有的可能是exact_value<br>
query string search 会用跟倒排索引一样的分词器去进行分词</p>
<h4 id="倒排索引的核心原理快速解密">倒排索引的核心原理快速解密</h4>
<p>倒排索引最简单的建立过程</p>
<figure data-type="image" tabindex="8"><img src="images/daopaisuoyin.png" alt="img.png" loading="lazy"></figure>
<p>normalization：在建立倒排索引的时候，会执行一个操作，也就是说对拆分出来的各个单词进行处理<br>
以提升后面搜索的时候能够搜到相关联文档的概率</p>
<p>我们在搜索的时候，会把词进行拆分，把每一个词去倒排索引中去匹配。</p>
<h4 id="分词器">分词器</h4>
<p>切分词语，<br>
normalization (提升recal1召回率)</p>
<h4 id="querydsl">QueryDSL</h4>
<p>（2）、query DSL（Domain Specified Language 特定领域的语言） 基于Http request body请求体，可以用json格式构建语法，可以构建各种复杂的语法</p>
<pre><code>    例如：  
    {
        &quot;query&quot;:{ //查询
        “match_all”:{ //
        },
        &quot;filter&quot; :{ // 过滤
            &quot;range&quot;{
                &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
            }
        }
    }
        &quot;sort&quot;:[ 排序
        {
        &quot;price&quot;:&quot;desc&quot;
        }
        ]
        &quot;from&quot;:1, 查询游标
        &quot;size&quot;:2 查询数量
        }
        &quot;_source&quot;:[&quot;&quot;,&quot;&quot;] :指定要查询出来的field
     }
</code></pre>
<p>bool:组合查询，其他的查询放在bool下<br>
must:必须匹配<br>
should：可以匹配也可以不匹配<br>
must_not:不要匹配<br>
match_all:全部查询<br>
match:全文检索，将搜素词拆分为一个个词之后去倒排索引中进行匹配<br>
match_phrase(短语搜索) :要求输入的搜索串，必须在指定字段文本中，完全一模一样的，才能算匹配<br>
term:不分词去倒排索引中匹配（比较少用，建立mapping的时候，可以指定那个field不分词）<br>
terms:不分词去倒排索引中匹配（比较少用，建立mapping的时候，可以指定那个field不分词）<br>
exists：搜索词不能为空<br>
sort:排序<br>
highlight:高亮<br>
from:查询游标<br>
size：查询数量<br>
_source:指定要查询出来的field</p>
<p>filter,仅仅只是按照搜索条件过滤出需要的数据而已，不计算任何相关度分数，对相关度没有任何影响<br>
query,会去计算每个document相对于搜索条件的相关度，并按照相关度进行排序<br>
-般来说，如果你是在进行搜索，需要将最匹配搜索条件的数据先返回，那么用query; 如果你只是要根据一些条件筛选出一部分数据，不关注其排序。那么用filter<br>
除非是你的这些搜索案件，你希望越符合这些搜索条件的document起排在前面返回，那么这些搜索条件放在query中;如果你不希望-一些搜索条 件来影响你的document排序，那么filter中即可<br>
3、fi1ter与 query性能<br>
fi1ter,不需要计算相关度分数:不需要按照相关度分数进行排序，同时还有内置的自动cache最常使用filter的功能<br>
query,相反，要计算相关度分数，按照分数进行排序，而且无法cache结果</p>
<p>不要bool，只要filter的话，</p>
<pre><code>{
&quot;query&quot;:{ //查询
  “constant_score”:{
    &quot;filter&quot; :{ // 过滤
    &quot;range&quot;{
    &quot;price&quot; :{&quot;gt&quot;,&quot;&quot;}
    }
   },

}
</code></pre>
<p>定位DSL语法不合法的原因</p>
<pre><code>GET /index/type/_validate/query?explain
{
    DSL语句
}
</code></pre>
<h4 id="对stringfield排序">对StringField排序</h4>
<p>如果对string file 排序，结果往往是不准确的，因为分词后是多个单词，再排序就不是我们想要的结果<br>
通常解决办法是，将一个string filed索引两次，一个分词用来搜索，另一个不分词，用来排序</p>
<p>方式一：</p>
<pre><code>PUT /index/type/
{
   &quot;mapping&quot;:{
      type:text, /第一次设置分词
      fields:{    //第二次设置不分词
        &quot;raw&quot;:{
            type:string,
            index:&quot;not_analyzed&quot;
        },
      &quot;fielddata&quot;:true  //设置正排索引，为了排序
     }
   }
}
</code></pre>
<h4 id="相关度评分tfidf算法">相关度评分TF&amp;IDF算法</h4>
<p>relevance score算法， 简单来说，就是计算出，-个索引中的文本，与搜索文本，他们之间的关联匹配程度</p>
<p>Elasticsearch 使用的是 term frequency/ inverse document frequency算法， 简称为TF /IDF算法</p>
<p>Term frequency: 搜索文本中的各个词条在fie1d文本中出现了多少次，出现次数越多，就越相关<br>
Inverse document frequency: 搜索文本中的各个词条在整个索引的所有文档中出现了多少次，出现的次数越多，就越不相关<br>
Field-1ength norm: fie1d长度， fie1d越长， 相关度越弱</p>
<p>查看_score分数<br>
GET /test_index/test_type/_search?explain<br>
{<br>
query”: {<br>
'term”: {<br>
&quot;test_filed&quot;:&quot;&quot;<br>
}<br>
}<br>
}</p>
<h4 id="docvalues正排索引">DocValues正排索引</h4>
<p>搜索的吋候，要依靠倒排索引;排序的吋候，需要依靠正排索引，看到毎个document的毎个field, 然后迸行排序，<br>
所渭的正排索引,其是就是doc values<br>
在建:立索引的吋候，-一方面会建立倒排素引，以供搜索用; 一方面会建立正排索引，也就是doc values, 以供排序，聚合,辻濾等操作使用</p>
<p>doc values是被保存在磁盘上的。</p>
<p>如果内存足够，os会自劫将其缓存在内存中，性能逐是会很高;如果内存不足够，os会将其写入磁盈上</p>
<h4 id="queryphase">QueryPhase</h4>
<figure data-type="image" tabindex="9"><img src="images/queryPhase.png" alt="img_1.png" loading="lazy"></figure>
<p>(1)搜索请求发送到某一个coordinate node, 构构建一个priority queue, 长度以paging操作from和size为准，默认为10<br>
(2) coordinate_node将请求转发到所有shard,每个shard本地搜索，并构建一个本地的priority queue<br>
(3)各个shard将自己的priority queue返回给coordinate node， 并构建一个全局的priority queue</p>
<h4 id="fetchphase">FetchPhase</h4>
<figure data-type="image" tabindex="10"><img src="images/FetchPhase.png" alt="img_1.png" loading="lazy"></figure>
<p>（1）coordinate node构建完priority queue之后，就发送mget请求去所有shard上获取对应的document<br>
（2）各个shard将document返回给coordinate node<br>
（3）coordinate node将合并后的document结果返回给client客户端</p>
<h4 id="搜索相关参数梳理以及bouncingresults问题的解决方案">搜索相关参数梳理以及bouncingresults问题的解决方案</h4>
<p>1、preference<br>
决定了哪些shard会被用来执行搜索操作<br>
<em>primary,</em> primary_ first,_ 1oca1，_ on1y_ <em>node:xyz，</em> prefer_ node:xyz，_ shards:2,3<br>
bguncing. results问题，两个document排序， fie1d值相同; 不同的shard上，可能排序不同;每次请求轮询打到不同的replica shard上; 每次页面上看到的搜索结果的排序都不一<br>
样。这就是bouncing resu1t， 也就是跳跃的结果。<br>
搜索的时候，是轮询将搜索请求发送到每一-个replica shard (primary shard)，但是在不同的shard上，可能document的排序不同<br>
解决方案就是将preference设置为一个字符串，比如说user_ id, 让每个user每次搜索的时候，都使用同- -个replica shard去执行， 就不会看到bouncing results了<br>
2、timeout, 已经讲解过原理了，主要就是限定在一定时间内，将部分获取到的数据直接返回，避免查询耗时过张<br>
3、 routing, document文档路由， id路由，routing=user id, 这样的话可以让同一个user对应的数据到一个shard上去<br>
4、search_ type<br>
default: query_ <em>then</em> <em>fetch,<br>
dfs</em> query_ <em>then</em> fetch,可以提升revel ance sort精准度</p>
<h4 id="scoll技术滚动搜索大量数据">Scoll技术滚动搜索大量数据</h4>
<p>如果一次性要查出来比如10万条数据，那么性能会很差，此时一般会采取用sco11滚动查询，一批一批的查，直到所有数据都查询完处理完<br>
使用sco11滚动搜索，可以先搜索一批数据，然后下次再搜索一批数据，以此类推，直到搜索出全部的数据来，</p>
<p>scoll搜索会在第一次搜索的时候，保存一一个当时的视图快照，之后只会基于该旧的视图快照提供数据搜索，如果这个期间数据变更,是不会让用户看到的<br>
采用基于_doc进行排序的方式，性能较高<br>
每次发送scroll请求，我们还需要指定一个sco11参数， 指定一个时间窗口， 每次搜索请求只要在这个时间窗口内能完成就可以了<br>
GET /index/_search?scroll=1m<br>
&quot;query&quot;: {<br>
&quot;metch_a11&quot;: {},<br>
&quot;sort&quot;:[&quot;_doc&quot;],<br>
&quot;size&quot;: 1000<br>
」<br>
获得的结果会有一个scrollid, 下一次再发送scroll请求的时候，必须带上这个scrollid .<br>
GET /_search/scro11<br>
&quot;scroll&quot; :<br>
” scroll<br>
“cXV1 cn1UaGVuRmV0Y2g7NTsxMDk5NDpkUmpiR2F j0F NhNn1CM 1ZDMWpWYnRR0zEw0Tk 10mRSamJHYWM 4U2E2eUI zVkl{xa1Zi dFE7MTA50TM6ZF JqYkdhYzhTYTZ5Q jNWQzF qVmJOUTsxMTE5MDpBVUtwN21 x<br>
c1FLZV8yRGVjW1I2QUVB0zEw0Tk20mRSamJHYWM4U2E2eUI zVkMxa1Zi dFE7MDs='<br>
size会发送给每个shard, 因此每次最多会返回size * primary shard条数据</p>
<p>scoll，看起来挺像分页的，但是其实使用场景不-样。<br>
分页主要是用来一页一页搜索,给用户看的;<br>
sco11主要是用来一批一批检索数据，让系统进行处理的</p>
<h3 id="elasticsearch索引管理">Elasticsearch索引管理</h3>
<h4 id="索引的增删改">索引的增删改</h4>
<h4 id="修改分词起以及定制分词器">修改分词起以及定制分词器</h4>
<h4 id="深入探索type底层数据结构">深入探索type底层数据结构</h4>
<h4 id="mappingrootobject深入解析">MappingRootObject深入解析</h4>
<h4 id="定制化自己的dynamicmapping策略">定制化自己的dynamicMapping策略</h4>
<h2 id="elasticsearch高手进阶篇">Elasticsearch高手进阶篇</h2>
<h3 id="深度揭秘搜索技术">深度揭秘搜索技术</h3>
<p>TermFilter</p>
<p>GET /index/_search<br>
{<br>
&quot;query&quot; : {<br>
constant_score:{<br>
filter:{bool:{<br>
}<br>
}<br>
}<br>
}<br>
}</p>
<pre><code>es新版本内置的建立对于text类型的filed，会建立两次索引，一个是分词的，另一个是不分词的，不分词的是基于field.keyword,最多保留256个字符直接一个字符串放入到倒排索引中。
teamquery：根据exact value进行搜索，数字 boolean 日期有天然支持
text类型的filed需要建立索引是指定not_analyzed,才能用terms
新版本中设置field为keyword和not_analyzed一样就是不分词
term 匹配一个值
terms 匹配多个值
</code></pre>
<p>全文检索多字段搜索</p>
<pre><code>GET /index/_search
{
    bool:{
        &quot;should&quot;:{
            term:{field:value},
            term:{field:value},
        }
    }
}

and match 转term+must

GET /index/_search
{
  bool:{
    &quot;must&quot;:{
       query:'value',
        operator:and
    }
   }
}
等价于
GET /index/_search
{
    bool:{
        &quot;must&quot;:{
            term:{field:value},
            term:{field:value},
        }
    }
}
</code></pre>
<figure data-type="image" tabindex="11"><img src="images/duoziduansousuo.png" alt="img.png" loading="lazy"></figure>
<p>手动控制全文检索的精准度</p>
<figure data-type="image" tabindex="12"><img src="images/convert.png" alt="img.png" loading="lazy"></figure>
<p>boost的细粒度搜索条件控制</p>
<figure data-type="image" tabindex="13"><img src="images/boost.png" alt="img.png" loading="lazy"></figure>
<p>多shard场景下 relevance score 不准确问题大揭秘</p>
<pre><code>如何解决该问题？    
生产环境下，数据量大尽可能的实现均匀分配
测试环境下，将所有的primary设置为1
测试环境下搜索附带search_type = dfs_query_then_query参数，会将local IDF取出来计算global IDF
</code></pre>
<p>基于dis_max实现best_field策略进行多字段搜索</p>
<pre><code>dix_max取某一个query最大的分数
GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
        &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;},
        {match:&quot;content&quot;:&quot;java solution&quot;}
     ]
    }  ,
    tie_ breaker:0.3
}

}
</code></pre>
<figure data-type="image" tabindex="14"><img src="images/best_field.png" alt="img.png" loading="lazy"></figure>
<p>基于tie_ breaker参数优化dis_ max搜索效果</p>
<pre><code>使用tie_ breaker参数的意义在于将其他query分数乘以tie_ breaker 综合与
最高分数的那个query，综合一起计算，除了最高分外将其他query的分数也考虑进去

GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
      &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;},
        {match:&quot;content&quot;:&quot;java solution&quot;}
     ]
    }  ,
    tie_ breaker:0.3
}

}
</code></pre>
<p>实战基于multi match语法实现dis_max+tie_breaker<br>
best_fields 策略</p>
<pre><code>GET / index/_search
    {
    &quot;query&quot;:{
      &quot;multi_match&quot;:{
         &quot;query&quot;:&quot;aaa&quot;,
         &quot;fileds&quot;:[&quot;field1&quot;,&quot;field2&quot;],
         type:&quot;best_fields&quot;,
         &quot;tie_breaker&quot;:0.3,
        &quot;minimum_should_match&quot;:50%
     }
}
</code></pre>
<p>等价于</p>
<pre><code>GET /index/_search
{
    &quot;query&quot;:{
    &quot;dis_max&quot;:{
        &quot;queries&quot;[
        {match:&quot;title&quot;:&quot;java solution&quot;
        &quot;minimum_should_match&quot;:50%
        &quot;boost&quot;:2},
        {match:&quot;content&quot;:&quot;java solution&quot;}
    ]  ,
    }  ,
    tie_ breaker:0.3
}

}
minimum_should_match:去长尾，控制搜索的精准度，只要匹配到一定数量的关键数据才能返回
</code></pre>
<p>基于multi_ match+most field策略进行multi-field搜索</p>
<pre><code>GET / index/_search
    {
    &quot;query&quot;:{
      &quot;multi_match&quot;:{
        &quot;query&quot;:&quot;&quot;,
          filed:[&quot;field1&quot;,&quot;field2&quot;],
         type:&quot;most_field&quot;,
         &quot;tie_breaker&quot;:0.3,
        &quot;minimum_should_match&quot;:50%
     }
}
</code></pre>
<p>与best_fields的区别</p>
<pre><code>1.best_fields是对多个field进行搜索，搜索挑选某个field匹配度最高的那个分数，同时在多个query最高分相同的情况下，在一定
程度上考虑其他query的分数。简单来说，你对多个field进行搜索，就想搜索到某一个field尽可能的包含更多关键字的数据
优点：通过best_fields策略，以及综合考虑其他field，还有minimum_should_match，可以尽可能精准地将匹配结果推送到最前面
缺点：除了那些精准匹配的结果，其他差不多大的结果，排序结果不太均匀
实际的例子，百度之类的搜索引擎，最匹配的在前面，但是其他的就没有什么区分度了
2.most_fields,综合多个field一起进行搜索，尽可能多的让所有field的query参与到总分计算中来，此时就会是个大杂烩结果不一定精准，
某一个document的一个field包含了多个关键字，但是因为有其他document有更多的field匹配到了，所以排在了前面；所以需要建立sub_title.std这样的field，
尽可能的让某一个field匹配到query string，贡献更高的分数，将更精准的结果拍到前面
优点：尽可能的匹配更多的field的结果推送到前面整个结果是比较均匀分布的
缺点：可能那些精准匹配的结果无法推送到到前面
实际的例子wiki，明显就是most_fields策略，搜索的结果比较均匀，但是翻好几页才能找到最匹配的结果
</code></pre>
<p>使用most_ fields策 略进行cross-fields search弊端大揭秘</p>
<p>使用copy_ to 定制组合field解决cross- -fields搜索弊端</p>
<p>使用原生cross-field技术解决搜索弊端</p>
<p>phrase matching搜索技术</p>
<pre><code>match query 做全文检索时，只能搜索包含这些次的document，
如果需要这些词里得很近的document，那就要给他一个更高的relevance score 这里
就涉及到proximity match 近似匹配
 
GET /index/_search
{
    &quot;query&quot;:{
    match_phrase:{
        &quot;title&quot;:{
        &quot;query&quot;:&quot;java spark&quot;,
        &quot;slop&quot;:1
    }
  }
 }
}
slop:query string搜索文本中的几个term，要经过多少次移动才能与一个document匹配 
其实加了phrase match 就是 proximity match 近似匹配
</code></pre>
<p>混合使用match和近似匹配实现召回率与精准度的平衡</p>
<pre><code>召回率（recall）： 比如说你搜索一个java spark 总共有100个doc，能返回多少个结果作为doc，就是召回率。
精准度（precision）:比如你搜索一个java spark ,能不能尽可能的让包含java spark，或者java和spark离得很近的排在前面
近似匹配的时候，召回率比较低，精准度太高了
但是有时候可能我们希望的是匹配到几个term中的部分，就可以作为结果出来，这样可以提高召回率。同时我们也希望用上match_phrase根据距离提高分数的功能，
让几个term距离越近的分数越高，优先返回
就是优先返回召回率同时兼顾精准度
   GET /index/_search
{
    &quot;query&quot;:{
      bool:{
         must:{
            &quot;match&quot;:{
              &quot;field&quot;:{
                &quot;query&quot;:&quot; vaule&quot;,
                &quot;minimum_should_match&quot; :&quot;50%&quot;
          },
          should:{
            &quot;match_phrase&quot;:{
                &quot;field&quot;:{
                   &quot;query&quot;:&quot;value&quot;
                    &quot;slop&quot;:&quot;50&quot;
                }
            }
        }
      }
    }
  }
 }
}
</code></pre>
<p>使用rescore机制优化近似匹配搜索的性能</p>
<pre><code>match 和 match_phrase区别
    match：只要简单的匹配到了一个term，就可以将doc作为结果返回
    match_phrase：首先扫描到所有的term的doc list；找到包含所有的
    term 的doc list；然后对每个doc都计算每个term的position，是否符合指定范围
    slop，需要进行复杂的运算，来判断是否通过slop，
match query的性能要比match_phrase和 proximity match(有slop) 近似匹配要高很多，
因为后两者豆芽计算position 的距离。match query 比match_phrase性能搞10被，比proximity match 高20倍
但是别担心，因为es的性能都是毫秒级别的，match query一般就在几毫秒或者几十毫秒，所以是可以接受的

优化proximity match的性能一般就是减少要进行proximity match搜索的documeng 的数量
主要思路就是match query 先过滤出需要的数据，然后再用proximity match来根据term距离来提高doc分数
rescore：重打分
</code></pre>
<pre><code class="language-java">   GET/index/_search
        {
        &quot;query&quot;:{
                    &quot;match&quot;:{
                     &quot;field&quot;:&quot; vaule&quot;,
                     
               }
          },
        rescore:{
            &quot;window_size&quot;:50,
             rescore_query:{
                &quot;match_phrase&quot;:{
                &quot;field&quot;:{
                &quot;query&quot;:&quot;value&quot;
                &quot;slop&quot;:&quot;50&quot;
                }
            }
           }
        }
</code></pre>
<figure data-type="image" tabindex="15"><img src="images/rescoring.png" alt="img.png" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="images/chongdafen.png" alt="img.png" loading="lazy"></figure>
<p>实战前缀搜索、通配符搜索、正则搜索等技术</p>
<pre><code>前缀搜索

    GET /index/_search/
    {
        &quot;query&quot;:{
         &quot;prefix&quot;:{
            &quot;field&quot;:&quot;value&quot;
        }
      }
    }
prefix query 不计算relevance score 与prefix filter 唯一区别就是
filter 会cache bitset
前缀越短，要处理的doc越多，性能越差，尽可能的用长前缀搜索
 
通配符搜索：
跟前缀搜索类似，功能更加强大

GET /index/_search/
{
&quot;query&quot;:{
  &quot;wildcard&quot;:{
      &quot;field&quot;:&quot;value&quot;
      }
   }
}

 正则搜索
   GET /index/_search/
 {
    &quot;query&quot;:{
      &quot;regexp&quot;:{
          &quot;field&quot;:&quot;value&quot;
          }
       }
  }

wildcard 和regexp和prefix原理一致，都会扫描整个索引，性能很差
</code></pre>
<p>实战match_phrase_prefix实现search-time搜索推荐（少用）</p>
<pre><code>match_phrase_prefix原理跟match_phrase类似，唯一的区别就是把最后一个term超过这个数量的就不需要匹配了，限定性能
也可以指定slop，但是最后一个term会最为前缀
 max_expansions:指定prefix最多匹配多个term，超过这个数量就不再匹配了，限定性能
   GET /index/_search/
 {
    &quot;query&quot;:{
      &quot;match_phrase_prefix&quot;:{
          &quot;field&quot;:&quot;{
                &quot;query&quot;:&quot;value1 value2&quot;,
                &quot;slop&quot;:&quot;10&quot;,
                &quot;max_expansions&quot;:50,
             }
          }
       }
  }
默认情况下，前缀要扫描所有的倒排索引中的term，去找这个词打头的，但是这样性能太差，可以用max_expansions限定，最对匹配多少个。就停止搜索了。
</code></pre>
<p>实战通过ngram分词机制实现index-time搜索推荐</p>
<figure data-type="image" tabindex="17"><img src="images/ngram.png" alt="img.png" loading="lazy"></figure>
<p>深入揭秘TF&amp;IDF算法以及向量空间模型算法</p>
<p>深入揭秘lucene的相关度分数算法</p>
<p>实战掌握四种常见的相关度分数优化方法</p>
<p>实战用function_ score自定 义相关度分数算法</p>
<p>实战掌握误拼写时的fuzzy模糊搜索技术<br>
<img src="images/fuzzy.png" alt="img.png" loading="lazy"></p>
<h3 id="ik中文分词器">IK中文分词器</h3>
<h3 id="深入聚合数据分析">深入聚合数据分析</h3>
<p>bucket与metric核心概念</p>
<pre><code>bucket:对数据进行分组，每一组就是一个bucket
metric:对一个数据组进行统计，就是对一个bucket执行某种聚合分析操作，比如说求最大值，求最小值
select count(*) from table group by id 
bucket:group by id --&gt; 那些id相同的数据，就会被划分到一个bucket中
metric:count(*),对每个id 对应饿bucket中的所有数据，计算一个数量
</code></pre>
<p>聚合分组最基本语法</p>
<pre><code>GET /index/_search/
{
   size:0,
   &quot;aggs&quot;:{
      &quot;group_name&quot;: {
          &quot;terms&quot;:{
                &quot;field&quot;:&quot;value&quot;
            }
        }
    }
}
size：只获取聚合结果，而不要执行聚合的原始数据
aggs: 固定语法，要对一份数据执行分组聚合操作
group_name：就是对每个aggs，都要起一个名字，这个名字是自定义的，你取什么都OK 
terms:根据字段的值进行分组
filed:根据指定的字段的值进行分组
</code></pre>
<p>聚合查询结果分析：</p>
<pre><code>hits.hits:我们指定了size是0，所以hits.hits就是空的，否则会把执行聚合的那些原始数据给你返回回来
aggregations:聚合结果
group_name：我们执行的聚合的名称
buckets:我们执行的field划分出的buckets
doc_count:这个bucket分组内有多少数据
默认的排序规则:按照doc_count倒叙排序
</code></pre>
<p>聚合分组后，执行每组的metric聚合操作：</p>
<pre><code>GET /index/_search/
{
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
     &quot;terms&quot;:{
     &quot;field&quot;:&quot;value&quot;
      },
     &quot;aggs&quot;:{
        &quot;group_name_1&quot;:
            &quot;ave&quot;:{
                &quot;field&quot;:&quot;value&quot;
            }
        }
    }
  }
}
doc_count: 其实知识es的bucket操作默认执行的一个内置的metric
对每组bucket执行metric聚合统计操作
在一个aggs执行的bucket操作（terms），平级的json结构下，再加一个aggs，
这个aggs内部同样去个名字，执行metric操作avg（max，min），对之前的每个bucket中的数据的执行field，求一个平均值

select avg(field) from tabel group by filed
</code></pre>
<p>bucket嵌套实现多层下钻分析：</p>
<pre><code>下钻的意思是：已经分了一个组，比如说颜色的分组，然后还要对这个分组内的数据在分组，比如说一个颜色内有多个不同品牌的组
最后对每个最小粒度的分组进行聚合分析操作，这就叫做下钻分析。 

es实现下钻分析，就是对bucket进行多层嵌套，多次分组
     GET /index/_search/
{
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
         &quot;terms&quot;:{
         &quot;field&quot;:&quot;value&quot;
          },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;avg&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;max&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;min&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
            },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;terms&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                 &quot;aggs&quot;:{
                   &quot;group_name_1&quot;:
                    &quot;ave&quot;:{
                       &quot;field&quot;:&quot;value&quot;
                }
            },
            },
    }
  }
}
avg:计算组内平均值
max:计算组内最大值
min:计算组内最小值
sum:计算组内平均值
</code></pre>
<p>histogram区间统计</p>
<pre><code>histogram，类似terms，也是进行bucket分组操作，按照这个field的值的各个范围区间，进行bucket分组操作
按照数字区间：
&quot;histogram&quot;:{
         &quot;field&quot;:&quot;value&quot;
         &quot;interval&quot;:2000
         },
interval:2000 划分范围，比如0-2000，2000-4000 bucket
 去根据field的值看落在哪个区间，就会将这条数据放在哪个bucket中
按照日期区间；
    &quot;histogram&quot;:{
         &quot;field&quot;:&quot;value&quot;
         &quot;interval&quot;:&quot;month&quot;
         &quot;format&quot;:&quot;yyyy-MM-dd&quot;
        &quot;min_doc_count&quot;:0
        &quot;extended_bounds&quot;:{
            &quot;min&quot;:&quot;2017-01-10&quot;,
            &quot;max&quot;:&quot;2017-11-10&quot;,
        }
     },
    min_doc_count:即使某个日期interval一条数据也没有，那么这个区间也是要返回的，不然默认会过滤掉这个区间
    extended_bounds：划分bucket会限定起止日期
    extended_bounds.min：开始日期
    extended_bounds.max：截止日期
</code></pre>
<p>搜索+聚合</p>
<pre><code>es aggregation scope 任何的聚合都必须在搜索的结果中执行，搜索结果就是分析的scope

        GET /index/_search/
{
    query：{},
    size:0,
   &quot;aggs&quot;:{
     &quot;group_name&quot;: {
         &quot;terms&quot;:{
         &quot;field&quot;:&quot;value&quot;
          },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;avg&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;max&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                   &quot;min&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
            },
         &quot;aggs&quot;:{
            &quot;group_name_1&quot;:
                &quot;terms&quot;:{
                    &quot;field&quot;:&quot;value&quot;
                },
                 &quot;aggs&quot;:{
                   &quot;group_name_1&quot;:
                    &quot;ave&quot;:{
                       &quot;field&quot;:&quot;value&quot;
                }
            },
            },
    }
  }
}
</code></pre>
<p>排序</p>
<pre><code>es聚合排序默认是按照每组的doc_count降序来排的
如果按照指定字段来排序
GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;terms&quot;:{
              &quot;field&quot;:&quot;value&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            },
           &quot;aggs&quot;:{
                &quot;group_name_1&quot;:{
                 &quot;avg&quot;:{&quot;field&quot;:&quot;value&quot;}
                }

            }
        }

    }

    }
}
</code></pre>
<p>并行聚合算法、三角选择原则、近似聚合算法</p>
<pre><code>有些聚合算法，是很容易可以并行的，比如说max
有些聚合分析的算法是不好并行的，比如说count(distinct), 并不是说在每个node上，
直接就出一些distinct value，就可以了，因为有些数据可能会很多近似估计后的结构，
不完全准确，但是速度会很快，一一般是完全精准的算法的性能的十倍

三角选择原则：精准+实时+大数据
1.精准+实时：没有大数据，数据量很小，那么一般就是单机跑，随便你怎么玩就可以
2.精准+大数据：hadoop，批处理，非实时，可以处理海量数据，保证精准，可能会跑几个小时
3.大数据+实时：es 不精准，近似估计，可能会有百分之几的错误率

近似聚合算法
如果采用近似估计的算法，延时在100ms左右，0.5%错误
如果采用100%精准的算法：延时一般在5s到几十秒 几个小时，0%错误率
</code></pre>
<p>去重</p>
<pre><code>es去重，cardinality metric，对每个bucket中指定的filed去重，取去重后的count,类似count(distinct)
 GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;terms&quot;:{
              &quot;field&quot;:&quot;value&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            },
           &quot;aggs&quot;:{
                &quot;distinct_group_name&quot;:{
                 &quot;cardinality&quot;:{&quot;field&quot;:&quot;value&quot;,&quot;precision_threshold&quot;:&quot;100&quot;}
                }

            }
        }

    }

    }
}
precision_threshold: precision_threshold* 8内存的消耗
占用内存很小而且你的unique value如果在值以内，那么可以确保100%精准
precision_threshold 设置的值越大，占用内存越大，可以确保更多unique value的100%准确
</code></pre>
<p>HyperLog++（HLL）算法性能优化(一般)</p>
<pre><code>cardinality底层是HyperLog算法
会对所有的unique value取hash值，通过hash值近似的去求distinct count，
默认情况下 ，发送一个cardinality请求的时候，会动态的对所有的filed value2
取hash值，前移到建立索引的时候
 
put /index/_mapping
 {
    &quot;mapping&quot;:{
        properties:{
         &quot;type&quot;:&quot;text&quot;,
        &quot;fileds&quot;:{
            &quot;hash&quot;:{&quot;type&quot;:&quot;murmur3&quot;}
        }
    }
    }
}

查询时
    GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;cardinality&quot;:{
              &quot;field&quot;:&quot;type.hash&quot;,
              &quot;order&quot;:{
                &quot;group_name_1&quot;:&quot;desc&quot;
            }
        }
    }
}
</code></pre>
<p>percentiles百分比算法</p>
<pre><code>GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;percentiles&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        }
    }，
    &quot;latency_ave&quot;:{
    &quot;avg&quot;:{field:&quot;value&quot;}
    }
}


  GET /index/_search/
{
    &quot;size&quot;:&quot;0&quot;,
    &quot;aggs&quot;:{
        &quot;group_name&quot;:{
            &quot;percentiles&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        },
    &quot;aggs&quot;:{
        &quot;group_name_1&quot;:{
            &quot;percentile_ranks&quot;:{
              &quot;field&quot;:&quot;latency&quot;,
              &quot;percents&quot;:{
                50，95，99
            }
        },

    }，
    
}
</code></pre>
<p>基于doc value正排索引聚合分析内部原理</p>
<pre><code>核心原理
    与倒排索引类似，正排索引也会写入磁盘文件中，然后呢os cache先进行缓存，以提升 doc value正排索引的性能
    如果 os cache 内存大小不足够放下整个正排索引，就会将doc value数据写入到磁盘文件中

性能问题：
    es官网建议，es大量是基于os cache来进行缓存和提升性能的，不建议用JVM内存来进行缓存
    那样会导致GC和oom的问题
    一般来说给jvm更少的内存，给os cache更大的内存
    os cache可以提升doc value和倒排索引的缓存和查询效率

column压缩：
  1.所有的值相同，直接保留单值
  2.....
  3.
disable doc value
    如果的确不需要用到doc value，比如聚合，排序等操作，那么可以禁用，减少磁盘占用
    put /index/
    {
        &quot;mapping&quot;
            &quot;properties&quot;:{
               &quot;field&quot;:&quot;keyword&quot;,
                &quot;doc_values&quot;:false
            }
    }
doc_values:false 禁用倒排索引
</code></pre>
<p>string field 和fielddata原理</p>
<pre><code>对分词的field直接执行聚合操作，会报错，
大概的意思是说，你必须要打开fielddata，然后将正排索引的数据加入到缓存中，才可以对分词的field进行聚合操作
会消耗很大的内存

对不分词的field执行聚合操作，直接可以执行，不需要设置fielddata ：true

分词field + fielddata的工作原理
    如果你的某个fie1d不分词，那么在建立索引的时候，会自动生成doc value（正排索引），针对这些不分词的fie1d 执行聚合操作，直接就可以执行
    分词的fie1d，是没有doc value的，所以必须打开是使用fielddata，那么必须将fielddata = true ，那么es在进行聚合操作的时候，会现场对
    field建立一份正排索引，完全存于内存中，结构和doc value类似，如果是ngram或者是大量的term，那么必将
    占用大量的内存，导致性能很差

fielddata加载是lazy加载的，对一个analyzed field执行聚合时，才会加载，而且是field-level
一个index的field所有的doc都会被加载，而不是少数doc
不是index-time创建，是query-time创建

fielddata内存限制
    indices.fielddata.cache.size:20%,超出限制清楚内存已有的fielddata数据
    默认设置无限制，限制内存的使用，但是会导致频繁evict和reload，大量的IO性能损耗，以及内存碎片和gc 

监控fielddata内存使用
     GET /_stats/fielddata?fileds=*
     GET /_nodes/_stats/indices/fielddata?fileds=*
     GET /_nodes/_stats/indices/fielddata?level=indices&amp;fileds=*

Circuit breaker 
        如果一次query load的fielddata超过总内存，就会oom 
indices.breaker.fielddata.limit: fielddata内存限制默认是60%
indices.breaker.request.limit: 执行聚合操作的内存限制，默认40%
indices.breaker.total.limit: 综合上面两个，限制在70%以内

fielddata filter细粒度内存加载控制
    POST /index/_mapping
    {
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;filter&quot;: {
                &quot;frequency&quot;:{
                    &quot;min&quot;:&quot;0.01&quot;,
                    &quot;min_segment_size&quot;:500
                    }
                }
            }
        }
    }
   min:仅仅加载至少在1%的doc中出现过的term对于的fielddata
   min_segment_size：少于500doc的segment 不加载fielddata
   这两个参数比较底层，一般不设置

fielddata预加载机制，以及序号标记预加载
    如果真的要对某个分词的field进行聚合，那么在query-time的时候现场生产fielddata并加载到内存，速度可能比较慢，此时我们可以fielddata预加载
     POST /index/_mapping
    {
       &quot;properties&quot;:{
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;loading&quot;：&quot;eager&quot;
            }
        }
     }
    }


  POST /index/_mapping
    {
       &quot;properties&quot;:{
        &quot;field&quot;:{
            &quot;type&quot;: &quot;text&quot;,
            &quot;fielddata&quot;：{
                &quot;loading&quot;：&quot;eager_global_ordinals&quot;
            }
        }
     }
    }
</code></pre>
<p>海量bucket优化机制：从深度优化到广度优化</p>
<figure data-type="image" tabindex="18"><img src="images/sdyx.png" alt="img.png" loading="lazy"></figure>
<h3 id="数据建模实战">数据建模实战</h3>
<h3 id="完成建议">完成建议</h3>
<pre><code>基于complete suggest实现搜索提示

比如说我们在百度搜索 '大话西游' 百度会自动给你提示 ，
'大话西游电影'，'大话西游小说'，'大话西游手游'
不用你把所有你想要的文本都输入完，搜索引擎会自动提示你可能想要搜索的那个文本
PUT index
   {
    &quot;settings&quot;: {
        &quot;number_of_shards&quot;: 3,
        &quot;number_of_replicas&quot;: 2
    },
 
    &quot;mappings&quot;: {
        &quot;properties&quot; : {
        &quot;suggest&quot; : {
            &quot;type&quot; : &quot;completion&quot;
        },
          &quot;id&quot;: {
           &quot;type&quot;: &quot;integer&quot;
        }
    }
  }
}

或者

PUT index
   {
    &quot;settings&quot;: {
        &quot;number_of_shards&quot;: 3,
        &quot;number_of_replicas&quot;: 2
    },
 
    &quot;mappings&quot;: {
        &quot;properties&quot; : {
        &quot;title&quot; : {
             &quot;type&quot; : &quot;text&quot;,
            &quot;analyzed&quot;:&quot;ik_max_word&quot;
             &quot;fields&quot;: {
                    &quot;suggest&quot;: {
                        &quot;type&quot;: &quot;completion&quot;,
                        &quot;analyzer&quot;:&quot;ik_max_word&quot;
                    }
                }
        },
          &quot;id&quot;: {
           &quot;type&quot;: &quot;integer&quot;
        }
    }
  }
}
completion,es实现的时候，是非常高性能的，会建立不是倒排索引，也不是正排索引。
就是纯基于前缀搜索的一种特殊数据结构，而且会放在内存中，所以auto completion进行
前缀搜索提示性能是非常高的。


GET /index/_search/
{
  &quot;suggest&quot;:{
    &quot;my-suggest&quot;:{
        &quot;prefix&quot;:&quot;大话西游&quot;，
        &quot;completion&quot;:{
            &quot;field&quot;:&quot;suggest&quot;
        }

        }
    }

或者

GET /index/_search/
{
  &quot;suggest&quot;:{
    &quot;my-suggest&quot;:{
        &quot;prefix&quot;:&quot;大话西游&quot;，
        &quot;completion&quot;:{
            &quot;field&quot;:&quot;title.suggest&quot;
        }
      }
    }
}
</code></pre>
<h3 id="生产实践集群">生产实践集群</h3>
<h3 id="elasticsearch性能调优">Elasticsearch性能调优</h3>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#elasticsearch">Elasticsearch</a>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
</ul>
</li>
<li><a href="#elasticsearch-2">Elasticsearch</a>
<ul>
<li><a href="#elasticsearch%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8%E7%AF%87">Elasticsearch核心知识入门篇</a>
<ul>
<li><a href="#elasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8">Elasticsearch快速入门</a>
<ul>
<li><a href="#elasticsearch%E5%8A%9F%E8%83%BD%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%E7%89%B9%E7%82%B9">Elasticsearch功能适用场景特点</a></li>
<li><a href="#elasticsearch%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5">Elasticsearch核心概念</a></li>
<li><a href="#elasticsearch%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2">Elasticsearch安装部署</a></li>
<li><a href="#elasticsearch%E6%96%87%E6%A1%A3%E7%9A%84crud">Elasticsearch文档的CRUD</a></li>
<li><a href="#elasticsearch%E5%A4%9A%E7%A7%8D%E6%90%9C%E7%B4%A2%E6%96%B9%E5%BC%8F">Elasticsearch多种搜索方式</a></li>
<li><a href="#elasticsearch%E8%81%9A%E5%90%88%E6%90%9C%E7%B4%A2">Elasticsearch聚合搜索</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch分布式架构</a>
<ul>
<li><a href="#elasticsearch%E5%9F%BA%E7%A1%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch基础分布式架构</a>
<ul>
<li><a href="#elasticsearch%E5%AF%B9%E5%A4%8D%E6%9D%82%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%8F%E6%98%8E%E9%9A%90%E8%97%8F%E7%89%B9%E6%80%A7">Elasticsearch对复杂分布式机制的透明隐藏特性</a></li>
<li><a href="#elasticsearch%E7%9A%84%E5%9E%82%E7%9B%B4%E6%89%A9%E5%AE%B9%E4%B8%8E%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9">Elasticsearch的垂直扩容与水平扩容</a></li>
<li><a href="#elasticsearch%E5%A2%9E%E5%87%8F%E8%8A%82%E7%82%B9%E6%97%B6rebalance">Elasticsearch增减节点时rebalance</a></li>
<li><a href="#elasticsearch%E7%9A%84master%E8%8A%82%E7%82%B9">Elasticsearch的master节点</a></li>
<li><a href="#elasticsearch%E8%8A%82%E7%82%B9%E5%B9%B3%E7%AD%89%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84">Elasticsearch节点平等的分布式架构</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86">分片原理</a>
<ul>
<li><a href="#shardreplica%E6%9C%BA%E5%88%B6%E6%A2%B3%E7%90%86">Shard&amp;replica机制梳理</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E5%8E%9F%E7%90%86">Elasticsearch横向扩容原理</a><br>
*
<ul>
<li><a href="#elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%9F%E7%90%86_%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E5%A6%82%E4%BD%95%E8%B6%85%E5%87%BA%E6%89%A9%E5%AE%B9%E6%9E%81%E9%99%90%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%AE%B9%E9%94%99%E6%80%A7">Elasticsearch分布式原理_横向扩容，如何超出扩容极限以及如何提升容错性</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6master%E9%80%89%E4%B8%BEreplace%E5%AE%B9%E9%94%99%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D">Elasticsearch容错机制：master选举，replace容错，数据恢复</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E5%88%86%E5%B8%83%E5%BC%8Fdocument">Elasticsearch分布式document</a>
<ul>
<li><a href="#index%E5%85%83%E6%95%B0%E6%8D%AE">Index元数据</a></li>
<li><a href="#type%E5%85%83%E6%95%B0%E6%8D%AE">Type元数据</a></li>
<li><a href="#id%E5%85%83%E6%95%B0%E6%8D%AE">Id元数据</a></li>
<li><a href="#source%E5%85%83%E6%95%B0%E6%8D%AE">Source元数据</a></li>
<li><a href="#document%E7%9A%84%E5%85%A8%E9%87%8F%E6%9B%BF%E6%8D%A2">Document的全量替换</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Eexterna1lversion%E8%BF%9B%E8%A1%8C%E4%B9%90%E8%A7%82%E9%94%81%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6">基于externa1lVersion进行乐观锁并发控制</a></li>
<li><a href="#partialupdate">PartialUpdate</a></li>
<li><a href="#%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C">批量操作</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">Elasticsearch分布式系统</a>
<ul>
<li><a href="#document%E6%95%B0%E6%8D%AE%E8%B7%AF%E7%94%B1%E5%8E%9F%E7%90%86">Document数据路由原理</a></li>
<li><a href="#document%E5%A2%9E%E5%88%A0%E6%94%B9%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86">Document增删改内部原理</a></li>
<li><a href="#%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8Aquorum%E6%9C%BA%E5%88%B6%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">写一致性原理以及quorum机制的深入解析</a></li>
<li><a href="#document%E5%86%85%E9%83%A8%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86">Document内部查询原理</a></li>
<li><a href="#builapi%E7%9A%84%E5%A5%87%E7%89%B9json%E6%A0%BC%E5%BC%8F%E4%B8%8E%E5%BA%95%E5%B1%82%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%85%B3%E7%B3%BB">BuilApi的奇特json格式与底层性能优化关系</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E">Elasticsearch搜索引擎</a>
<ul>
<li><a href="#search%E7%BB%93%E6%9E%9C%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">Search结果的深入解析</a></li>
<li><a href="#multi-indexmulti-type%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86">Multi-index&amp;multi-type搜索模式解析以及搜索原理</a></li>
<li><a href="#%E5%88%86%E9%A1%B5%E6%90%9C%E7%B4%A2%E4%BB%A5%E5%8F%8Adeep-paging%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%B7%B1%E5%BA%A6%E5%9B%BE%E8%A7%A3">分页搜索以及deep paging性能问题深度图解</a></li>
<li><a href="#%E9%80%9F%E6%8E%8C%E6%8F%A1query-string-search%E8%AF%AD%E6%B3%95%E4%BB%A5%E5%8F%8A_all-metadata%E5%8E%9F%E7%90%86%E6%8F%AD%E7%A7%98">速掌握query string search语法以及_all metadata原理揭秘</a></li>
<li><a href="#mapping">mapping</a></li>
<li><a href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%BF%AB%E9%80%9F%E8%A7%A3%E5%AF%86">倒排索引的核心原理快速解密</a></li>
<li><a href="#%E5%88%86%E8%AF%8D%E5%99%A8">分词器</a></li>
<li><a href="#querydsl">QueryDSL</a></li>
<li><a href="#%E5%AF%B9stringfield%E6%8E%92%E5%BA%8F">对StringField排序</a></li>
<li><a href="#%E7%9B%B8%E5%85%B3%E5%BA%A6%E8%AF%84%E5%88%86tfidf%E7%AE%97%E6%B3%95">相关度评分TF&amp;IDF算法</a></li>
<li><a href="#docvalues%E6%AD%A3%E6%8E%92%E7%B4%A2%E5%BC%95">DocValues正排索引</a></li>
<li><a href="#queryphase">QueryPhase</a></li>
<li><a href="#fetchphase">FetchPhase</a></li>
<li><a href="#%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0%E6%A2%B3%E7%90%86%E4%BB%A5%E5%8F%8Abouncingresults%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">搜索相关参数梳理以及bouncingresults问题的解决方案</a></li>
<li><a href="#scoll%E6%8A%80%E6%9C%AF%E6%BB%9A%E5%8A%A8%E6%90%9C%E7%B4%A2%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE">Scoll技术滚动搜索大量数据</a></li>
</ul>
</li>
<li><a href="#elasticsearch%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86">Elasticsearch索引管理</a>
<ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9">索引的增删改</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E5%88%86%E8%AF%8D%E8%B5%B7%E4%BB%A5%E5%8F%8A%E5%AE%9A%E5%88%B6%E5%88%86%E8%AF%8D%E5%99%A8">修改分词起以及定制分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2type%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">深入探索type底层数据结构</a></li>
<li><a href="#mappingrootobject%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90">MappingRootObject深入解析</a></li>
<li><a href="#%E5%AE%9A%E5%88%B6%E5%8C%96%E8%87%AA%E5%B7%B1%E7%9A%84dynamicmapping%E7%AD%96%E7%95%A5">定制化自己的dynamicMapping策略</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#elasticsearch%E9%AB%98%E6%89%8B%E8%BF%9B%E9%98%B6%E7%AF%87">Elasticsearch高手进阶篇</a>
<ul>
<li><a href="#%E6%B7%B1%E5%BA%A6%E6%8F%AD%E7%A7%98%E6%90%9C%E7%B4%A2%E6%8A%80%E6%9C%AF">深度揭秘搜索技术</a></li>
<li><a href="#ik%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8">IK中文分词器</a></li>
<li><a href="#%E6%B7%B1%E5%85%A5%E8%81%9A%E5%90%88%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">深入聚合数据分析</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E5%AE%9E%E6%88%98">数据建模实战</a></li>
<li><a href="#%E5%AE%8C%E6%88%90%E5%BB%BA%E8%AE%AE">完成建议</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E9%9B%86%E7%BE%A4">生产实践集群</a></li>
<li><a href="#elasticsearch%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98">Elasticsearch性能调优</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://zuolinlin.github.io/zuo.github.io/post/redis/">
              <h3 class="post-title">
                redis
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">zuozuozuo</a>
  <a class="rss" href="https://zuolinlin.github.io/zuo.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
